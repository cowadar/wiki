{"config":{"lang":["nl"],"separator":"[\\s\\-\\.]","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83c\udfe0 Home","text":""},{"location":"#personal-knowledge-management","title":"Personal Knowledge Management","text":""},{"location":"#waarom-een-pkm","title":"Waarom een PKM?","text":"<p>We hebben deze PKM opgezet aangezien we beide dagelijks veel bijleren en er dagelijks nieuwe technologi\u00eben en ontwikkelingen ontstaan. Aangezien we het fijn vinden om mee te zijn met de laatste nieuwtjes, hebben we uiteraard ook een plaats nodig om dit te kunnen documenteren.</p>"},{"location":"#hoe-is-deze-pkm-ontstaan","title":"Hoe is deze PKM ontstaan?","text":"<p>In het begin hebben we op Discord veel nuttige informatie \"\ud83d\udccc gepind\" in onze gezamelijke chat. Deze chat is heilig voor ons en hebben al vaak gesproken over wat een ramp het zou zijn als deze chat ooit verwijderd zou worden.</p> <p>Uiteraard is een chat niet overzichtelijk en moeten we toch vaak beroep doen op de zoekfunctie.</p> <p>Daarom heeft Bedar voorgesteld om te werken met mkdocs.</p>"},{"location":"#welke-informatie-kan-ik-hier-terugvinden","title":"Welke informatie kan ik hier terugvinden?","text":"<p>Alle informatie die we belangrijk genoeg vinden om te documenteren en die ons kunnen helpen met onze dagelijkse taken.</p>"},{"location":"#mag-ik-zelf-iets-toevoegen-of-verbeteren","title":"Mag ik zelf iets toevoegen of verbeteren?","text":"<p>Uiteraard! Je bent altijd welkom om PR's te sturen.</p>"},{"location":"#hoe-kan-ik-jullie-contacteren","title":"Hoe kan ik jullie contacteren?","text":"<p>Je kan meer informatie over ons vinden over Bedar en Cowarol op de Cowadar pagina.</p>"},{"location":"about/bedar/","title":"Bedar","text":""},{"location":"about/bedar/#bedar","title":"Bedar","text":""},{"location":"about/bedar/#over-mij","title":"Over mij","text":"<p>Ik ben sinds kinds af aan gepassioneerd door computers, servers, networking en basically alles dat met IT te maken heeft.</p> <p>Mijn eerste herinnering was toen ik als kind een joystick gekregen had voor mijn verjaardag. Uiteraard bestond er toen nog geen \"plug &amp; play\" en was mijn vader bezig om de drivers werkende te krijgen voor mij. Zo zat ik uren naast hem te kijken hoe hij al de magische getallen en cijfers deed veranderen (ja, het was in de het MS-DOS tijdperk). Tijdens dat hij hiermee bezig was, heb ik hem verschillende vragen gesteld en leerde ik dus op vroege leeftijd al hoe je een computer moest aansluiten. (Dit was als kind al veel)</p> <p>Door deze herinnering is er een vurige passie ontstaan om met IT te werken. Of zoals mijn moeder zegt \"Zolang het maar iets met computers is\".</p> <p>Op school bestond er eerst nog een informatica richting en ben dus maar Electro mechanica gaan studeren, in de hoop om later robots te kunnen aansturen. Echter kregen we opeens het nieuws dat er eindelijk een Informatica richting beschikbaar zou zijn in het 5de middelbaar. Deze kans heb ik niet laten liggen en heb in het 4de middelbaar mijn grootste inspanning gedaan om naar Informatie te kunnen overschakelen.</p>"},{"location":"about/bedar/#carriere","title":"Carriere","text":"<p>Door omstandigheden, ben ik eerder met school gestopt en ben ik moeten gaan werken. In het begin waren dit magazijnier-achtige jobs, maar heb opeens de kans gekregen om in een cold-calling bedrijf terecht te komen die IT oplossingen \"verkocht\" aan andere bedrijven. Hier haalde ik zeer goede resultaten, aangezien ik op hetzelfde niveau als een IT Manager kon spreken, wat mijn success-rate naar boven heeft gehaald.</p> <p>Toch wou ik naar iets anders op zoek, aangezien ik niet alle dagen wou uitbellen en ben dan uiteindelijk in de IT Distributie terecht gekomen. Dit was origineel niet mijn \"eindstation\", maar de combinatie met Sales en IT begon ik steeds fijner te vinden. Zo kan ik tegelijkertijd mensen helpen, met gelijkzinnige mensen over IT onderwerpen praten en mijn IT kennis blijven bijschaven.</p> <p>Momenteel ben ik werkzaam bij 1 van de grootste IT Distributeurs in de wereld als \"Technical Presales Specialist\".</p> <p>Het voelt nog niet alsof ik op mijn eindstation zit, maar wegens het aanschaffen van een huis, blijf ik wel graag even in dit station zitten </p>"},{"location":"about/bedar/#waar-kan-je-mij-vinden","title":"Waar kan je mij vinden?","text":""},{"location":"about/cowadar/","title":"Cowadar","text":""},{"location":"about/cowadar/#cowadar","title":"Cowadar","text":""},{"location":"about/cowadar/#betekenis-cowadar","title":"Betekenis Cowadar","text":"<p>Cowadar is een samenvoeging van COWArol en beDAR.</p>"},{"location":"about/cowadar/#ontstaan-van-cowadar","title":"Ontstaan van Cowadar","text":"<p>Cowadar is ontstaan doordat Cowarol en Bedar dezelfde interesses hebben en een plaats zochten om alles kennis te bundelen. Hierdoor kunnen we niet enkel persoonlijk groeien, maar eveneens ook op professioneel vlak.</p> <p>Zo is Cowarol beter in Networking en Bedar is dan weer beter in programmeren. Door deze sterktes en zwaktes te combineren en aan te vullen, kunnen samen sneller en efficienter groeien en kennis opdoen.</p>"},{"location":"about/cowarol/","title":"Cowarol","text":""},{"location":"about/cowarol/#cowarol","title":"Cowarol","text":""},{"location":"about/cowarol/#over-mij","title":"Over mij","text":"<p>Op 14 jarige leeftijd was ik reeds op eigen initiatief de router van mijn ouders aan het configureren. Later breide ik dit zelf verder uit met meerdere routers en switchen tot een groter thuisnetwerk en dit zonder enige scholing op dat moment. Zo groeide mijn interesse in IT verder. Op dat momment was ik nog in mijn opleiding Elektriciteit. Na deze opeleiding heb ik toch de stap gewaagd om verder te studeren en ben ik mijn opleiding Systeem &amp; netwerkeheer gestart. Na mijn 2 jarige opleiding ben ik gestart als Netwerk beheerder. En omdat ik er geen genoeg van kreeg ben ik nu een systeem en netwerkbeheerder.</p> <p>Naast mijn enorme intresse in IT ga ik ook nog muurklimmen. Dat brengt me helemaal tot rust.</p>"},{"location":"about/cowarol/#carriere","title":"Carriere","text":"<p>Mijn professionele reis begon als netwerkbeheerder bij de Cronos Group, waar ik gedurende de eerste twee jaar waardevolle ervaringenen opdeed in het beheer en de optimalisatie van netwerkinfrastructuren. Deze rol stelde me in staat om diepgaande kennis op te bouwen van netwerkconfiguraties, beveiligingsprotocollen en het oplossen van netwerkgerelateerde problemen. Ik werkte nauw samen met diverse teams om ervoor te zorgen dat onze netwerksystemen altijd optimaal presteerden en betrouwbaar waren. Tijdens deze periode heb ik uitgebreide ervaringen opgedaan met netwerkapparatuur en -technologie\u00ebn van gerenommeerde leveranciers zoals Cisco, FortiGate en Palo Alto, wat mijn kennis en vaardigheden op het gebied van netwerkbeveiliging en -beheer aanzienlijk heeft vergroot.</p> <p>Na deze twee jaar besloot ik een nieuwe richting in te slaan binnen de IT-sector en maakte ik de overstap naar systeembeheer. In mijn huidige functie houd ik me voornamelijk bezig met het bieden van support voor Microsoft-producten, waarbij ik me specialiseer in Azure. Dit cloud computing-platform heeft mijn interesse gewekt vanwege de vele mogelijkheden en de flexibiliteit die het biedt aan bedrijven van alle groottes.</p>"},{"location":"apps/","title":"App list","text":""},{"location":"apps/#analytics","title":"Analytics","text":"<p>Category Feed URL</p> Project Repository Feed Matomo matomo-org/matomo RSS Link Plausible plausible/analytics RSS Link Umami umami-software/umami RSS Link"},{"location":"apps/#automation","title":"Automation","text":"<p>Category Feed URL</p> Project Repository Feed Czkawka qarmin/czkawka RSS Link feed2toot chaica/feed2toot RSS Link Huginn huginn/huginn RSS Link LazyLibrarian LazyLibrarian/LazyLibrarian RSS Link Lidarr Lidarr/Lidarr RSS Link LunaSea JagandeepBrar/lunasea RSS Link Medusa pymedusa/Medusa RSS Link Node-RED node-red/node-red RSS Link Plex Meta Manager meisnate12/Plex-Meta-Manager RSS Link Podgrab akhilrex/podgrab RSS Link Radarr Radarr/Radarr RSS Link Sonarr Sonarr/Sonarr RSS Link Subvert aschmelyun/subvert RSS Link Tube Archivist tubearchivist/tubearchivist RSS Link YouTubeDL-Material Tzahi12345/YoutubeDL-Material RSS Link"},{"location":"apps/#blogging-and-content-management","title":"Blogging and Content Management","text":"<p>Category Feed URL</p> Project Repository Feed Chyrp Lite xenocrat/chyrp-lite RSS Link Gatsby gatsbyjs/gatsby RSS Link Ghost TryGhost/Ghost RSS Link Hugo gohugoio/hugo RSS Link Jekyll jekyll/jekyll RSS Link WordPress WordPress/WordPress RSS Link WriteFreely writefreely/writefreely RSS Link"},{"location":"apps/#bookmarks-and-link-sharing","title":"Bookmarks and Link Sharing","text":"<p>Category Feed URL</p> Project Repository Feed LinkAce Kovah/LinkAce RSS Link linkding sissbruecker/linkding RSS Link Linkwarden linkwarden/linkwarden RSS Link Pinry pinry/pinry RSS Link Shaarli shaarli/Shaarli RSS Link Shiori go-shiori/shiori RSS Link xBrowserSync xbrowsersync/app RSS Link"},{"location":"apps/#calendar-and-contacts","title":"Calendar and Contacts","text":"<p>Category Feed URL</p> Project Repository Feed AgenDAV agendav/agendav RSS Link Baikal sabre-io/Baikal RSS Link Bloben nibdo/bloben-app RSS Link DAViCal davical-project/davical RSS Link EteSync etesync/server RSS Link Radicale Kozea/Radicale RSS Link sabre/dav sabre-io/dav RSS Link"},{"location":"apps/#communication","title":"Communication","text":"<p>Category Feed URL</p> Project Repository Feed Chirpy devrsi0n/chirpy RSS Link Commento commento/commento RSS Link Dendrite matrix-org/dendrite RSS Link Discourse discourse/discourse RSS Link GoToSocial superseriousbusiness/gotosocial RSS Link HumHub humhub/humhub RSS Link kbin ernestwisniewski/kbin RSS Link Lemmy LemmyNet/lemmy RSS Link Mastodon mastodon/mastodon RSS Link Mattermost mattermost/mattermost RSS Link Mumble mumble-voip/mumble RSS Link Pixelfed pixelfed/pixelfed RSS Link Rocket.Chat RocketChat/Rocket.Chat RSS Link SimpleX Chat simplex-chat/simplex-chat RSS Link Snikket snikket-im/snikket-server RSS Link Synapse matrix-org/synapse RSS Link"},{"location":"apps/#dashboards","title":"Dashboards","text":"<p>Category Feed URL</p> Project Repository Feed Dashy Lissy93/dashy RSS Link Flame pawelmalak/flame RSS Link Heimdall linuxserver/Heimdall RSS Link Homarr ajnart/homarr RSS Link Homer bastienwirtz/homer RSS Link miniboard aceberg/miniboard RSS Link Organizr causefx/Organizr RSS Link Your Spotify Yooooomi/your_spotify RSS Link"},{"location":"apps/#database-management","title":"Database Management","text":"<p>Category Feed URL</p> Project Repository Feed Baserow baserow/baserow RSS Link MySQL mysql/mysql-server RSS Link Nextcloud Tables nextcloud/tables RSS Link NocoDB nocodb/nocodb RSS Link PostgreSQL postgres/postgres RSS Link undb undb-xyz/undb RSS Link"},{"location":"apps/#document-management","title":"Document Management","text":"<p>Category Feed URL</p> Project Repository Feed Docspell eikek/docspell RSS Link Paperless-ngx paperless-ngx/paperless-ngx RSS Link Papermerge ciur/papermerge RSS Link SheetAble SheetAble/SheetAble RSS Link Stirling-PDF Frooodle/Stirling-PDF RSS Link"},{"location":"apps/#ebooks","title":"Ebooks","text":"<p>Category Feed URL</p> Project Repository Feed Calibre-Web janeczku/calibre-web RSS Link Kavita Kareadita/Kavita RSS Link Komga gotson/komga RSS Link"},{"location":"apps/#e-commerce","title":"E-commerce","text":"<p>Category Feed URL</p> Project Repository Feed EverShop evershopcommerce/evershop RSS Link Medusa (Commerce) medusajs/medusa RSS Link WooCommerce woocommerce/woocommerce RSS Link"},{"location":"apps/#e-mail","title":"E-mail","text":"<p>Category Feed URL</p> Project Repository Feed AnonAddy anonaddy/anonaddy RSS Link Dovecot dovecot/core RSS Link Keila pentacent/keila RSS Link Mail4one mail4one/mail4one RSS Link Mailcow mailcow/mailcow-dockerized RSS Link Mail-in-a-Box mail-in-a-box/mailinabox RSS Link Mailu Mailu/Mailu RSS Link Mautic mautic/mautic RSS Link Postal postalserver/postal RSS Link Roundcube roundcube/roundcubemail RSS Link"},{"location":"apps/#feed-readers","title":"Feed Readers","text":"<p>Category Feed URL</p> Project Repository Feed FreshRSS FreshRSS/FreshRSS RSS Link Kill-the-Newsletter leafac/kill-the-newsletter RSS Link Miniflux miniflux/v2 RSS Link Newsblur samuelclay/NewsBlur RSS Link RSS (Dan Brown) ssddanbrown/rss RSS Link RSS-Bridge RSS-Bridge/rss-bridge RSS Link yarr nkanaev/yarr RSS Link"},{"location":"apps/#file-transfer-and-sync","title":"File Transfer and Sync","text":"<p>Category Feed URL</p> Project Repository Feed FileBrowser filebrowser/filebrowser RSS Link Filestash mickael-kerjean/filestash RSS Link Nextcloud nextcloud/server RSS Link ownCloud owncloud/core RSS Link PairDrop schlagmichdoch/PairDrop RSS Link ProjectSend projectsend/projectsend RSS Link Seafile haiwen/seafile RSS Link SFTPGo drakkan/sftpgo RSS Link Syncthing syncthing/syncthing RSS Link xBackBone SergiX44/XBackBone RSS Link"},{"location":"apps/#identity-management","title":"Identity Management","text":"<p>Category Feed URL</p> Project Repository Feed Authelia authelia/authelia RSS Link Authentik goauthentik/authentik RSS Link Keycloak keycloak/keycloak RSS Link lldap lldap/lldap RSS Link nforwardauth NOSDuco/nforwardauth RSS Link"},{"location":"apps/#internet-of-things","title":"Internet of Things","text":"<p>Category Feed URL</p> Project Repository Feed Home Assistant - Core home-assistant/core RSS Link Home Assistant - OS home-assistant/operating-system RSS Link"},{"location":"apps/#inventory-management","title":"Inventory Management","text":"<p>Category Feed URL</p> Project Repository Feed Homebox hay-kot/homebox RSS Link"},{"location":"apps/#media-streaming","title":"Media Streaming","text":"<p>Category Feed URL</p> Project Repository Feed AudioBookshelf advplyr/audiobookshelf RSS Link Dim Dusk-Labs/dim RSS Link Fireshare ShaneIsrael/fireshare RSS Link Invidious iv-org/invidious RSS Link Jellyfin jellyfin/jellyfin RSS Link MediaCMS mediacms-io/mediacms RSS Link Navidrome navidrome/navidrome RSS Link Owncast owncast/owncast RSS Link PeerTube Chocobozzz/PeerTube RSS Link Playlet iBicha/playlet RSS Link RomM zurdi15/romm RSS Link Tautulli Tautulli/Tautulli RSS Link"},{"location":"apps/#miscellaneous","title":"Miscellaneous","text":"<p>Category Feed URL</p> Project Repository Feed Libreddit libreddit/libreddit RSS Link LinkStack LinkStackOrg/LinkStack RSS Link Monica monicahq/monica RSS Link Ombi Ombi-app/Ombi RSS Link Overseerr sct/overseerr RSS Link Petio petio-team/petio RSS Link Serge serge-chat/serge RSS Link wallabag wallabag/wallabag RSS Link"},{"location":"apps/#mobile","title":"Mobile","text":"<p>Category Feed URL</p> Project Repository Feed Abacus victorbalssa/abacus RSS Link Aegis beemdevelopment/Aegis RSS Link Aegis Icons aegis-icons/aegis-icons RSS Link Endless kaangiray26/endless RSS Link Obtainium ImranR98/Obtainium RSS Link Openreads mateusz-bak/openreads-android RSS Link Syncthing-Fork Catfriend1/syncthing-android RSS Link Tempo CappielloAntonio/tempo RSS Link"},{"location":"apps/#money-and-budgeting","title":"Money and Budgeting","text":"<p>Category Feed URL</p> Project Repository Feed Actual Budget actualbudget/actual-server RSS Link Firefly III firefly-iii/firefly-iii RSS Link Invoice Ninja invoiceninja/invoiceninja RSS Link"},{"location":"apps/#monitoring","title":"Monitoring","text":"<p>Category Feed URL</p> Project Repository Feed AdGuardian-Term Lissy93/AdGuardian-Term RSS Link ChangeDetection.io dgtlmoon/changedetection.io RSS Link Uptime-Kuma louislam/uptime-kuma RSS Link"},{"location":"apps/#note-taking","title":"Note-Taking","text":"<p>Category Feed URL</p> Project Repository Feed HedgeDoc hedgedoc/hedgedoc RSS Link Joplin laurent22/joplin RSS Link memos usememos/memos RSS Link Trilium zadam/trilium RSS Link"},{"location":"apps/#notifications","title":"Notifications","text":"<p>Category Feed URL</p> Project Repository Feed Apprise caronc/apprise RSS Link Gotify gotify/server RSS Link ntfy binwiederhier/ntfy RSS Link"},{"location":"apps/#password-managers","title":"Password Managers","text":"<p>Category Feed URL</p> Project Repository Feed Bitwarden bitwarden/server RSS Link Vaultwarden dani-garcia/vaultwarden RSS Link"},{"location":"apps/#pastebins","title":"Pastebins","text":"<p>Category Feed URL</p> Project Repository Feed MicroBin szabodanika/microbin RSS Link PrivateBin PrivateBin/PrivateBin RSS Link"},{"location":"apps/#photo-and-video-galleries","title":"Photo and Video Galleries","text":"<p>Category Feed URL</p> Project Repository Feed Chevereto chevereto/chevereto RSS Link Immich immich-app/immich RSS Link LibrePhotos LibrePhotos/librephotos RSS Link Lychee LycheeOrg/Lychee RSS Link Memories pulsejet/memories RSS Link Photofield SmilyOrg/photofield RSS Link PhotoPrism photoprism/photoprism RSS Link Photoview photoview/photoview RSS Link PiGallery2 bpatrik/pigallery2 RSS Link Piwigo Piwigo/Piwigo RSS Link"},{"location":"apps/#polls-and-events","title":"Polls and Events","text":"<p>Category Feed URL</p> Project Repository Feed docassemble jhpyle/docassemble RSS Link LimeSurvey LimeSurvey/LimeSurvey RSS Link Meetable aaronpk/Meetable RSS Link OhMyForm ohmyform/ohmyform RSS Link Rallly lukevella/rallly RSS Link"},{"location":"apps/#recipe-management","title":"Recipe Management","text":"<p>Category Feed URL</p> Project Repository Feed Grocy grocy/grocy RSS Link KitchenOwl TomBursch/kitchenowl RSS Link Mealie hay-kot/mealie RSS Link Tandoor Recipes TandoorRecipes/recipes RSS Link"},{"location":"apps/#search-engines","title":"Search Engines","text":"<p>Category Feed URL</p> Project Repository Feed searx searx/searx RSS Link Whoogle benbusby/whoogle-search RSS Link"},{"location":"apps/#server-management","title":"Server Management","text":"<p>Category Feed URL</p> Project Repository Feed Cosmos azukaar/cosmos-Server RSS Link Dockcheck mag37/dockcheck RSS Link LeGo CertHub gregtwallace/legocerthub RSS Link OPNsense opnsense/core RSS Link Portainer portainer/portainer RSS Link Sshwifty nirui/sshwifty RSS Link UltimateHomeServer TechSquidTV/UltimateHomeServer RSS Link umbrelOS getumbrel/umbrel RSS Link Yacht SelfhostedPro/Yacht RSS Link"},{"location":"apps/#software-development","title":"Software Development","text":"<p>Category Feed URL</p> Project Repository Feed code-server coder/code-server RSS Link Gitea go-gitea/gitea RSS Link GitLab gitlab-org/gitlab-foss RSS Link"},{"location":"apps/#tasks-and-to-do-lists","title":"Tasks and To-Do Lists","text":"<p>Category Feed URL</p> Project Repository Feed Kanboard kanboard/kanboard RSS Link"},{"location":"apps/#url-shorteners","title":"URL Shorteners","text":"<p>Category Feed URL</p> Project Repository Feed Lynx Lynx-Shortener/Lynx RSS Link Shlink shlinkio/shlink RSS Link YOURLS YOURLS/YOURLS RSS Link"},{"location":"apps/#video-conferencing","title":"Video Conferencing","text":"<p>Category Feed URL</p> Project Repository Feed Jitsi Meet jitsi/jitsi-meet RSS Link MiroTalk C2C miroslavpejic85/mirotalkc2c RSS Link MiroTalk P2P miroslavpejic85/mirotalk RSS Link MiroTalk SFU miroslavpejic85/mirotalksfu RSS Link"},{"location":"apps/#vpn-remote-access","title":"VPN / Remote Access","text":"<p>Category Feed URL</p> Project Repository Feed Headscale juanfont/headscale RSS Link MeshCentral Ylianst/MeshCentral RSS Link NetBird netbirdio/netbird RSS Link Tailscale tailscale/tailscale RSS Link"},{"location":"apps/#web-servers","title":"Web Servers","text":"<p>Category Feed URL</p> Project Repository Feed Caddy caddyserver/caddy RSS Link Cloudflared cloudflare/cloudflared RSS Link Nginx Proxy Manager NginxProxyManager/nginx-proxy-manager RSS Link"},{"location":"apps/#wikis","title":"Wikis","text":"<p>Category Feed URL</p> Project Repository Feed BookStack BookStackApp/BookStack RSS Link DokuWiki dokuwiki/dokuwiki RSS Link Outline outline/outline RSS Link Pepperminty Wiki sbrl/Pepperminty-Wiki RSS Link SilverBullet silverbulletmd/silverbullet RSS Link TiddlyWiki Jermolene/TiddlyWiki5 RSS Link Wiki.js requarks/wiki RSS Link"},{"location":"apps/authentik/","title":"Authentik","text":""},{"location":"apps/authentik/#authentik","title":"Authentik","text":""},{"location":"apps/authentik/#bypass-mfa-on-local-network","title":"Bypass MFA on Local Network","text":"<p>In this video, I demonstrate how to setup an expression policy to check if a client's IP address is local and if so, bypass 2-factor-authentication/multi-factor-authentication.</p>"},{"location":"apps/authentik/#password-recovery-flow-setup","title":"Password Recovery Flow Setup","text":"<p>In this video I show how to create a flow in Authentik to allow users to reset their passwords via email.</p>"},{"location":"apps/crafty-controller/","title":"Crafty","text":""},{"location":"apps/crafty-controller/#crafty","title":"Crafty","text":""},{"location":"apps/crafty-controller/#wat-is-crafty","title":"Wat is Crafty","text":"<p>Crafty Controller is een webgebaseerde beheerinterface voor Minecraft-servers. Het biedt een eenvoudige manier om meerdere Minecraft-servers te beheren, inclusief start/stop-functionaliteit, automatische updates en monitoring.</p>"},{"location":"apps/crafty-controller/#belangrijkste-kenmerken","title":"\ud83c\udf1f Belangrijkste kenmerken:","text":"<ul> <li>\u2705 Webinterface \u2013 Beheer servers via een browser  </li> <li>\u2705 Meerdere servers \u2013 Ondersteuning voor verschillende Minecraft-instanties  </li> <li>\u2705 Automatische updates \u2013 Houdt serverbestanden up-to-date  </li> <li>\u2705 Logboek en monitoring \u2013 Houdt prestaties en fouten bij  </li> <li>\u2705 Gebruikersbeheer \u2013 Toegangscontrole voor meerdere beheerders  </li> </ul> <p>Handig voor zowel particuliere als professionele serverbeheerders! \ud83c\udfae\ud83d\ude80</p> <p>Note</p> <p>Dit kan je vergelijken met Prerodactyl maar dan enkel voor Minecraft server en een veel simpelere setup.</p>"},{"location":"apps/crafty-controller/#review","title":"Review","text":"<p>We hebben deze oplossing uitgebreid getest en zijn tot een evenwichtige conclusie gekomen. Voordelen</p> <ul> <li>Gebruiksgemak: De interface is intu\u00eftief en vereist weinig training</li> <li>Overzichtelijkheid: Alle belangrijke functies zijn logisch georganiseerd</li> <li>Snelheid: De responstijd is indrukwekkend</li> </ul> <p>Nadelen</p> <ul> <li>Beperkte vrijheid in de filemanager: het oploaden van folders is niet mogelijk.</li> </ul> <p>Ondanks de genoemde beperkingen biedt deze oplossing een uitstekende balans tussen functionaliteit en gebruiksgemak voor de meeste toepassingen.</p> <p>Warning</p> <p>De lokale webinterface werkt goed. Vanaf we dit via traefik laten verlopen zie ik toch dat wat problemen op treden.</p>"},{"location":"apps/crafty-controller/#intallatie","title":"Intallatie","text":""},{"location":"apps/crafty-controller/#lxc","title":"LXC","text":"<p>Wij hebben Crafty geinstalleerd in Proxmox met Dit script</p> <p>Na het runnen van dit script kan je direkt beginnen met servers aanmaken.</p>"},{"location":"apps/crafty-controller/#docker","title":"Docker","text":"<p>Warning</p> <p>Het nadeel van een Docker container is dat je de poorten zelf moet toevoegen aan het compose bestand. Dus zorg ervoor dat er genoeg poorten openstaan.</p> <p></p><pre><code>services:\n  crafty:\n    container_name: crafty_container\n    image: registry.gitlab.com/crafty-controller/crafty-4:latest\n    restart: always\n    environment:\n        - TZ=Etc/UTC\n    ports:\n        - \"8443:8443\" # HTTPS\n        - \"8123:8123\" # DYNMAP\n        - \"19132:19132/udp\" # BEDROCK\n        - \"25500-25600:25500-25600\" # MC SERV PORT RANGE\n    volumes:\n        - ./docker/backups:/crafty/backups\n        - ./docker/logs:/crafty/logs\n        - ./docker/servers:/crafty/servers\n        - ./docker/config:/crafty/app/config\n        - ./docker/import:/crafty/import\n</code></pre> Voer het compose bestand uit <pre><code>docker-compose up -d &amp;&amp; docker-compose logs -f\n</code></pre>"},{"location":"apps/crafty-controller/#update","title":"Update","text":"<pre><code>docker-compose pull &amp;&amp; docker-compose up -d\n</code></pre>"},{"location":"apps/crafty-controller/#reverse-proxy","title":"Reverse proxy","text":""},{"location":"apps/crafty-controller/#treafik","title":"Treafik","text":"<pre><code>http:\n  routers:\n    crafty:\n      rule: \"Host(`crafty.{{env \"DOMAINNAME_1\"}}`)\"\n      service: \"crafty\"\n      tls:\n        certResolver: dns-cloudflare\n        options: tls-opts@file\n  services:\n    crafty:\n      loadBalancer:\n        servers:\n          - url: \"https://172.16.7.8:8443\"\n        serversTransport: \"craftytransport\"\n  middlewares:\n    sslheader:\n      headers:\n        customRequestHeaders:\n          X-Forwarded-Proto: \"https\"\n  serversTransports:\n    craftytransport:\n      insecureSkipVerify: true\n</code></pre> Of <pre><code>labels:\n    - \"traefik.enable=true\"\n    # Router\n    - \"traefik.http.routers.crafty.rule=Host(`crafty.${DOMAINNAME_1}`)\"\n    - \"traefik.http.routers.crafty.tls.certresolver=dns-cloudflare\"\n    - \"traefik.http.routers.crafty.tls.options=tls-opts@file\"\n    - \"traefik.http.routers.crafty.service=crafty\"\n    # Service\n    - \"traefik.http.services.crafty.loadbalancer.server.port=8443\"\n    - \"traefik.http.services.crafty.loadbalancer.serverstransport=craftytransport\"\n    # Headers middleware\n    - \"traefik.http.middlewares.sslheader.headers.customrequestheaders.X-Forwarded-Proto=https\"\n    # Server Transport voor self-signed certificates\n    - \"traefik.http.servertransports.craftytransport.insecureskipverify=true\"\n</code></pre>"},{"location":"apps/fivem/","title":"Fivem","text":""},{"location":"apps/fivem/#fivem","title":"Fivem","text":"<p>Fivem is een modificatie voor Grand Theft Auto V waarmee je multiplayer kunt spelen op aangepaste servers, aangedreven door Cfx.re. Fivem maakt gebruik van de fxOM script runtimes, die verschillende programmeertalen ondersteunen, zoals Lua, C# en JavaScript. Fivem laat je toe om je eigen server te maken of deelnemen aan bestaande servers met verschillende spelmodi, zoals roleplay, racen, deathmatch en meer. Fivem heeft ook een uitgebreide documentatie voor ontwikkelaars die meer willen weten over de kernmechanismen van de modificatie.</p> <p></p>"},{"location":"apps/fivem/#installatie","title":"Installatie","text":"<p>Om Fivem te gebruiken, moet je het downloaden van de website en installeren op je computer . Je hebt ook een ge\u00efnstalleerde en bijgewerkte versie van GTA V nodig. Fivem verandert niets aan je GTA V installatie, dus je kunt zonder problemen wisselen tussen Fivem en GTA:O. Fivem heeft geen invloed op de Rockstar Online Services, dus je kunt niet geband worden voor het spelen van Fivem.</p>"},{"location":"apps/fivem/#systeem-vereisten","title":"Systeem vereisten","text":"<p>De systeemeisen voor Fivem zijn afhankelijk van de server waarop je speelt, maar over het algemeen zijn ze vergelijkbaar met die van GTA V.</p>"},{"location":"apps/fivem/#windows","title":"Windows","text":"<p>Voor Windows heb je minimaal nodig: - Intel Core 2 Q6600 @ 2.40GHz / AMD Phenom 9850 @ 2.5GHz CPU - NVIDIA 9800 GT 1GB / AMD HD 4870 1GB / Intel HD GT2 GPU - 8GB RAM - 72GB + ~4GB HDD</p>"},{"location":"apps/fivem/#linux","title":"Linux","text":"<p>Voor Linux heb je minimaal nodig: - Intel Core i3-3220 @ 3.30GHz / AMD FX-6300 @ 3.5GHz CPU - NVIDIA GeForce GT 710 / AMD Radeon HD 6450 GPU - 8GB RAM - 72GB + ~4GB HDD</p>"},{"location":"apps/fivem/#fivem-self-hosting","title":"Fivem self-hosting","text":"<p>Om Fivem uit te rollen met Docker, moet je eerst Docker installeren op je Linux machine. Daarna kun je de volgende stappen volgen:</p> <ol> <li>Maak een map aan voor je serverbestanden, bijvoorbeeld <code>~/fivem</code>.</li> <li>Download het <code>server-data</code> repository van GitHub naar je map:     <pre><code>git clone https://github.com/citizenfx/cfx-server-data.git ~/fivem/server-data\n</code></pre></li> <li> <p>Download het <code>server</code> bestand van de Fivem website naar je map:</p> <pre><code>wget https://runtime.fivem.net/artifacts/fivem/build_proot_linux/master/439-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx/server -O ~/fivem/server\n</code></pre> Laatste versie terugvinden <p>Via https://runtime.fivem.net/artifacts/fivem/build_proot_linux/master/ kan je de laatste versie terugvinden.</p> </li> <li> <p>Maak het <code>server</code> bestand uitvoerbaar:</p> <pre><code>chmod +x ~/fivem/server\n</code></pre> </li> <li> <p>Maak een <code>Dockerfile</code> aan in je map met de volgende inhoud:</p> <pre><code>FROM debian:stable-slim\nRUN apt-get update &amp;&amp; apt-get install -y curl xz-utils\nWORKDIR /opt/fivem\nCOPY server .\nCOPY server-data ./server-data\nEXPOSE 30120/tcp\nEXPOSE 30120/udp\nCMD [\"/opt/fivem/server\", \"+exec\", \"server.cfg\"]\n</code></pre> </li> <li> <p>Bouw de Docker image met het commando:</p> <pre><code>docker build -t fivem-server ~/fivem\n</code></pre> </li> <li> <p>Start de Docker ../container met het commando:     </p><pre><code>docker run -d --name fivem-server -p 30120:30120/tcp -p 30120:30120/udp fivem-server\n</code></pre> </li> <li> <p>Je kunt nu verbinding maken met je Fivem server via het <code>IP-adres</code> en de poort van je Linux machine.</p> </li> </ol>"},{"location":"apps/fivem/#download-laatste-fivem-artifacts","title":"Download laatste fivem artifacts","text":"<pre><code>wget https://runtime.fivem.net/artifacts/fivem/build_proot_linux/master/5878-a5c270439ddb3bbb1fc4e7d02cb5593be84a9b89/fx.tar.xz &amp;&amp; tar -xf fx.tar.xz --strip-components=1 --exclude alpine/dev --exclude alpine/proc --exclude alpine/run --exclude alpine/sys &amp;&amp; rm fx.tar.xz\n</code></pre>"},{"location":"apps/grafana/","title":"Grafana","text":""},{"location":"apps/grafana/#grafana","title":"Grafana","text":"<p>Grafana is een open-source observatieplatform voor het visualiseren van statistieken, logs en sporen die verzameld zijn van uw toepassingen. Het is een cloud-native oplossing voor het snel samenstellen van datadashboards waarmee u uw stack kunt inspecteren en analyseren. Grafana kan verbinding maken met verschillende gegevensbronnen zoals Prometheus, InfluxDB, ElasticSearch en traditionele relationele database-engines. Grafana heeft ook een ge\u00efntegreerde waarschuwingsoplossing om u te waarschuwen voor problemen als ze zich voordoen. U kunt Grafana zelf hosten op uw eigen hardware of gebruik maken van de beheerde Grafana Cloud-service.</p> <p></p>"},{"location":"apps/makeMKV/","title":"MakeMKV","text":""},{"location":"apps/makeMKV/#makemkv","title":"MakeMKV","text":"<p>MakeMKV is een programma dat je kunt gebruiken om video\u2019s die je bezit om te zetten naar een gratis en patentvrij formaat dat overal kan worden afgespeeld. MakeMKV is een formaatconverter, ook wel \u201ctranscoder\u201d genoemd. Het converteert videoclips van een eigen (en meestal versleutelde) schijf naar een set MKV-bestanden, waarbij de meeste informatie behouden blijft maar niet wordt gewijzigd. Het MKV-formaat kan meerdere video-/audiotracks met alle meta-informatie opslaan en hoofdstukken behouden. Er zijn veel spelers die MKV-bestanden op bijna alle platforms kunnen afspelen en er zijn hulpmiddelen om MKV-bestanden om te zetten naar vele formaten, waaronder DVD- en Blu-ray-schijven. Bovendien kan MakeMKV direct gedecodeerde video streamen zonder tussenconversie naar een breed scala aan spelers, zodat je Blu-ray- en DVD-schijven kunt bekijken met je favoriete speler op je favoriete besturingssysteem of op je favoriete apparaat.</p>"},{"location":"apps/makeMKV/#koppel-je-dvd-station","title":"Koppel je DVD station","text":""},{"location":"apps/makeMKV/#unraid","title":"Unraid","text":"<p>ALs je met unraid werkt kan je eenvoudig je DVD/Blue-ray speler koppelen aan je docker container. Dit doe je door eerst op te zoeken welke je DVD/Blue-ray station is. </p><pre><code>lsscsi\n</code></pre> Dan krijg je volgende output: <code>cd/dvd  TSSTcorp DVDWBD SH-B123L  SB02  /dev/sr0   /dev/sg5</code> . Hier zie je dat <code>/dev/sr0</code> je DVD station is. nu moet je nog zien welke  <p>Doe vervolgens in de <code>/dev</code> folder </p><pre><code>ls-l\n</code></pre> Dan krijg je een lijst en zoek je acheter <code>crw-rw---- 1 root cdrom    21,     3 Jun 13 14:23 sg3</code>. Nu zie je dat <code>/dev/sg3/</code> je CD rom station is. <p>Als laatste voeg je aan je container volgende parameter toe bij <code>Extra Parameters:``--device /dev/sr0 --device /dev/sg0</code></p>"},{"location":"apps/makeMKV/#proxmox","title":"Proxmox","text":"<p>Voor Proxmox zijn de stappen ongeveer hetzelfde. Maar eerste voer je volgende stappen uit op de Proxmox host. </p><pre><code>lsscsi -g\n</code></pre> Dan krijg je volgende output: <code>cd/dvd  TSSTcorp DVDWBD SH-B123L  SB02  /dev/sr0   /dev/sg5</code> . Hier zie je dat <code>/dev/sr0</code> je DVD station is. En hier zie je dat <code>/dev/sg5/</code> je CD rom station is. <p>Nu maak je eerst 2 Device passtrough aan in de LXC met de waardes van hier boven. Dit kan zowel via de GUI als via de cli van Proxmox </p><pre><code>nano /etc/pve/lxc/101.conf\ndev0: /dev/sr0,gid=0,mode=0666,uid=0\ndev1: /dev/sg5,gid=0,mode=0666,uid=0\n</code></pre> <p>Voege deze nu toe in onderstaande docker compose.</p> <pre><code>services:\n    makemkv:\n        container_name: makemkv\n        ports:\n            - 5800:5800\n        volumes:\n            - /docker/appdata/makemkv:/config:rw\n            - /home/user:/storage:ro\n            - /home/user/MakeMKV/output:/output:rw\n        devices:\n            - \"/dev/sr0:/dev/sr0\"\n            - \"/dev/sg5:/dev/sg5\"\n        image: jlesage/makemkv\n</code></pre>"},{"location":"apps/mkdocs/","title":"Mkdocs","text":""},{"location":"apps/mkdocs/#mkdocs","title":"Mkdocs","text":""},{"location":"apps/mkdocs/#vereisten","title":"Vereisten","text":"<pre><code>sudo apt install python3-pipis\n</code></pre>"},{"location":"apps/mkdocs/#installatie","title":"Installatie","text":"<ol> <li> <p>Installeer mkdocs (liefst in WSL of debian-based distro)</p> <pre><code>pip install mkdocs\n</code></pre> </li> <li> <p>Installeer de requirements</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> </ol> <p>Note</p> <pre><code>Deze commando's moeten uiteraard in de root-folder van het project uitgevoerd worden.\n</code></pre> <ol> <li> <p>Serve de website lokaal</p> <pre><code>mkdocs serve\n</code></pre> </li> </ol>"},{"location":"apps/mkdocs_material/","title":"Getting started","text":""},{"location":"apps/mkdocs_material/#getting-started","title":"Getting started","text":"<p>Url: https://pypi.org/project/mkdocs-material/</p> <p>Material for Mkdocs is een thema voor Mkdocs, een statische site generator die gericht is op (technische) projectdocumentatie. Met Material for Mkdocs kun je je documentatie schrijven in Markdown en een professionele statische site maken in enkele minuten - doorzoekbaar, aanpasbaar, voor alle apparaten. Je kunt Material for Mkdocs installeren met pip, de Python package manager, of met docker.</p>"},{"location":"apps/mkdocs_material/#installatie","title":"Installatie","text":""},{"location":"apps/mkdocs_material/#met-pip","title":"Met <code>pip</code>","text":"<p>Material for MkDocs wordt gepubliceerd als een Python package en kan worden ge\u00efnstalleerd met <code>pip</code>, idealiter door gebruik te maken van een virtual environment. Open een terminal en installeer Material for MkDocs met:</p> <pre><code>pip install mkdocs-material\n</code></pre> <p>Note</p> <p>Dit zal automatisch compatibele versies van alle afhankelijkheden installeren: [MkDocs], [Markdown], [Pygments] en [Python Markdown Extensions]. Material for MkDocs streeft er altijd naar om de nieuwste versies te ondersteunen, dus het is niet nodig om die pakketten apart te installeren.</p>"},{"location":"apps/mkdocs_material/#met-docker","title":"Met docker","text":"<p>De offici\u00eble [Docker image] is een geweldige manier om snel aan de slag te gaan, want het bevat alle afhankelijkheden die vooraf ge\u00efnstalleerd zijn. Open een terminal en haal de image op met:</p> <pre><code>docker pull squidfunk/mkdocs-material\n</code></pre> <p>Het <code>mkdocs</code> uitvoerbaar bestand wordt aangeboden als een entry point en <code>serve</code> is het standaard commando.</p> How to add plugins to the Docker image? <p>Material for MkDocs bundelt alleen geselecteerde plugins om de grootte van de offici\u00eble image klein te houden. Als de plugin die je wilt gebruiken niet is inbegrepen, maak dan een nieuw <code>Dockerfile</code> aan en breid de offici\u00eble Docker image uit:</p> <pre><code>FROM squidfunk/mkdocs-material\nRUN pip install ...\n</code></pre> <p>Vervolgens kun je de image bouwen met het volgende commando:</p> <pre><code>docker build -t squidfunk/mkdocs-material .\n</code></pre> <p>De nieuwe image kan precies zo worden gebruikt als de offici\u00eble image.</p>"},{"location":"apps/mkdocs_material/#met-git","title":"met git","text":"<p>Material for MkDocs kan direct gebruikt worden vanaf GitHub door de repository te klonen naar een submap van je project root. Dit kan handig zijn als je de nieuwste versie wilt gebruiken:</p> <pre><code>git clone https://github.com/squidfunk/mkdocs-material.git\n</code></pre> <p>Het thema bevindt zich in de map <code>mkdocs-material/material</code>. Na het klonen van <code>git</code>, moet je alle vereiste afhankelijkheden installeren met:</p> <pre><code>pip install -e mkdocs-material\n</code></pre>"},{"location":"apps/moonlight/","title":"Moonlight","text":""},{"location":"apps/moonlight/#moonlight","title":"Moonlight","text":"<p>Moonlight Panel is een gratis en open-source hostingpaneel dat is ontworpen om het beheer van game- en webservers te vereenvoudigen. Het biedt een snelle en responsieve gebruikersinterface, ondersteund door een effici\u00ebnte backend, waardoor gebruikers meer controle hebben over de gehoste diensten. Moonlight Panel</p> <p>Belangrijke kenmerken van Moonlight Panel zijn:</p> <ul> <li>Plugin- en functiesysteem: Maakt het mogelijk om het paneel aan te passen en workflows te optimaliseren.</li> <li>Virtuele schijven: Beschermt tegen exploits die proberen de harde schijf van de server te beschadigen.</li> <li>Priv\u00e9netwerken: Isoleert subservers en kritieke API's zonder complexe firewallconfiguraties.</li> <li>Rechtenbeheer: Biedt gedetailleerde controle over de acties die beheerders kunnen uitvoeren.</li> <li>Diagnosesysteem: Helpt bij het snel identificeren en oplossen van problemen.</li> </ul> <p>Moonlight Panel</p> <p>Moonlight Panel is volledig on-premise, wat betekent dat alle gegevens en diensten binnen uw eigen infrastructuur blijven. Het project is oorspronkelijk ontwikkeld voor Endelon Hosting en is nu een onafhankelijk project met als doel een alles-in-\u00e9\u00e9n oplossing te bieden voor hostingbedrijven en gemeenschappen.</p> <p>Info</p> <p>Dit is een heel goed alternatief voor Pterodactyl. En ja kan de Pterodactyl Eggs hier ook gebruiken.</p>"},{"location":"apps/moonlight/#installatie","title":"Installatie","text":""},{"location":"apps/moonlight/#requirements","title":"Requirements","text":"<ul> <li>An Ubuntu Linux server</li> <li>The ability to run Docker</li> <li>4 GB of memory (recommended; can work with less)</li> <li>20GB of disk space</li> <li>2 Cores</li> </ul>"},{"location":"apps/moonlight/#installeren","title":"Installeren","text":""},{"location":"apps/moonlight/#panel","title":"Panel","text":"<p>In de huidge release hebben ze nog geen Docker compose file. voer het volgde uit: </p><pre><code>bash &lt;(curl https://get-moonlight.app)\n</code></pre> Als het bovenstaande niet werkt: <pre><code>curl -o moonlight-installer.sh https://get-moonlight.app\nchmod +x moonlight-installer.sh\nsudo ./moonlight-installer.sh\n</code></pre> Tijdens de installatie sellecteer je: Moonlight Panel \u2192 Install <p>En volg de standaard instellingen</p> <p>Als ales doorlopen is voer je het volgende uit: </p><pre><code>mlcli moonlight login\n</code></pre> <p>Note</p> <p>Alls je de login niet ziet doe je: </p><pre><code>mlcli moonlight logs\n</code></pre> <p>Nu kan je via het \"ip+port\" aan de webinterface en aanmelden.</p>"},{"location":"apps/moonlight/#node","title":"Node","text":"<p>Open het admin panel en ga naar Servers =&gt; Nodes. Maak nu een node aan. Als je node hebt aangemaakt bewerk je de node en ga je naar \"setup\". Nu kopieer het commando en plak je dit op dezelfde of de desbetreffende server. En volg de stappen die gevraagd worden.</p>"},{"location":"apps/moonlight/#configuratie","title":"Configuratie","text":""},{"location":"apps/moonlight/#allocations","title":"Allocations","text":"<p>Maak nu zoals bij Pterodactyl allocations aan onder Server \u2192 nodes \u2192 node \u2192 allocations</p> <p>Note</p> <p>Ja mag het ip op 0.0.0.0 zetten en de juiste poort(en).</p>"},{"location":"apps/moonlight/#images-eggs","title":"Images/ Eggs","text":"<p>Deze Importeer je alle 2 onder servers \u2192 images.</p> <p>Warning</p> <p>Vergeet voor of na het importeren van de Images/Eggs zeker niet de juiste poort Allocations te doen.</p> <p>Image</p> <p>Een image is een vooraf geconfigureerde besturingssysteemomgeving die als basis dient voor een server. Dit kan een Docker-image of een VM-image zijn. In hostingpanels wordt vaak Docker gebruikt, en een Docker-image bevat alles wat nodig is om een applicatie uit te voeren, zoals het besturingssysteem, bibliotheken en afhankelijkheden.</p> <p>Voorbeeld: Een Minecraft-server image kan een vooraf geconfigureerde versie van een Minecraft-server bevatten, zodat deze snel en consistent kan worden gedraaid binnen een container.</p> <p>Egg</p> <p>Een egg is een configuratiebestand of sjabloon dat wordt gebruikt binnen hostingpanels zoals Pterodactyl en Moonlight Panel om servers in te stellen. Een egg bevat instructies zoals:</p> <ul> <li>Welke Docker-image moet worden gebruikt</li> <li>Welke opstartparameters en milieuvariabelen nodig zijn</li> <li>Welke poorttoewijzingen vereist zijn</li> <li>Welke bestanden en mappen worden gebruikt</li> </ul> <p>Voorbeeld: Een Minecraft Egg bepaalt welke versie van Minecraft wordt ge\u00efnstalleerd, welke poorten worden geopend, en welke startup-opdrachten worden uitgevoerd. Samengevat</p> <ul> <li>Image: De complete serveromgeving (bijv. een Docker-image met het OS en basissoftware).</li> <li>Egg: Een configuratiebestand dat bepaalt hoe een server wordt ingesteld en beheerd binnen een hostingpanel.</li> </ul>"},{"location":"apps/moonlight/#images","title":"Images","text":"<p>Deze kan kan je terug vinden in hun Discord server</p>"},{"location":"apps/moonlight/#eggs","title":"Eggs","text":"<p>De bestaande Pterodactyl Eggs die je kan vinden.</p> <p>Warning</p> <p>Het kan zijn dat niet alle Eggs compatieble zijn.</p>"},{"location":"apps/moonlight/#review","title":"Review","text":"<p>Na het uitgebreid testen van deze service. Raad ik deze aan alle mensen aan die een hosting service thuis willen draaien. Je hebt alle vrijheid en een makkelijke setup. In de volgende release komt ook een Docker Compose voor nog meer vrijheid. De support is ook snel en goed.</p>"},{"location":"apps/nginx/","title":"Nginx","text":""},{"location":"apps/nginx/#nginx","title":"Nginx","text":"<p>Open source web and application server.</p> <p>Project Homepage: Nginx Homepage Documentation: Nginx Unit Docs</p>"},{"location":"apps/nginx/#basic-configuration-arguments-and-examples","title":"Basic configuration arguments and examples","text":"<p>Logging and debugging:</p> <pre><code>error_log &lt;file&gt; &lt;loglevel&gt;\n    error_log logs/error.log;\n    error_log logs/debug.log debug;\n    error_log logs/error.log notice;\n</code></pre> <p>basic listening ports:</p> <pre><code>listen &lt;port&gt; &lt;options&gt;\n        listen 80;\n        listen 443 ssl http2;\n        listen 443 http3 reuseport; (this is experimental!)\n</code></pre> <p>header modifcations: </p><pre><code>add_header &lt;header&gt; &lt;values&gt;\n        add_header Alt-svc '$http3=\":&lt;port&gt;\"; ma=&lt;value&gt;'; (this is experimental!)\n\nssl_certificate / ssl_certificate_key\n        ssl_certificate cert.pem;\n        ssl_certificate_key cert.key;\n\nserver_name &lt;domains&gt;\n    server_name domain1.com *.domain1.com\n\nroot &lt;folder&gt;\n    root /var/www/html/domain1;\n\nindex &lt;file&gt;\n    index index.php;\n\nlocation &lt;url&gt; {\n}\n    location / {\n        root index.html;\n        index index.html index.htm;\n    }\n    location / {\n        try_files $uri $uri/ /index.php$is_args$args;\n    }\n    location ~ \\\\.php$ {\n        fastcgi_pass 127.0.0.1:9000;\n        fastcgi_index index.php;\n        fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n        include fastcgi_params;\n    }\n    location ~ /\\\\.ht {\n        deny all;\n    }\n    location = /favicon.ico {\n        log_not_found off;\n        access_log off;\n    }\n    location = /robots.txt {\n        log_not_found off;\n        access_log off;\n        allow all;\n    }\n    location ~* .(css|gif|ico|jpeg|jpg|js|png)$ {\n        expires max;\n        log_not_found off;\n}\n</code></pre>"},{"location":"apps/nginx/#reverse-proxy","title":"Reverse Proxy","text":""},{"location":"apps/nginx/#show-clients-real-ip","title":"Show Client's real IP","text":"<pre><code>server {\n    server_name example.com;\n    location / { \n        proxy_pass http://localhost:4000;\n\n        # Show clients real IP behind a proxy\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre>"},{"location":"apps/npm/","title":"Installeer node.js &amp; npm op Ubuntu","text":""},{"location":"apps/npm/#installeer-nodejs-npm-op-ubuntu","title":"Installeer node.js &amp; npm op Ubuntu","text":"<pre><code>sudo apt update\nsudo apt install nodejs npm\n</code></pre>"},{"location":"apps/portainer/","title":"Portainer","text":""},{"location":"apps/portainer/#portainer","title":"Portainer","text":"<p>Portainer is een populaire Docker UI die u helpt om uw containers, images, volumes en netwerken te visualiseren. Portainer helpt u om de controle te nemen over de Docker-bronnen op uw machine, zonder lange terminalcommando\u2019s. Portainer heeft onlangs versie 2.0 bereikt die ondersteuning toevoegde voor Kubernetes-clusters. Het hulpmiddel ondersteunt ook Docker Swarm en Azure ACI-omgevingen1. U kunt Portainer zelf hosten op uw eigen hardware of gebruik maken van de beheerde Portainer Business-service.</p> <p></p>"},{"location":"apps/prometheus/","title":"Prometheus","text":""},{"location":"apps/pterodactyl/","title":"Pterodactyl","text":""},{"location":"apps/pterodactyl/#pterodactyl","title":"Pterodactyl","text":""},{"location":"apps/pterodactyl/#wat-is-pterodactyl","title":"Wat is pterodactyl","text":"<p>Pterodactyl is een open-source game server management paneel dat is gebouwd voor Docker-containers. Het stelt gebruikers in staat om game- en applicatieservers eenvoudig te beheren via een webinterface. Belangrijke kenmerken van Pterodactyl:</p> <ul> <li>Webinterface: Intu\u00eftief dashboard om servers te beheren.</li> <li>Docker-gebaseerd: Elke game server draait ge\u00efsoleerd in een container.</li> <li>Ondersteuning voor meerdere games: Werkt met Minecraft, CS:GO, Rust, ARK, FiveM en meer.</li> <li>Gebruikersbeheer: Mogelijkheid om meerdere gebruikers toegang te geven tot specifieke servers.</li> <li>API-integratie: Automatisering en integratie met andere systemen.</li> <li>Veiligheid: Runs als een niet-root gebruiker en gebruikt Wings als de daemon om servers te beheren.</li> </ul> <p>Wil je Pterodactyl gebruiken om zelf game servers te hosten? \ud83d\ude80</p>"},{"location":"apps/pterodactyl/#installatie","title":"Installatie","text":""},{"location":"apps/pterodactyl/#panel","title":"Panel","text":"<p>Hieronder vind u de 2 docker compose Files:</p> Configuratie bestanden <p>Warning</p> <p>Vergeet niet alle gegevens naar die van jou te veranderen!!</p> <p>Note</p> <p>https://github.com/pterodactyl/panel/blob/1.0-develop/docker-compose.example.yml https://github.com/pterodactyl/wings/blob/develop/docker-compose.example.yml</p> pterodactyl-panel.ymlpterodactyl-wings.yml.env <pre><code>x-common:\ndatabase:\n    &amp;db-environment\n    # Do not remove the \"&amp;db-password\" from the end of the line below, it is important\n    # for Panel functionality.\n    MYSQL_PASSWORD: &amp;db-password \"MYSQL_PASSWORD\"\n    MYSQL_ROOT_PASSWORD: \"$MYSQL_ROOT_PASSWORD\"\npanel:\n    &amp;panel-environment\n    APP_URL: \"$APP_URL\"\n    # A list of valid timezones can be found here: http://php.net/manual/en/timezones.php\n    APP_TIMEZONE: \"$TZ\"\n    APP_SERVICE_AUTHOR: \"$APP_SERVICE_AUTHOR\"\n    # Uncomment the line below and set to a non-empty value if you want to use Let's Encrypt\n    # to generate an SSL certificate for the Panel.\n    # LE_EMAIL: \"\"\nmail:\n    &amp;mail-environment\n    MAIL_FROM: \"noreply@example.com\"\n    MAIL_DRIVER: \"smtp\"\n    MAIL_HOST: \"mail\"\n    MAIL_PORT: \"1025\"\n    MAIL_USERNAME: \"\"\n    MAIL_PASSWORD: \"\"\n    MAIL_ENCRYPTION: \"true\"\n\n#\n# ------------------------------------------------------------------------------------------\n# DANGER ZONE BELOW\n#\n# The remainder of this file likely does not need to be changed. Please only make modifications\n# below if you understand what you are doing.\n#\nservices:\ndatabase:\n    image: mariadb:10.5\n    container_name: maridb\n    restart: always\n    command: --default-authentication-plugin=mysql_native_password\n    volumes:\n    - \"$PTERODACTYLDIR/panel/database:/var/lib/mysql\"\n    environment:\n    &lt;&lt;: *db-environment\n    MYSQL_DATABASE: \"$MYSQL_DATABASE\"\n    MYSQL_USER: \"$MYSQL_USER\"\ncache:\n    image: redis:alpine\n    container_name: cache\n    restart: always\npanel:\n    image: ghcr.io/pterodactyl/panel:latest\n    container_name: panel\n    restart: always\n    ports:\n    - \"${PTERODACTYLPANELPORTS_HTTP:-80}:80\"\n    - \"${PTERODACTYLPANELPORTS_HTTPS:-443}:443\"\n    links:\n    - database\n    - cache\n    volumes:\n    - \"$PTERODACTYLDIR/panel/var/:/app/var/\"\n    - \"$PTERODACTYLDIR/panel/nginx/:/etc/nginx/http.d/\"\n    - \"$PTERODACTYLDIR/panel/certs/:/etc/letsencrypt/\"\n    - \"$PTERODACTYLDIR/panel/logs/:/app/storage/logs\"\n    environment:\n    &lt;&lt;: [*panel-environment, *mail-environment]\n    DB_PASSWORD: *db-password\n    APP_ENV: \"$APP_ENV\"\n    APP_ENVIRONMENT_ONLY: \"false\"\n    CACHE_DRIVER: \"redis\"\n    SESSION_DRIVER: \"redis\"\n    QUEUE_DRIVER: \"redis\"\n    REDIS_HOST: \"cache\"\n    DB_HOST: \"database\"\n    DB_PORT: \"3306\"\nnetworks:\ndefault:\n    ipam:\n    config:\n        - subnet: 172.20.0.0/16\n</code></pre> <pre><code>services:\nwings:\n    image: ghcr.io/pterodactyl/wings:latest\n    container_name: wing1\n    restart: always\n    networks:\n    - wings0\n    ports:\n    - \"${PTERODACTYLNODE1_PORTS_HTTP:-8080}:8080\"\n    - \"${PTERODACTYLNODE1_PORTS_FTP:-2022}:2022\"\n    - \"${PTERODACTYLNODE1_PORTS_HTTPS:-444}:443\"\n    tty: true\n    environment:\n    TZ: \"$TZ\"\n    WINGS_UID: 988\n    WINGS_GID: 988\n    WINGS_USERNAME: $WINGS_USERNAME\n    volumes:\n    - \"/var/run/docker.sock:/var/run/docker.sock\"\n    - \"/var/lib/docker/containers/:/var/lib/docker/containers/\"\n    - \"$PTERODACTYLDIR/node1/etc/pterodactyl/:/etc/pterodactyl/\"\n    - \"$PTERODACTYLDIR/node1/var/lib/pterodactyl/:/var/lib/pterodactyl/\"\n    - \"$PTERODACTYLDIR/node1/var/log/pterodactyl/:/var/log/pterodactyl/\"\n    - \"$PTERODACTYLDIR/node1/tmp/pterodactyl/:/tmp/pterodactyl/\"\n    - \"$PTERODACTYLDIR/node1/etc/ssl/certs:/etc/ssl/certs:ro\"\n    # you may need /srv/daemon-data if you are upgrading from an old daemon\n    #- \"/srv/daemon-data/:/srv/daemon-data/\"\n    # Required for ssl if you use let's encrypt. uncomment to use.\n    #- \"/etc/letsencrypt/:/etc/letsencrypt/\"\n\nnetworks:\nwings0:\n    name: wings0\n    driver: bridge\n    ipam:\n    config:\n        - subnet: \"172.21.0.0/16\"\n    driver_opts:\n    com.docker.network.bridge.name: wings0\n</code></pre> <pre><code>PUID=1000 # User ID\nPGID=1003 #Group ID\nUMASK=002\nTZ=Europe/Brussels # Timezone\nUSERDIR=/home/&lt;USER&gt; # User directory\nDOCKERDIR=/home/&lt;USER&gt;/docker # Docker directory\nCOMPOSEDIR=/home/&lt;USER&gt;/docker/docker-compose/compose # Compose directory\nAPPDATADIR=/home/&lt;USER&gt;/docker/appdata # Appdata directory\nDATADIR=/data\nLOCAL_IPS=127.0.0.1/32,10.0.0.0/8,192.168.0.0/16,172.16.0.0/16 # Lokale IP's\nCLOUDFLARE_IPS=173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22,141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20,197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/13,104.24.0.0/14,172.64.0.0/13,131.0.72.0/22 # Cloudflare IP's\nDOMAINNAME_1=DOMAIN # Domeinnaam\nHOSTNAME=Hostname # Hostname\nUSERNAME=&lt;USER&gt;\nPASSWORD=&lt;PASSWORD&gt;\n\n\n\n###### MYSQL #####\nMYSQL_PASSWORD=PASSWORD\nMYSQL_ROOT_PASSWORD=PASSWORD\nMYSQL_DATABASE=panel\nMYSQL_USER=pterodactyl\n\n###### Pterodactyl ######\nAPP_URL=https://panel.$DOMAINNAME_1\nAPP_SERVICE_AUTHOR=EMAIL\nPTERODACTYLDIR=/pterodactyl\nAPP_ENV=production\n\n\n###### NODE1 ######\nWINGS_USERNAME=USERNAME\n\n\n\n###### PORTS #######\nPTERODACTYLPANELPORTS_HTTP=80\nPTERODACTYLPANELPORTS_HTTPs=443\nPTERODACTYLNODE1_PORTS_HTTP=8080\nPTERODACTYLNODE1_PORTS_FTP=2022\nPTERODACTYLNODE1_PORTS_HTTPS=444\n</code></pre> <p>na dat je dit gedaan hebt doe je: </p><pre><code>docker compose up -d\n</code></pre> <p>Nu ga je naar uw DNS provider en maak je een Record aan panel.domain.com \u2192 WAN IP. Doe dit hetzelfde voor de WING.</p> <p>Note</p> <p>Als je local DNS kunt doen mag dit voor de Wing. Pterodactyl is gemaakt voor meerdere nodes in verschillende datacenters.</p> <p>Als je eenmaal aan je Panel kunt voor je volgende commando uit um een user te maken: </p><pre><code>docker-compose run --rm panel php artisan p:user:make\n</code></pre>"},{"location":"apps/pterodactyl/#configuratie","title":"Configuratie","text":""},{"location":"apps/pterodactyl/#treafik","title":"Treafik","text":"<p>Eerst gaan we de reverse proxy midellwares instellen:</p> <p>Note</p> <p>Hou er rekening mee dat je een midellware moete instellen anders ga je Corsall errors krijgen.</p> <pre><code>http:\n    middlewares:\n        cors-pterodactyl:\n        headers:\n            accessControlAllowMethods:\n            - \"OPTIONS\"\n            - \"POST\"\n            - \"GET\"\n            - \"PUT\"\n            - \"DELETE\"\n            accessControlAllowHeaders:\n            # - \"*\" # If you do this you get errors for \"*\"\n            - \"Accept\"\n            - \"Authorization\"\n            - \"Cache-Control\"\n            - \"Content-Type\"\n            - \"DNT\"\n            - \"If-Modified-Since\"\n            - \"Keep-Alive\"\n            - \"Origin\"\n            - \"User-Agent\"\n            - \"X-Requested-With\"\n            accessControlAllowOriginList:\n            - \"*\"\n            accessControlMaxAge: 100\n            addVaryHeader: true\n            customRequestHeaders:\n            X-Forwarded-Proto: \"https\"\n            Content-Type: \"application/json\"\n            customResponseHeaders:\n            X-Forwarded-Proto: \"https\"\n</code></pre>"},{"location":"apps/pterodactyl/#panel-configuration","title":"Panel configuration","text":"<p>Als alles goed is ingesteld ga je naar je Panel. Dan Stel je uw location is. Als dat gadaan is stel je uw Node in (dit is het moeilijkste). Tijdens het aanmaken van de node verwander je 8080 \u2192 443 (voor https connecties). Vergeet zeten geen IP en poort allocatie in deze setup op te zetten. Dit zijn de poorten dat je Node kan gebruiken voor servers.</p>"},{"location":"apps/pterodactyl/#node","title":"Node","text":"<p>Nu krijg je een config file dat je op de node moet zetten. Onder \"/etc/pterodactyl/config.yml\"</p> <p>Note</p> <p>Vrander in deze file de 443 \u2192 8080. Dit komt omdat we hierboven moeten verwijzen naar HTTPS maar onde Deamon werkt op 8080.</p> <p>Warning</p> <p>Probeer eerst je panel url te laten staan. Word je verbinding (Hartslag) niet opgezet verander dit in het lokaal ip van je Panel. Ik ben in communicatie met pterodactyl om dit op te lossen.</p>"},{"location":"apps/pterodactyl/#testen","title":"Testen","text":"<p>Probeer nu een server op te zetten en alles Werkt</p>"},{"location":"apps/rancher/","title":"Rancher","text":""},{"location":"apps/rancher/#rancher","title":"Rancher","text":"<p>Rancher, the open-source multi-cluster orchestration platform, lets operations teams deploy, manage and secure enterprise Kubernetes.</p> <p>Project Homepage: Rancher Homepage</p>"},{"location":"apps/rancher/#remove-installation","title":"Remove Installation","text":"<pre><code>kubectl delete validatingwebhookconfiguration rancher.cattle.io\nkubectl delete mutatingwebhookconfiguration rancher.cattle.io\n</code></pre>"},{"location":"apps/tailscale/","title":"Tailscale","text":""},{"location":"apps/tailscale/#tailscale","title":"Tailscale","text":"<p>Tailscale is a zero config VPN for building secure networks, powered by wireguard. Install on any device in minutes. Remote access from any network or physical location.</p> <p>Project Homepage: https://tailscale.com</p>"},{"location":"apps/teleport/","title":"Teleport","text":""},{"location":"apps/teleport/#teleport","title":"Teleport","text":"<p>A single-day dual-track user conference to discuss industry challenges around Access, DevSecOps, and deploying secure systems at scale.</p> <p>Project homepage: Teleport Documentation: Teleport Docs</p>"},{"location":"apps/teleport/#installation","title":"Installation","text":""},{"location":"apps/teleport/#configuration","title":"Configuration","text":""},{"location":"apps/teleport/#users-and-roles","title":"Users and Roles","text":"<p>Teleport Role Templates | Teleport Docs (goteleport.com)</p>"},{"location":"apps/teleport/#tctl","title":"TCTL","text":""},{"location":"apps/teleport/#adding-nodes","title":"Adding nodes","text":"<p>Add another node with roles <code>tctl nodes add --roles=&lt;node,app,kube,proxy,...&gt; --ttl=1h</code></p>"},{"location":"apps/traefik/","title":"Traefik","text":""},{"location":"apps/traefik/#traefik","title":"Traefik","text":"<p>Traefik is an\u00a0open-source\u00a0Edge Router for Docker, and Kubernetes\u00a0that makes publishing your services a fun and easy experience. It receives requests on behalf of your system and finds out which components are responsible for handling them.</p>"},{"location":"apps/traefik/#installation","title":"Installation","text":""},{"location":"apps/traefik/#docker","title":"Docker","text":"<p>TODO: WIP</p>"},{"location":"apps/traefik/#kubernetes","title":"Kubernetes","text":""},{"location":"apps/traefik/#dashboard-and-api","title":"Dashboard and API","text":"<p>WIP</p>"},{"location":"apps/traefik/#entrypoints","title":"EntryPoints","text":"<p>WIP</p>"},{"location":"apps/traefik/#http-redirection","title":"HTTP Redirection","text":"<p>WIP </p><pre><code>entryPoints:\n  web:\n    address: :80\n    http:\n      redirections:\n        entryPoint:\n          to: websecure\n          scheme: https\n</code></pre>"},{"location":"apps/traefik/#https","title":"HTTPS","text":"<p>WIP </p><pre><code>entryPoints:\n  websecure:\n    address: :443\n</code></pre>"},{"location":"apps/traefik/#routers","title":"Routers","text":"<p>traefik.http.routers.router.entrypoints Specifies the Entrypoint for the Router. Setting this to <code>traefik.http.routers.router.entrypoints: websecure</code> will expose the Container on the <code>websecure</code> entrypoint. *When using websecure, you should enable <code>traefik.http.routers.router.tls</code> as well.</p> <p>traefik.http.routers.router.rule Specify the Rules for the Router. This is an example for an FQDN: Host(<code>subdomain.your-domain</code>)</p> <p>traefik.http.routers.router.tls Will enable TLS protocol on the router.</p> <p>traefik.http.routers.router.tls.certresolver Specifies the Certificate Resolver on the Router.</p>"},{"location":"apps/traefik/#pathprefix-and-stripprefix","title":"PathPrefix and StripPrefix","text":"<p>WIP</p> <pre><code>- \"traefik.enable=true\"\n- \"traefik.http.routers.nginx-test.entrypoints=websecure\"\n- \"traefik.http.routers.nginx-test.tls=true\"\n- \"traefik.http.routers.nginx-test.rule=PathPrefix(`/nginx-test/`)\"\n- \"traefik.http.routers.nginx-test.middlewares=nginx-test\"\n- \"traefik.http.middlewares.nginx-test.stripprefix.prefixes=/nginx-test\"\n</code></pre> <p>Add <code>/api</code> prefix to any requets to <code>myapidomain.com</code> Example:   - Request -&gt; <code>myapidomain.com</code>   - Traefik translates this to <code>myapidomain.com/api</code> without requestee seeing it </p><pre><code>- \"traefik.enable=true\"\n- \"traefik.http.routers.myapp-secure-api.tls=true\"\n- \"traefik.http.routers.myapp-secure-api.rule=Host(`myapidomain.com`)\"\n- \"traefik.http.routers.myapp-secure-api.middlewares=add-api\"\n\n# Middleware\n- \"traefik.http.middlewares.add-api.addPrefix.prefix=/api\"\n</code></pre>"},{"location":"apps/traefik/#certificatesresolvers","title":"CertificatesResolvers","text":"<p>WIP</p>"},{"location":"apps/traefik/#dnschallenge","title":"dnsChallenge","text":"<p>DNS Providers such as <code>cloudflare</code>, <code>digitalocean</code>, <code>civo</code>, and more. To get a full list of supported providers, look up the Traefik ACME Documentation .</p> <pre><code>certificatesResolvers:\n  yourresolver:\n    acme:\n      email: \"your-mail-address\"\n      dnsChallenge:\n        provider: your-dns-provider\n        resolvers:\n          - \"your-dns-resolver-ip-addr:53\"\n</code></pre>"},{"location":"apps/traefik/#serverstransport","title":"ServersTransport","text":""},{"location":"apps/traefik/#insecureskipverify","title":"InsecureSkipVerify","text":"<p>If you want to skip the TLS verification from Traefik to your Servers, you can add the following section to your <code>traefik.yml</code> config file. </p><pre><code>serversTransport:\n  insecureSkipVerify: true\n</code></pre>"},{"location":"apps/traefik/#tls-settings","title":"TLS Settings","text":"<p>Define TLS Settings in Traefik.</p>"},{"location":"apps/traefik/#defaultcertificates","title":"defaultCertificates","text":"<pre><code>tls:\n  stores:\n    default:\n      defaultCertificate:\n        certFile: /your-traefik-cert.crt\n        keyFile: /your-traefik-key.key\n</code></pre>"},{"location":"apps/traefik/#options","title":"options","text":"<p>Define TLS Options like disabling insecure TLS1.0 and TLS 1.1. </p><pre><code>tls:\n  options:\n    default:\n      minVersion: VersionTLS12\n</code></pre>"},{"location":"apps/traefik/#providers","title":"Providers","text":"<p>WIP</p>"},{"location":"apps/traefik/#file","title":"File","text":"<p>WIP </p><pre><code>providers:\n  file:\n</code></pre>"},{"location":"apps/traefik/#docker_1","title":"Docker","text":"<p>With <code>exposedByDefault: false</code>, Traefik won't automatically expose any containers by default. Setting <code>traefik.enable: true</code>, will expose the Container.</p> <pre><code>providers:\n  docker:\n    exposedByDefault: false\n</code></pre>"},{"location":"apps/traefik/#kubernetes_1","title":"Kubernetes","text":"<p>WIP</p>"},{"location":"apps/traefik/#ingress","title":"Ingress","text":"<p>WIP</p>"},{"location":"apps/traefik/#log","title":"Log","text":"<p>WIP</p> <pre><code>log:\n  level: ERROR\n</code></pre>"},{"location":"apps/traefik/#global","title":"Global","text":"<p>WIP</p> <pre><code>global:\n  checkNewVersion: true\n  sendAnonymousUsage: false\n</code></pre>"},{"location":"apps/unmanic/","title":"Unmanic","text":""},{"location":"apps/unmanic/#unmanic","title":"Unmanic","text":"<p>Unmanic is een eenvoudig hulpmiddel voor het optimaliseren van je bestandsbibliotheek. Je kunt het gebruiken om je bestanden om te zetten naar een enkel, uniform formaat, bestandsbewegingen te beheren op basis van tijdstempels of aangepaste opdrachten uit te voeren op een bestand op basis van de bestandsgrootte. Configureer Unmanic eenvoudig door het naar je bibliotheek te wijzen en laat het automatisch die bibliotheek voor je beheren.</p>"},{"location":"apps/vault/","title":"HashiCorp Vault","text":""},{"location":"apps/vault/#hashicorp-vault","title":"HashiCorp Vault","text":""},{"location":"apps/vault/#beschrijving","title":"Beschrijving","text":"<p>HashiCorp Vault is een populaire open-source tool die is ontworpen om gevoelige gegevens veilig op te slaan en te beheren, zoals wachtwoorden, API-sleutels en encryptiesleutels. Het biedt een gecentraliseerd systeem voor het beheren van geheimen en biedt fijnmazige toegangscontrole om gevoelige informatie te beschermen.</p> <p>Vault biedt verschillende authenticatiemethoden, waaronder tokens, gebruikersnaam/wachtwoord en vertrouwde entiteiten (bijv. GitHub, Active Directory). Het ondersteunt ook 'encryption-as-a-service', dynamische geheimen en het leasen van geheimen om de beveiliging te verbeteren en geheimen effici\u00ebnt te beheren.</p>"},{"location":"apps/vault/#kenmerken","title":"Kenmerken","text":"<ul> <li>Geheimenbeheer: Vault slaat gevoelige gegevens veilig op en beheert ze, waarbij geheimen worden versleuteld tijdens opslag.</li> <li>Dynamische geheimen: Vault kan dynamische geheimen genereren voor verschillende services, waardoor het risico van langdurige geheimen wordt verminderd.</li> <li>Encryption-as-a-Service: Vault fungeert als een centraal sleutelbeheersysteem en biedt versleutelingsservices voor toepassingen.</li> <li>Leasen en verlengen: Geheimen kunnen worden geleaset voor een bepaalde duur, en Vault biedt automatische verlengingsmogelijkheden.</li> <li>Toegangsbeheerbeleid: Vault biedt fijnmazige toegangsbeheerbeleidsregels om gebruikerstoegang tot geheimen te beperken en te beheren.</li> <li>Audit logging: Alle interacties met Vault worden gelogd, waardoor een audittrail wordt gecre\u00eberd voor compliance-doeleinden.</li> </ul>"},{"location":"apps/vault/#installatie","title":"Installatie","text":""},{"location":"apps/vault/#vereisten","title":"Vereisten","text":"<p>Voordat je Vault installeert, zorg ervoor dat je aan de volgende vereisten voldoet:</p> <ul> <li>Een ondersteund besturingssysteem (bijv. Linux, macOS, Windows)</li> <li>Beheerdersrechten op het systeem waarop Vault wordt ge\u00efnstalleerd</li> </ul>"},{"location":"apps/vault/#installatiestappen","title":"Installatiestappen","text":"<ol> <li> <p>Download Vault: Ga naar de HashiCorp Vault-website en download de nieuwste versie van Vault die geschikt is voor jouw besturingssysteem.</p> </li> <li> <p>Pak het archief uit: Pak het gedownloade archiefbestand uit naar een map van jouw keuze.</p> </li> </ol> <pre><code>$ tar -xf vault_&lt;versie&gt;.zip\n</code></pre> <ol> <li>Verplaats het uitgepakte bestand: Navigeer naar de uitgepakte Vault-directory.</li> </ol> <pre><code>$ cd vault_&lt;versie&gt;\n</code></pre> <ol> <li>Plaats het uitvoerbare bestand: Verplaats het uitvoerbare bestand naar een locatie in je <code>PATH</code>, zodat je Vault vanaf elke locatie kunt uitvoeren.</li> </ol> <pre><code>$ sudo mv vault /usr/local/bin/\n</code></pre> <ol> <li>Verifieer de installatie: Controleer of Vault correct is ge\u00efnstalleerd door het uitvoeren van het volgende commando.</li> </ol> <pre><code>$ vault -v\n</code></pre> <p>Je zou de versie van Vault moeten zien die je hebt ge\u00efnstalleerd.</p> <ol> <li>Start de Vault-server: Om de Vault-server te starten, voer je het volgende commando uit.</li> </ol> <pre><code>$ vault server -dev\n</code></pre> <p>Dit start een ontwikkelingsserver van Vault in de dev-modus. Deze modus is bedoeld voor lokaal ontwikkelings- en testgebruik.</p> <ol> <li>Gebruik Vault: Je kunt nu de Vault CLI gebruiken om met de server te communiceren en geheimen te beheren. Raadpleeg de Vault-documentatie voor meer informatie over het gebruik van Vault en het configureren van geheimen.</li> </ol> <pre><code>$ vault &lt;commando&gt;\n</code></pre> <p>Bijvoorbeeld: <code>$ vault secrets list</code> om de lijst met geheime backends weer te geven.</p> <p>Let op: De ontwikkelingsserver van Vault in de dev-modus is niet geschikt voor productiegebruik. Voor productie-implementaties raadpleeg je de Vault-documentatie voor informatie over het instellen van een productieklare Vault-server.</p>"},{"location":"apps/vault/#links","title":"links","text":"<ul> <li>https://www.youtube.com/watch?v=WQ52YJMZZYY</li> </ul>"},{"location":"apps/vaultwarden/","title":"Vaultwarden","text":""},{"location":"container/docker/docker-compose/","title":"Docker-compose","text":""},{"location":"container/docker/docker-compose/#docker-compose","title":"Docker-compose","text":"<p>Docker-compose is een software die wordt gebruikt om multi-container Docker applicaties te defini\u00ebren en uit te voeren. Het kan meerdere containers tegelijkertijd afhandelen in de productie-, staging-, ontwikkelings-, test- en CI-omgeving. Gebruik daarom docker-compose om de hele softwareontwikkelingscyclus (SDLC) te beheren.</p> <p>Met docker-compose kun je een YAML-bestand maken om de services van je applicatie te configureren. Vervolgens kun je met \u00e9\u00e9n commando alle services uit je configuratie maken en starten. Het grote voordeel van docker-compose is dat je je applicatiestack in een bestand kunt defini\u00ebren, bij de root van je projectrepo kunt bewaren (het is nu versiebeheerd) en gemakkelijk iemand anders kunt laten bijdragen aan je project.</p> <p></p>"},{"location":"container/docker/docker-compose/#networking","title":"Networking","text":"<p>Docker-Compose maakt standaard een nieuw netwerk aan voor het gegeven compose-bestand. U kunt het gedrag wijzigen door aangepaste netwerken te defini\u00ebren in uw samengestelde bestand.</p>"},{"location":"container/docker/docker-compose/#aangepast-netwerk-maken-en-toewijzen","title":"Aangepast netwerk maken en toewijzen","text":"<pre><code>networks:\n  custom-network:\n\nservices:\n  app:\n    networks:\n      - custom-network\n</code></pre>"},{"location":"container/docker/docker-compose/#gebruik-bestaande-netwerken","title":"Gebruik bestaande netwerken","text":"<p>Als u een bestaand Docker-netwerk wilt gebruiken voor uw samengestelde bestanden, kunt u de <code>external: true</code> parameter toevoegen aan uw samengestelde bestand</p> <pre><code>networks:\n  existing-network:\n    external: true\n</code></pre>"},{"location":"container/docker/docker-compose/#volumes","title":"Volumes","text":"<p>Met volumes kunnen Docker-containers permanente opslag gebruiken. In een samengesteld bestand kunt u volumes als volgt maken en toewijzen: </p><pre><code>volumes:\n  my-volume:\n\nservices:\n  app:\n    volumes:\n      - my-volume:/path-in-container\n</code></pre> <p>Deze volumes worden vaak opgeslagen in <code>/var/lib/docker/volumes</code>.</p>"},{"location":"container/docker/docker-compose/#labels","title":"Labels","text":"<p>Docker labels zijn metadata-tags die je aan containers, images, volumes en netwerken kunt toevoegen. Ze helpen bij organisatie, filtering en automatisering binnen Docker en Docker Swarm.  </p>"},{"location":"container/docker/docker-compose/#gebruik","title":"\ud83d\udd39 Gebruik","text":""},{"location":"container/docker/docker-compose/#1-labels-toevoegen-bij-het-aanmaken-van-een-container","title":"1. Labels toevoegen bij het aanmaken van een container","text":"<pre><code>docker run --label environment=production nginx\n</code></pre> <p>In onderstaande compose is de variabele voor de container zelf: </p><pre><code>services:\n  web:\n    image: nginx\n    labels:\n      - environment=production\n</code></pre> <p>In deze compose file is de variabele voor een andere container: </p><pre><code>services:\n  uptime-kuma:\n    image: louislam/uptime-kuma:1\n    container_name: uptime-kuma\n    ports:\n      - \"3001:3001/tcp\"\n    volumes:\n      - $APPDATADIR/uptime-kuma:/app/data\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n    restart: unless-stopped\n    security_opt:\n      - no-new-privileges:true\n    networks:\n      - t3_proxy\n      - swarm-traefik\n    labels:\n      - \"traefik.enable=true\"\n      ## HTTP Routers\n      - \"traefik.http.routers.uptime-rtr.entrypoints=websecure-internal,websecure-external\"\n      - \"traefik.http.routers.uptime-rtr.rule=Host(`uptime.$DOMAINNAME_1`)\"\n      ## Middlewares\n      - \"traefik.http.routers.uptime-rtr.middlewares=chain-no-auth@file\"\n      ## HTTP Services\n      - \"traefik.http.routers.uptime-rtr.service=uptime-svc\"\n      - \"traefik.http.services.uptime-svc.loadbalancer.server.port=3001\"\n</code></pre> <p>Volgende Containers werken als zeker met deze soort labels: - Traefik - Homepage - TSDProxy - AutoKuma</p>"},{"location":"container/docker/docker-compose/#docker-compose-easy","title":"Docker compose (Easy)","text":"<p>Docker Compose is een tool waarmee je meerdere Docker-containers kunt defini\u00ebren en beheren via een docker-compose.yml-bestand. Hiermee kun je eenvoudig complete applicaties met meerdere services (zoals databases, backends en frontends) opstarten met \u00e9\u00e9n commando.</p> <p>\ud83d\udd39 Belangrijkste functies:</p> <ul> <li>Definieert containers en hun configuratie in YAML.</li> <li>Start alles met \"docker compose up\".</li> <li>Beheert netwerken, volumes en afhankelijkheden automatisch.</li> </ul> <p>\ud83d\ude80 Kort gezegd: Docker Compose maakt het eenvoudiger om multi-container applicaties te beheren!</p>"},{"location":"container/docker/docker-compose/#voorbeeld","title":"voorbeeld","text":"<p>Laten we een opstelling maken om het te verduidelijken. maak deze struktuur.</p> <pre><code>docker\n  \u2514\u2500\u2500 docker-compose.yaml\n</code></pre> <p>Zet het volgend in de \"docker-compose.yaml\" </p><pre><code>services:\n  mariadb:\n    image: lscr.io/linuxserver/mariadb:latest\n    container_name: mariadb\n    networks:\n      - default\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Etc/UTC\n      - MYSQL_ROOT_PASSWORD=ROOT_ACCESS_PASSWORD\n      - MYSQL_DATABASE=USER_DB_NAME #optional\n      - MYSQL_USER=MYSQL_USER #optional\n      - MYSQL_PASSWORD=DATABASE_PASSWORD #optional\n      - REMOTE_SQL=http://URL1/your.sql,https://URL2/your.sql #optional\n    volumes:\n      - ./mariadb/config:/config\n    ports:\n      - 3306:3306\n    restart: unless-stopped\n\n  phpmyadmin:\n    image: phpmyadmin\n    restart: always\n    networks:\n      - default\n    ports:\n      - 8080:80\n    environment:\n      - PMA_ARBITRARY=1\n</code></pre> <p>Als je dit gedaan hebt doe je het volgende:</p> <pre><code>cd ~/docker\ndocker compose up -d\n</code></pre> <p>Nu zal zullen je dockers opgestart worden. Je kan hier zoveel docker insteken.</p>"},{"location":"container/docker/docker-compose/#update-compose","title":"update compose","text":"<p>Als je nu heel simpel je dockers wilt updaten doe je het volgende: </p><pre><code>docker compose pull\ndocker compose up -d\n</code></pre>"},{"location":"container/docker/docker-compose/#docker-compose-advanced","title":"Docker compose (Advanced)","text":"<p>Docker Compose ondersteunt variabelen en externe opslag voor flexibiliteit en betere configuratiebeheer.</p> <p>\ud83d\udd39 Belangrijkste functies:</p> <ul> <li>Variabelen gebruiken via een .env-bestand of direct in docker-compose.yml (bijvoorbeeld ${VARIABELE} voor dynamische configuratie).</li> <li>Opslag op andere plaatsen door volumes of bind mounts te gebruiken, zodat data persistent blijft buiten de container.</li> </ul> <p>\ud83d\ude80 Kort gezegd: Docker Compose maakt het eenvoudig om multi-container applicaties te beheren, inclusief dynamische configuratie en externe opslag!</p>"},{"location":"container/docker/docker-compose/#voobeeld","title":"voobeeld","text":"<p>laten we een opstelling maken om het te verduidelijken. maak deze struktuur.</p> <pre><code>docker\n  \u251c\u2500\u2500 appdata\n  \u2514\u2500\u2500 docker-compose\n        \u251c\u2500\u2500compose\n        \u2502   \u2514\u2500\u2500 database.yml\n        \u251c\u2500\u2500docker-compose.yaml\n        \u2514\u2500\u2500.env\n</code></pre> <p>Zet de volgende gegevens in de files:</p> Configuratie bestanden <p>Warning</p> <p>Vergeet niet alle gegevens naar die van jou te veranderen!!</p> docker-compose.yamldatabase.yml.env <pre><code>########################### NETWORKS ######################\n# U kunt de onderstaande netwerk-subnetten (10.250.x.0/24) naar wens aanpassen.\nnetworks:\n  default:\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 10.250.10.0/24\ninclude:\n  ########################### SERVICES ####################\n  - compose/database.yml\n</code></pre> <pre><code>services:\n  mariadb:\n    image: lscr.io/linuxserver/mariadb:latest\n    container_name: mariadb\n    networks:\n      - default\n    environment:\n      - PUID=$PUID\n      - PGID=$PGID\n      - TZ=$TZ\n      - MYSQL_ROOT_PASSWORD=$ROOTPASSWORD\n      - MYSQL_DATABASE=$USER_DB_NAME #optional\n      - MYSQL_USER=$MYSQL_USER #optional\n      - MYSQL_PASSWORD=$DATABASE_PASSWORD #optional\n      - REMOTE_SQL=http://db.$DOMAINNAME_1/your.sql,https://db2.$DOMAINNAME_1/your.sql #optional\n    volumes:\n      - $APPDATADIR/mariadb/config:/config\n    ports:\n      - ${MARIADB_PORT:-3306}:3306\n    restart: unless-stopped\n\n  phpmyadmin:\n    image: phpmyadmin\n    restart: always\n    networks:\n      - default\n    ports:\n      - ${PHPMYADMIN_PORT:-8080}:80\n    environment:\n      - PMA_ARBITRARY=1\n</code></pre> <p>Note</p> <p>Dit bestand is voorzien om al je veriabele in te zetten.</p> <pre><code>PUID=1000 # User ID\nPGID=1003 #Group ID\nUMASK=002\nTZ=Europe/Brussels # Timezone\nUSERDIR=/home/&lt;USER&gt; # User directory\nDOCKERDIR=/home/&lt;USER&gt;/docker # Docker directory\nCOMPOSEDIR=/home/&lt;USER&gt;/docker/docker-compose/compose # Compose directory\nAPPDATADIR=/home/&lt;USER&gt;/docker/appdata # Appdata directory\nDATADIR=/data\nLOCAL_IPS=127.0.0.1/32,10.0.0.0/8,192.168.0.0/16,172.16.0.0/16 # Lokale IP's\nCLOUDFLARE_IPS=173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22,141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20,197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/13,104.24.0.0/14,172.64.0.0/13,131.0.72.0/22 # Cloudflare IP's\nDOMAINNAME_1=&lt;DOMAIN.COM&gt; # Domeinnaam\nHOSTNAME=&lt;HOSTNAME&gt; # Hostname\nUSERNAME=&lt;USER&gt;\nPASSWORD=&lt;PASSWORD&gt;\n\n###### DATABASE #####\nROOTPASSWORD=&lt;ROOTPASSWORD&gt;\nUSER_DB_NAME=&lt;USER_DB_NAME&gt;\nMYSQL_USER=&lt;MYSQL_USER&gt;\nDATABASE_PASSWORD=&lt;DATABASE_PASSWORD&gt;\n\n\n\n###### PORTS #####\nMARIADB_PORT=3306\nPHPMYADMIN_PORT=8080\n</code></pre>"},{"location":"container/docker/docker-file/","title":"Dockerfile","text":""},{"location":"container/docker/docker-networking/","title":"Docker networking","text":""},{"location":"container/docker/docker/","title":"Docker","text":""},{"location":"container/docker/docker/#docker","title":"Docker","text":"<p>Docker\u00a0is a set of\u00a0platform as a service\u00a0(PaaS) products that use\u00a0OS-level virtualization\u00a0to deliver software in packages called\u00a0containers. The service has both free and premium tiers. The software that hosts the containers is called\u00a0Docker Engine.</p> <p>Project Homepage: Home - Docker</p> <p>Documentation: Docker Documentation | Docker Documentation</p>"},{"location":"container/docker/docker/#installation","title":"Installation","text":"<p>One click installation script: </p><pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n</code></pre> <p>Run docker as non root user: </p><pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\n</code></pre> <p>Install Docker Engine : Docker Engine</p>"},{"location":"container/docker/docker/#build-images","title":"Build Images","text":""},{"location":"container/docker/docker/#docker-cli","title":"Docker CLI","text":"<p>Run Containers</p> COMMAND DESCRIPTION <code>docker run IMAGE</code> Start a new container <code>docker run --name CONTAINER IMAGE</code> Start a new container and set a name <code>docker run -p HOSTPORT:CONTAINERPORT IMAGE</code> Start a new container with mapped ports <code>docker run -P IMAGE</code> Start a new container and map all ports <p>Container Management:</p> COMMAND DESCRIPTION <code>docker create IMAGE</code> Create a new container <code>docker start CONTAINER</code> Start a container <code>docker stop CONTAINER</code> Graceful stop a container <code>docker kill CONTAINER</code> Kill (SIGKILL) a container <code>docker restart CONTAINER</code> Graceful stop and restart a container <code>docker pause CONTAINER</code> Suspend a container <code>docker unpause CONTAINER</code> Resume a container <code>docker rm CONTAINER</code> Destroy a container <p>Container Bulk Management</p> COMMAND DESCRIPTION <code>docker stop $(docker ps -q)</code> To stop all the running containers <code>docker stop $(docker ps -a -q)</code> To stop all the stopped and running containers <code>docker kill $(docker ps -q)</code> To kill all the running containers <code>docker kill $(docker ps -a -q)</code> To kill all the stopped and running containers <code>docker restart $(docker ps  -q)</code> To restart all  running containers <code>docker restart $(docker ps -a -q)</code> To restart all the stopped and running containers <code>docker rm $(docker ps  -q)</code> To destroy all running containers <code>docker rm $(docker ps -a -q)</code> To destroy all the stopped and running containers <code>docker pause $(docker ps  -q)</code> To pause all  running containers <code>docker pause $(docker ps -a -q)</code> To pause all the stopped and running containers <code>docker start $(docker ps  -q)</code> To start all  running containers <code>docker start $(docker ps -a -q)</code> To start all the stopped and running containers <code>docker rm -vf $(docker ps -a -q)</code> To delete all containers including its volumes use <code>docker rmi -f $(docker images -a -q)</code> To delete all the images <code>docker system prune</code> To delete all dangling and unused images, containers, cache and volumes <code>docker system prune -a</code> To delete all used and unused images <code>docker system prune --volumes</code> To delete all docker volumes <p>Inspect Containers:</p> COMMAND DESCRIPTION <code>docker ps</code> List running containers <code>docker ps -a</code> List all containers, including stopped <code>docker logs CONTAINER</code> Show a container output <code>docker logs -f CONTAINER</code> Follow a container output <code>docker top CONTAINER</code> List the processes running in a container <code>docker diff</code> Show the differences with the image (modified files) <code>docker inspect</code> Show information of a container (json formatted) <p>Run Commands:</p> COMMAND DESCRIPTION <code>docker attach CONTAINER</code> Attach to a container <code>docker cp CONTAINER:PATH HOSTPATH</code> Copy files from the container <code>docker cp HOSTPATH CONTAINER:PATH</code> Copy files into the container <code>docker export CONTAINER</code> Export the content of the container (tar archive) <code>docker exec CONTAINER</code> Run a command inside a container <code>docker exec -it CONTAINER /bin/bash</code> Open an interactive shell inside a container (there is no bash in some images, use /bin/sh) <code>docker wait CONTAINER</code> Wait until the container terminates and return the exit code <p>Images:</p> COMMAND DESCRIPTION <code>docker images</code> List all local images <code>docker history IMAGE</code> Show the image history <code>docker inspect IMAGE</code> Show information (json formatted) <code>docker tag IMAGE TAG</code> Tag an image <code>docker commit CONTAINER IMAGE</code> Create an image (from a container) <code>docker import URL</code> Create an image (from a tarball) <code>docker rmi IMAGE</code> Delete images <code>docker pull REPO:[TAG]</code> pull an image/repo from a registry <code>docker push REPO:[TAG]</code> push and image/repo to a registry <code>docker search TEXT</code> Search an image on the official registry <code>docker login</code> Login to a registry <code>docker logout</code> Logout from a registry <code>docker save REPO:[TAG]</code> Export an image/repo as a tarball <code>docker load</code> Load images from a tarball <p>Volumes:</p> COMMAND DESCRIPTION <code>docker volume ls</code> List all vol1umes <code>docker volume create VOLUME</code> Create a volume <code>docker volume inspect VOLUME</code> Show information (json formatted) <code>docker volume rm VOLUME</code> Destroy a volume <code>docker volume ls --filter=\"dangling=true\"</code> List all dangling volumes (not referenced by any container) <code>docker volume prune</code> Delete all volumes (not referenced by any container)"},{"location":"container/docker/docker/#backup-a-container","title":"Backup a container","text":"<p>Backup docker data from inside container volumes and package it in a tarball archive. <code>docker run --rm --volumes-from CONTAINER -v $(pwd):/backup busybox tar cvfz /backup/backup.tar CONTAINERPATH</code></p> <p>An automated backup can be done also by this Ansible playbook. The output is also a (compressed) tar. The playbook can also manage the backup retention. So older backups will get deleted automatically.</p> <p>To also create and backup the container configuration itself, you can use <code>docker-replay</code>for that. If you lose the entire container, you can recreate it with the export from <code>docker-replay</code>. A more detailed tutorial on how to use docker-replay can be found here.</p>"},{"location":"container/docker/docker/#restore-container-from-backup","title":"Restore container from backup","text":"<p>Restore the volume with a tarball archive. <code>docker run --rm --volumes-from CONTAINER -v $(pwd):/backup busybox sh -c \"cd CONTAINERPATH &amp;&amp; tar xvf /backup/backup.tar --strip 1\"</code></p>"},{"location":"container/docker/docker/#networks","title":"Networks","text":""},{"location":"container/docker/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"container/docker/docker/#networking","title":"Networking","text":"<p><code>docker run --name netshoot --rm -it nicolaka/netshoot /bin/bash</code></p>"},{"location":"container/docker/docker_socket-proxy/","title":"Socker-proxy","text":""},{"location":"container/docker/swarm/","title":"Docker Swarm","text":""},{"location":"container/docker/swarm/#docker-swarm","title":"Docker Swarm","text":""},{"location":"container/docker/swarm/#wat-is-docker-swarm","title":"Wat is Docker Swarm","text":"<p>Docker Swarm is een clustering- en orkestratietool voor Docker-containers. Het maakt het mogelijk om meerdere Docker-hosts te groeperen en deze als \u00e9\u00e9n logische eenheid te beheren.</p> <p>Belangrijkste kenmerken van Docker Swarm:</p> <ul> <li>Container Orchestratie: Automatiseert de uitrol, schaling en het beheer van containers.</li> <li>Load Balancing: Verdeelt verkeer automatisch over de beschikbare containers.</li> <li>High Availability: Containers kunnen worden gerepliceerd over meerdere nodes, zodat de applicatie blijft draaien bij uitval.</li> <li>Rolling Updates: Voert updates uit zonder downtime.</li> </ul> <p>Swarm is ingebouwd in Docker en eenvoudiger dan Kubernetes, maar biedt minder geavanceerde functies. Het is vooral handig voor kleinere tot middelgrote projecten waar eenvoud en snelle setup belangrijk zijn.</p>"},{"location":"container/docker/swarm/#docker-swarm-opzetten","title":"Docker Swarm opzetten","text":"<p>In Docker Swarm zijn er twee soorten nodes:  </p> <pre><code>graph LR\n  A{Manager} &lt;--&gt; B[Node1];\n  A{Manager} &lt;--&gt; C[Node2];\n  A{Manager} &lt;--&gt; D[Node..];</code></pre>"},{"location":"container/docker/swarm/#1-manager-node","title":"1. Manager Node \ud83c\udfd7\ufe0f","text":"<ul> <li>Beheert het cluster en verdeelt taken (orkestratie).  </li> <li>Kan services aanmaken, schalen en beheren.  </li> <li>Gebruikt Raft-consensus voor hoge beschikbaarheid.  </li> </ul>"},{"location":"container/docker/swarm/#2-worker-node","title":"2. Worker Node \ud83c\udfed","text":"<ul> <li>Voert de toegewezen taken (containers) uit.  </li> <li>Kan geen beslissingen nemen over orkestratie.  </li> <li>Meldt status terug aan de manager.  </li> </ul> <p>Kort gezegd: Managers beheren, workers voeren uit. \ud83d\ude80</p> <p>Om een Docker swarm op te zetten heb je 2 commando`s nodig. Dit voor je uit op de Manager. </p><pre><code>docker swarm init\n</code></pre> Nu krijg je een join code en deze plak je op de Nodes. Als je deze code vergeten bent kan je volgende commando uitvoeren op de manager. <pre><code>docker swarm join-token worker\n</code></pre> Wil ke een extra manager wilt toevoegen kan je volgende commando op de huidige manage uitvoeren. <pre><code>docker swarm join-token manager\n</code></pre>"},{"location":"container/docker/swarm/#swarm-networks","title":"Swarm Networks","text":""},{"location":"container/docker/swarm/#wat-zijn-swarm-networks","title":"Wat zijn Swarm networks","text":"<p>Docker Swarm-netwerken bepalen hoe containers binnen een Swarm-cluster met elkaar en met de buitenwereld communiceren. Er zijn drie hoofdtypen netwerken:  </p>"},{"location":"container/docker/swarm/#1-overlay-network","title":"1. Overlay Network \ud83d\udd04","text":"<ul> <li>Verbindt containers over meerdere nodes.  </li> <li>Standaard voor services in Swarm Mode.  </li> <li>Zorgt voor interne service-discovery en load balancing.  </li> </ul>"},{"location":"container/docker/swarm/#2-ingress-network","title":"2. Ingress Network \ud83c\udf0d","text":"<ul> <li>Specifiek voor het routeren van inkomend verkeer naar de juiste service.  </li> <li>Gebruikt automatisch een ingebouwde load balancer.  </li> </ul>"},{"location":"container/docker/swarm/#3-bridge-network-per-node","title":"3. Bridge Network (per node) \ud83d\udd17","text":"<ul> <li>Alleen binnen \u00e9\u00e9n node bruikbaar.  </li> <li>Containers kunnen communiceren, maar niet over meerdere nodes heen.  </li> </ul> <p>Swarm-netwerken maken het makkelijk om containers dynamisch te laten samenwerken zonder dat je handmatig IP-adressen hoeft te beheren.</p> <p>Note</p> <p>Je kan je huidige docker containers het swarm netwerk laten gebruiken. Als je een Swarm netwerk aanmaakt zien uw nodes deze pas als er een conatainer op de node deze gebruikt.</p>"},{"location":"container/docker/swarm/#aanmaken-van-een-docker-swarm-overlay-network","title":"Aanmaken van een Docker Swarm overlay network","text":"<p>Door een Docker Swarm network aan te maken dat ook attacheble is aan uw huide docker conainers gebruik je het volgende commando op de manager. </p><pre><code>docker network create -d overlay --attachable my_overlay_network\n</code></pre> <p>Het enigste dat je nu moet doen is dit netwerk in je compose steken van de stand alone docker containers die je met elkaar wilt laten praten.</p> <pre><code>services:\n    app:\n        networks:\n            - swarm-network\n\nnetworks:\n  swarm-network:\n    external: true\n</code></pre>"},{"location":"container/docker/swarm/#testen-docker-swarm-network","title":"Testen Docker Swarm network","text":"<p>Om een Swarm netwerk te testen over verschillende nodes moet je het ping commando gebruiken en de conatiner naan of (docker network)IP gebruiken. Dat doe je met volgende commando.</p> <pre><code>docker exec -it &lt;conainer_name&gt; ping &lt;container_name/ip/DNS&gt;\n</code></pre>"},{"location":"container/docker/swarm/#docker-swarm-containers","title":"Docker swarm containers","text":""},{"location":"container/docker/swarm/#comming-soon","title":"Comming soon","text":""},{"location":"container/kubernetes/helm/","title":"Helm","text":""},{"location":"container/kubernetes/helm/#helm","title":"Helm","text":""},{"location":"container/kubernetes/helm/#repository-management","title":"Repository Management","text":"COMMAND DESCRIPTION <code>helm repo list</code> List Helm repositories <code>helm repo update</code> Update list of Helm charts from repositories"},{"location":"container/kubernetes/helm/#chart-management","title":"Chart Management","text":"COMMAND DESCRIPTION <code>helm search</code> List all installed charts <code>helm search &lt;CHARTNAME&gt;</code> Search for a chart <code>helm ls</code> List all installed Helm charts <code>helm ls --deleted</code> List all deleted Helm charts <code>helm ls --all</code> List installed and deleted Helm charts <code>helm inspect values &lt;REPO&gt;/&lt;CHART&gt;</code> Inspect the variables in a chart"},{"location":"container/kubernetes/helm/#installdelete-helm-charts","title":"Install/Delete Helm Charts","text":"COMMAND DESCRIPTION <code>helm install --name &lt;NAME&gt; &lt;REPO&gt;/&lt;CHART&gt;</code> Install a Helm chart <code>helm install --name &lt;NAME&gt; --values &lt;VALUES.YML&gt; &lt;REPO&gt;/&lt;CHART&gt;</code> Install a Helm chart and override variables <code>helm status &lt;NAME&gt;</code> Show status of Helm chart being installed <code>helm delete --purge &lt;NAME&gt;</code> Delete a Helm chart"},{"location":"container/kubernetes/helm/#upgrading-helm-charts","title":"Upgrading Helm Charts","text":"COMMAND DESCRIPTION <code>helm get values &lt;NAME&gt;</code> Return the variables for a release <code>helm upgrade --values &lt;VALUES.YML&gt; &lt;NAME&gt; &lt;REPO&gt;/&lt;CHART&gt;</code> Upgrade the chart or variables in a release <code>helm history &lt;NAME&gt;</code> List release numbers <code>helm rollback &lt;NAME&gt; 1</code> Rollback to a previous release number"},{"location":"container/kubernetes/helm/#creating-helm-charts","title":"Creating Helm Charts","text":"COMMAND DESCRIPTION <code>helm create &lt;NAME&gt;</code> Create a blank chart <code>helm lint &lt;NAME&gt;</code> Lint the chart <code>helm package &lt;NAME&gt;</code> Package the chart into foo.tgz <code>helm dependency update</code> Install chart dependencies"},{"location":"container/kubernetes/helm/#chart-folder-structure","title":"Chart Folder Structure","text":"<pre><code>wordpress/\n  Chart.yaml          # A YAML file containing information about the chart\n  LICENSE             # OPTIONAL: A plain text file containing the license for the chart\n  README.md           # OPTIONAL: A human-readable README file\n  requirements.yaml   # OPTIONAL: A YAML file listing dependencies for the chart\n  values.yaml         # The default configuration values for this chart\n  charts/             # A directory containing any charts upon which this chart depends.\n  templates/          # A directory of templates that, when combined with values,\n                      # will generate valid Kubernetes manifest files.\n  templates/NOTES.txt # OPTIONAL: A plain text file containing short usage notes\n</code></pre>"},{"location":"container/kubernetes/k3s/","title":"K3S","text":""},{"location":"container/kubernetes/k3s/#k3s","title":"K3S","text":"<p>Lightweight Kubernetes. Production ready, easy to install, half the memory, all in a binary less than 100 MB.</p> <p>Project Homepage: K3s.io Documentation: K3s Documentation</p>"},{"location":"container/kubernetes/k3s/#installation","title":"Installation","text":"<p>To install k3s, you can follow different approaches like setting up k3s with an external database, embedded database, or as a single node.</p>"},{"location":"container/kubernetes/k3s/#k3s-with-external-db","title":"K3s with external DB","text":"<p>Set up an HA K3s cluster backed by an external datastore such as MySQL, PostgreSQL, or etcd.</p>"},{"location":"container/kubernetes/k3s/#install-database","title":"Install Database","text":"<p>Install MariaDB.</p>"},{"location":"container/kubernetes/k3s/#install-servers","title":"Install Servers","text":"<pre><code>curl -sfL https://get.k3s.io | sh -s - server \\\n--token=YOUR-SECRET \\\n--datastore-endpoint='mysql://user:pass@tcp(ipaddress:3306)/dbname' \\\n--node-taint CriticalAddonsOnly=true:NoExecute \\\n--tls-san your-dns-name --tls-san your-lb-ip-address\n</code></pre>"},{"location":"container/kubernetes/k3s/#node-taint","title":"Node-Taint","text":"<p>By default, server nodes will be schedulable and thus your workloads can get launched on them. If you wish to have a dedicated control plane where no user workloads will run, you can use taints. The node-taint parameter will allow you to configure nodes with taints, for example <code>--node-taint CriticalAddonsOnly=true:NoExecute</code>.</p>"},{"location":"container/kubernetes/k3s/#ssl-certificates","title":"SSL Certificates","text":"<p>To avoid certificate errors in such a configuration, you should install the server with the <code>--tls-san YOUR_IP_OR_HOSTNAME_HERE</code> option. This option adds an additional hostname or IP as a Subject Alternative Name in the TLS cert, and it can be specified multiple times if you would like to access via both the IP and the hostname.</p>"},{"location":"container/kubernetes/k3s/#get-a-registered-address","title":"Get a registered Address","text":"<p>TODO: WIP</p>"},{"location":"container/kubernetes/k3s/#install-agents","title":"Install Agents","text":"<p>TODO: WIP</p> <pre><code>curl -sfL https://get.k3s.io | sh -s - agent \\\n--server https://your-lb-ip-address:6443 \\\n--token YOUR-SECRET\n</code></pre>"},{"location":"container/kubernetes/k3s/#k3s-with-embedded-db","title":"K3s with embedded DB","text":"<p>Set up an HA K3s cluster that leverages a built-in distributed database.</p> <p>TODO: WIP</p>"},{"location":"container/kubernetes/k3s/#install-first-server","title":"Install first Server","text":"<p>TODO: WIP</p> <pre><code>curl -sfL https://get.k3s.io | sh -s - server \\\n--token=YOUR-SECRET \\\n--tls-san your-dns-name --tls-san your-lb-ip-address \\\n--cluster-init\n</code></pre> <p>To avoid certificate errors in such a configuration, you should install the server with the <code>--tls-san YOUR_IP_OR_HOSTNAME_HERE</code> option. This option adds an additional hostname or IP as a Subject Alternative Name in the TLS cert, and it can be specified multiple times if you would like to access via both the IP and the hostname.</p>"},{"location":"container/kubernetes/k3s/#install-additional-servers","title":"Install additional Servers","text":"<p>TODO: WIP</p> <pre><code>curl -sfL https://get.k3s.io | sh -s - server \\\n--token=YOUR-SECRET \\\n--tls-san your-dns-name --tls-san your-lb-ip-address \\\n--server https://IP-OF-THE-FIRST-SERVER:6443\n</code></pre> <p>The <code>--cluster-init</code> initializes an HA Cluster with an embedded etcd database. The fault tolerance requires an odd number, minimum three, nodes to function.</p> Total Number of nodes Failed Node Tolerance 1 0 2 0 3 1 4 1 5 2 6 2 ... ..."},{"location":"container/kubernetes/k3s/#get-a-registered-address_1","title":"Get a registered Address","text":"<p>To achieve a high-available scenario you also need to load balance incoming connections between the server nodes.</p> <p>TODO: WIP</p>"},{"location":"container/kubernetes/k3s/#install-agents_1","title":"Install Agents","text":"<p>You can still add additional nodes without a server function to this cluster.</p> <pre><code>curl -sfL https://get.k3s.io | sh -s - agent \\\n--server https://your-lb-ip-address:6443 \\\n--token YOUR-SECRET\n</code></pre>"},{"location":"container/kubernetes/k3s/#k3s-single-node","title":"K3s single node","text":"<p>Set up K3s as a single node installation.</p> <p>TODO: WIP</p>"},{"location":"container/kubernetes/k3s/#manage-k3s","title":"Manage K3S","text":""},{"location":"container/kubernetes/k3s/#management-on-server-nodes","title":"Management on Server Nodes","text":"<p><code>k3s kubectl</code></p>"},{"location":"container/kubernetes/k3s/#download-kube-config","title":"Download Kube Config","text":"<p><code>/etc/rancher/k3s/k3s.yaml</code></p>"},{"location":"container/kubernetes/k3s/#database-backups","title":"Database Backups","text":""},{"location":"container/kubernetes/k3s/#etcd-snapshots","title":"etcd snapshots","text":"<p>Stored in <code>/var/lib/rancher/k3s/server/db/snapshots</code>.</p>"},{"location":"container/kubernetes/k9s/","title":"K9s","text":""},{"location":"container/kubernetes/k9s/#k9s","title":"K9s","text":"<p>K9s is a command line interface to easy up managing Kubernetes Clusters.</p> <p>Core features of k9s are for instance: - Editing of resource manifests - Shell into a Pod / Container - Manage multiple Kubernetes clusters using one tool</p> <p>More information and current releases of k9s, can be found on their Github repository.</p>"},{"location":"container/kubernetes/k9s/#installation","title":"Installation","text":""},{"location":"container/kubernetes/k9s/#on-linux","title":"On Linux","text":""},{"location":"container/kubernetes/k9s/#find-and-download-the-latest-release","title":"Find and download the latest release","text":"<p>Check the release page here and search for the fitting package type (e.g. Linux_x86_64). Copy the link to the archive of your choice. Download and unpack the archive like in this example:</p> <pre><code>wget https://github.com/derailed/k9s/releases/download/v0.26.6/k9s_Linux_x86_64.tar.gz\ntar -xvf k9s_Linux_x86.tar.gz\n</code></pre>"},{"location":"container/kubernetes/k9s/#install-k9s","title":"Install k9s","text":"<pre><code>sudo install -o root -g root -m 0755 k9s /usr/local/bin/k9s\n</code></pre>"},{"location":"container/kubernetes/k9s/#commands","title":"Commands","text":""},{"location":"container/kubernetes/k9s/#cluster-selection","title":"Cluster selection","text":"<p>As soon as you've started k9s, you can use a bunch of commands to interact with your selected cluster (which is the context you have selected in you current shell environment).</p> <p>You can everytime change the cluster you want to work with by typing <code>:context</code>. A list of available cluster configurations appear, you can select the cluster to connect to with the arrow keys and select the context to be used by pressing enter.</p>"},{"location":"container/kubernetes/k9s/#general-command-structure","title":"General command structure","text":"<p>Menu You can switch between resource types to show using a text menu selection. You need to press <code>:</code> to bring up this menu. Then you can type the resource type you want to switch to (e.g. <code>pod</code>, <code>services</code>...). Press the enter key to finish the command.</p> <p>Selection Selections are made with the arrow keys. To confirm your selection or to show more information, use the enter key again. For instance, you can select a pod with the arrow keys and type enter to \"drill down\" in that pod and view the running containers in it.</p> <p>Filter and searches In nearly every screen of k9s, you can apply filters or search for something (e.g. in the log output of a pod). This can be done by pressing <code>/</code> followed by the search / filter term. Press enter so apply the filter / search. Also in some screens, there are shortcuts for namespace filters bound to the number keys. Where <code>0</code> always shows all namespaces.</p>"},{"location":"container/kubernetes/k9s/#useful-shortcuts-and-commands","title":"Useful shortcuts and commands","text":"Command Comment Compareable kubectl command <code>:pod</code> Switches to the pod screen, where you can see all pods on the current cluster. <code>kubectl get pods --all-namespaces</code> <code>:services</code> Switches to the service screen, where you can see all services. <code>kubectl get services --all-namespaces</code> <code>ctrl</code>+<code>d</code> Delete a resource. <code>kubectl delete &lt;resource&gt; -n &lt;namespace&gt;</code> <code>ctrl</code>+<code>k</code> Kill a resource (no confirmation) <code>s</code> When on the Pod screen, you then open a shell into the selected pod. <code>kubectl exec -n &lt;namespace&gt; &lt;pod_name&gt; -c &lt;container_name&gt; -- /bin/bash</code> <code>l</code> Show the log output of a pod. <code>kubectl logs -n &lt;namespace&gt; &lt;pod_name&gt;</code>"},{"location":"container/kubernetes/kind/","title":"Kind","text":""},{"location":"container/kubernetes/kind/#kind","title":"Kind","text":"<p>Using the Kind project, you are able to easily deploy a Kubernetes cluster on top of Docker as Docker containers. Kind will spawn separate containers which be shown as the Kubernetes nodes. In this documentation, you can find some examples, as well as a link to a Ansible playbook which can do the cluster creation / deletion for you. This document only describes the basics of Kind. To find more detailed information, you can check the official Kind documentation.</p> <p>Kind is ideal to use in a local development environment or even during a build pipeline run.</p>"},{"location":"container/kubernetes/kind/#installation-on-linux","title":"Installation on Linux","text":"<p>Since Kind deploys Docker containers, it needs to have a Container engine (like Docker) installed.</p> <p>Installing Kind can be done by downloading the latest available release / binary for your platform:</p> <pre><code>curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.16.0/kind-linux-amd64\nchmod +x ./kind\nsudo mv ./kind /usr/local/bin/kind\n</code></pre>"},{"location":"container/kubernetes/kind/#cluster-management","title":"Cluster management","text":""},{"location":"container/kubernetes/kind/#cluster-creation","title":"Cluster creation","text":"<p>You have to provide a configuration file which tells Kind how you want your Kubernetes cluster to be deployed. Find an example configuration file below:</p> <pre><code>kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nname: testcluster\n# 1 control plane node and 2 workers\nnodes:\n# the control plane node config\n- role: control-plane\n# the two workers\n- role: worker\n- role: worker\n</code></pre> <p>Create the cluster by the following command:</p> <pre><code>kind create cluster --config kind-cluster-config.yaml\nCreating cluster \"testcluster\" ...\nEnsuring node image (kindest/node:v1.25.2)\nPreparing nodes\nWriting configuration\nStarting control-plane\nInstalling CNI\nInstalling StorageClass\nJoining worker nodes\n\nSet kubectl context to \"kind-testcluster\"\nYou can now use your cluster with:\nkubectl cluster-info --context kind-testcluster\n\nNot sure what to do next? Check out https://kind.sigs.k8s.io/docs/user/quick-start/\n</code></pre> <p>Checking for Docker containers running, you can see the following:</p> <pre><code>docker ps -a\n\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES\nac14d8c7a3c9 kindest/node:v1.25.2 \"/usr/local/bin/entr...\" 2 minutes ago Up About a minute testcluster-worker2\n096dd4bf1718 kindest/node:v1.25.2 \"/usr/local/bin/entr...\" 2 minutes ago Up About a minute 127.0.0.1:42319-&gt;6443/tcp testcluster-control-plane\ne1ae2d701394 kindest/node:v1.25.2 \"/usr/local/bin/entr...\" 2 minutes ago Up About a minute testcluster-worker\n</code></pre>"},{"location":"container/kubernetes/kind/#interacting-with-your-cluster","title":"Interacting with your cluster","text":"<p>You may have multiple Kind clusters deployed at the same time. To get a list of running clusters, you can use the following command:</p> <pre><code>kind get clusters\nkind\nkind-2\n</code></pre> <p>After cluster creation, the Kubernetes context is set automatically to the newly created cluster. In order to set the currently used kubeconfig, you may use some tooling like kubectx. You may also set the current context used by <code>kubectl</code> with the <code>--context</code> option, which refers to the Kind cluster name.</p>"},{"location":"container/kubernetes/kind/#cluster-deletion","title":"Cluster deletion","text":"<p>To delete a Kind cluster, you can use the following command. Kind will also delete the kubeconfig of the deleted cluster. So you don't need to do this on your own.</p> <pre><code>kind delete cluster -n testcluster\nDeleting cluster \"testcluster\" ...\n</code></pre>"},{"location":"container/kubernetes/kind/#further-information","title":"Further information","text":"<p>More examples and tutorials regarding Proxmox can be found in the link list below:</p> <ul> <li>Creating an Ansible playbook to manage Kind cluster: Lightweight Kubernetes cluster using Kind and Ansible</li> </ul>"},{"location":"container/kubernetes/kubectl/","title":"Kubectl","text":""},{"location":"container/kubernetes/kubectl/#kubectl","title":"Kubectl","text":"<p>Kubectl is a command line tool for communicating with a Kubernetes Cluster's control pane, using the Kubernetes API.</p> <p>Documentation: Kubectl Reference</p>"},{"location":"container/kubernetes/kubectl/#installation","title":"Installation","text":""},{"location":"container/kubernetes/kubectl/#on-windows-powershell","title":"On Windows (PowerShell)","text":"<p>Install Kubectl with chocolatey:</p> <pre><code>choco install kubernetes-cli\n</code></pre>"},{"location":"container/kubernetes/kubectl/#on-linux","title":"On Linux","text":"<p>[!INFO] Installing on WSL2 On WSL2 it's recommended to install Docker Desktop [[docker-desktop]], which automatically comes with kubectl.</p>"},{"location":"container/kubernetes/kubectl/#download-the-latest-release","title":"Download the latest release","text":"<pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n</code></pre>"},{"location":"container/kubernetes/kubectl/#install-kubectl","title":"Install kubectl","text":"<pre><code>sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n</code></pre>"},{"location":"container/kubernetes/kubectl/#config-management","title":"Config Management","text":""},{"location":"container/kubernetes/kubectl/#multiple-config-files","title":"Multiple Config Files","text":""},{"location":"container/kubernetes/kubectl/#on-windows-powershell_1","title":"On Windows (PowerShell)","text":"<pre><code>$env:KUBECONFIG = \"$HOME/.kube/prod-k8s-clcreative-kubeconfig.yaml;$HOME/.kube/infra-home-kube-prod-1.yml;$HOME/.kube/infra-home-kube-demo-1.yml;$HOME/.kube/infra-cloud-kube-prod-1.yml\"\n</code></pre>"},{"location":"container/kubernetes/kubectl/#on-linux_1","title":"On Linux","text":"<pre><code>export KUBECONFIG=~/.kube/kube-config-1.yml:~/.kube/kube-config-2.yml\n</code></pre> <p>Managing multiple config files manually can become extensive. Below you can find a handy script, which you can implement in your shell rc file (e.g. .bashrc or .zshrc). The script will automatically add all found kubeconfigs to the <code>KUBECONFIG</code> environment variable.</p> <p>Script was copied from here</p> <pre><code># If there's already a kubeconfig file in ~/.kube/config it will import that too and all the contexts\nDEFAULT_KUBECONFIG_FILE=\"$HOME/.kube/config\"\nif test -f \"${DEFAULT_KUBECONFIG_FILE}\"\nthen\n  export KUBECONFIG=\"$DEFAULT_KUBECONFIG_FILE\"\nfi# Your additional kubeconfig files should be inside ~/.kube/config-files\nADD_KUBECONFIG_FILES=\"$HOME/.kube/config-files\"\nmkdir -p \"${ADD_KUBECONFIG_FILES}\"OIFS=\"$IFS\"\nIFS=$'\\n'\nfor kubeconfigFile in `find \"${ADD_KUBECONFIG_FILES}\" -type f -name \"*.yml\" -o -name \"*.yaml\"`\ndo\n    export KUBECONFIG=\"$kubeconfigFile:$KUBECONFIG\"\ndone\nIFS=\"$OIFS\"\n</code></pre> <p>Another helpful tool that makes you changing and selecting the cluster context easier is <code>kubectx</code>. You can download <code>kubectx</code> here.</p> <p> The above script conflicts with kubectx, cause kubectx can only work with one kubeconfig file listed in the <code>KUBECONFIG</code> env var. If you want to use both, add the following lines to your rc file.</p> <pre><code># now we merge all configs to one\nkubectl config view --merge --flatten &gt; $HOME/.kube/merged-config\nexport KUBECONFIG=\"$HOME/.kube/merged-config\"\n</code></pre>"},{"location":"container/kubernetes/kubectl/#commands","title":"Commands","text":""},{"location":"container/kubernetes/kubectl/#networking","title":"Networking","text":"<p>Connect containers using Kubernetes internal DNS system: <code>&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local</code></p> <p>Troubleshoot Networking with a netshoot toolkit Container: <code>kubectl run tmp-shell --rm -i --tty --image nicolaka/netshoot -- /bin/bash</code></p>"},{"location":"container/kubernetes/kubectl/#containers","title":"Containers","text":"<p>Restart Deployments (Stops and Restarts all Pods): <code>kubectl scale deploy &lt;deployment&gt; --replicas=0</code> <code>kubectl scale deploy &lt;deployment&gt; --replicas=1</code></p> <p>Executing Commands on Pods: <code>kubectl exec -it &lt;PODNAME&gt; -- &lt;COMMAND&gt;</code> <code>kubectl exec -it generic-pod -- /bin/bash</code></p>"},{"location":"container/kubernetes/kubectl/#config-and-cluster-management","title":"Config and Cluster Management","text":"COMMAND DESCRIPTION <code>kubectl cluster-info</code> Display endpoint information about the master and services in the cluster <code>kubectl config view</code> Get the configuration of the cluster ### Resource Management COMMAND DESCRIPTION --- --- <code>kubectl get all --all-namespaces</code> List all resources in the entire Cluster <code>kubectl delete &lt;RESOURCE&gt; &lt;RESOURCENAME&gt; --grace-period=0 --force</code> Try to force the deletion of the resource"},{"location":"container/kubernetes/kubectl/#list-of-kubernetes-resources-short-names","title":"List of Kubernetes Resources \"Short Names\"","text":"Short Name Long Name <code>csr</code> <code>certificatesigningrequests</code> <code>cs</code> <code>componentstatuses</code> <code>cm</code> <code>configmaps</code> <code>ds</code> <code>daemonsets</code> <code>deploy</code> <code>deployments</code> <code>ep</code> <code>endpoints</code> <code>ev</code> <code>events</code> <code>hpa</code> <code>horizontalpodautoscalers</code> <code>ing</code> <code>ingresses</code> <code>limits</code> <code>limitranges</code> <code>ns</code> <code>namespaces</code> <code>no</code> <code>nodes</code> <code>pvc</code> <code>persistentvolumeclaims</code> <code>pv</code> <code>persistentvolumes</code> <code>po</code> <code>pods</code> <code>pdb</code> <code>poddisruptionbudgets</code> <code>psp</code> <code>podsecuritypolicies</code> <code>rs</code> <code>replicasets</code> <code>rc</code> <code>replicationcontrollers</code> <code>quota</code> <code>resourcequotas</code> <code>sa</code> <code>serviceaccounts</code> <code>svc</code> <code>services</code>"},{"location":"container/kubernetes/kubectl/#logs-and-troubleshooting","title":"\ufac6 Logs and Troubleshooting","text":"<p>...</p>"},{"location":"container/kubernetes/kubectl/#logs","title":"Logs","text":"<p>...</p>"},{"location":"container/kubernetes/kubectl/#mysql","title":"MySQL","text":"<p><code>kubectl run -it --rm --image=mysql:5.7 --restart=Never mysql-client -- mysql -u USERNAME -h HOSTNAME -p</code></p>"},{"location":"container/kubernetes/kubectl/#networking_1","title":"Networking","text":"<p><code>kubectl run -it --rm --image=nicolaka/netshoot netshoot -- /bin/bash</code></p>"},{"location":"container/kubernetes/kubectl/#resources-stuck-in-terminating-state","title":"Resources stuck in Terminating state","text":"<p>...</p> <pre><code>(\nNAMESPACE=longhorn-demo-1\nkubectl proxy &amp;\nkubectl get namespace $NAMESPACE -o json |jq '.spec = {\"finalizers\":[]}' &gt;temp.json\ncurl -k -H \"Content-Type: application/json\" -X PUT --data-binary @temp.json 127.0.0.1:8001/api/v1/namespaces/$NAMESPACE/finalize\n)\n</code></pre>"},{"location":"container/kubernetes/kubernetes-dns/","title":"Kubernetes DNS","text":""},{"location":"container/kubernetes/kubernetes-dns/#kubernetes-dns","title":"Kubernetes DNS","text":""},{"location":"container/kubernetes/kubernetes-dns/#dns-for-services-and-pods","title":"DNS for Services and Pods","text":"<p>Kubernetes creates DNS records for Services and Pods. You can contact Services with consistent DNS names instead of IP addresses.</p> <pre><code>your-service.your-namespace.svc.cluster.local\n</code></pre> <p>Any Pods exposed by a Service have the following DNS resolution available:</p> <pre><code>your-prod.your-service.your-namespace.svc.cluster.local\n</code></pre>"},{"location":"container/kubernetes/kubernetes-dns/#custom-dns-settings","title":"Custom DNS Settings","text":""},{"location":"container/kubernetes/kubernetes-dns/#edit-coredns-config-map","title":"Edit coredns config map","text":"<p>Add entry to the <code>Corefile: |</code> section of the <code>configmap/coredns</code> in section kube-system.</p> <pre><code>.:53 {\n  # ...\n}\nimport /etc/coredns/custom/*.server\n</code></pre>"},{"location":"container/kubernetes/kubernetes-dns/#add-new-config-map","title":"Add new config map","text":"<p>Example for local DNS server using the clcreative.home zone.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns-custom\n  namespace: kube-system\ndata:\n  clcreative.server: |\n    clcreative.home:53 {\n      forward . 10.20.0.10\n    }\n</code></pre>"},{"location":"container/kubernetes/kubernetes/","title":"Kubernetes","text":""},{"location":"databases/mariadb/","title":"Mariadb","text":""},{"location":"databases/mariadb/#mariadb","title":"Mariadb","text":""},{"location":"databases/mariadb/#installeer-mariadb-op-ubuntu-2004-lts","title":"Installeer MariaDB op Ubuntu 20.04 LTS","text":"<pre><code>sudo apt update\nsudo apt install mariadb-server\nsudo mysql_secure_installation\n</code></pre>"},{"location":"databases/mariadb/#admin-user-aanmaken","title":"Admin user aanmaken","text":"<ol> <li>Maak een nieuwe gebruiker <code>newuser</code> aan voor de host <code>localhost</code> met een nieuw <code>password</code>:</li> </ol> <pre><code>CREATE USER 'newuser'@'localhost' IDENTIFIED BY 'password';\n</code></pre> <ol> <li> <p>Geef alle rechten aan de nieuwe gebruiker </p><pre><code>GRANT ALL PRIVILEGES ON * . * TO 'newuser'@'localhost';\n</code></pre> </li> <li> <p>Werk de rechten bij </p><pre><code>FLUSH PRIVILEGES;\n</code></pre> </li> </ol>"},{"location":"databases/mysql/","title":"MySQL","text":""},{"location":"databases/postgres/","title":"PostgreSQL Cheat-Sheet","text":""},{"location":"databases/postgres/#postgresql-cheat-sheet","title":"PostgreSQL Cheat-Sheet","text":"<p>PostgreSQL or also known as Postgres, is a free and open-source relational database management system. PostgreSQL features transactions with Atomicity, Consistency, Isolation, Durability (ACID) properties automatically updatable views, materialized views, triggers, foreign keys, and stored procedures. It is designed to handle a range of workloads, from single machines to data warehouses or web services with many concurrent users.</p>"},{"location":"databases/postgres/#installation","title":"Installation","text":""},{"location":"databases/postgres/#install-postgresql-12-on-ubuntu-2004-lts","title":"Install PostgreSQL 12 on Ubuntu 20.04 LTS","text":"<pre><code>sudo apt update\nsudo apt install -y postgresql postgresql-contrib postgresql-client\nsudo systemctl status postgresql.service\n</code></pre>"},{"location":"databases/postgres/#install-deploy-postgres-on-kubernetes-with-zalando-postgres-operator","title":"Install / deploy Postgres on Kubernetes with Zalando Postgres Operator","text":"<p>Postgres is probably the database which is most common on Cloud platforms and also, running on Kubernetes environments. There are several so called \"Kubernetes Operators\" which handle the deployment of Postgres clusters for you. One of it is the Postgres Operator by Zalando.</p> <p>You can find some tutorials regarding deployment of the operator and how to work with it, in the link list below:</p> <ul> <li>Deploy Zalando Postgres Operator on your Kubernetes cluster</li> <li>Configure Zalando Postgres Operator Backup with WAL-G</li> <li>Configure Zalando Postgres Operator Restore with WAL-G</li> </ul>"},{"location":"databases/postgres/#initial-database-connection","title":"Initial database connection","text":"<p>A local connection (from the database server) can be done by the following command:</p> <pre><code>sudo -u postgres psql\n\npsql (12.12 (Ubuntu 12.12-0ubuntu0.20.04.1))\nType \"help\" for help.\n\npostgres=#\n</code></pre>"},{"location":"databases/postgres/#set-password-for-postgres-database-user","title":"Set password for postgres database user","text":"<p>The password for the <code>postgres</code> database user can be set the the quickcommand <code>\\password</code> or by <code>alter user postgres password 'Supersecret'</code>. A connection using the <code>postgres</code> user is still not possible from the \"outside\" hence to the default settings in the <code>pg_hba.conf</code>.</p>"},{"location":"databases/postgres/#update-pg_hbaconf-to-allow-postgres-user-connections-with-password","title":"Update pg_hba.conf to allow postgres user connections with password","text":"<p>In order to allow connections of the <code>postgres</code> database user not using OS user authentication, you have to update the <code>pg_hba.conf</code> which can be found under <code>/etc/postgresql/12/main/pg_hba.conf</code>.</p> <pre><code>sudo vi /etc/postgresql/12/main/pg_hba.conf\n\n...\nlocal   all             postgres                                peer\n...\n</code></pre> <p>Change the last section of the above line to <code>md5</code>.</p> <pre><code>local   all             postgres                                md5\n</code></pre> <p>A restart is required in order to apply the new configuration:</p> <pre><code>sudo systemctl restart postgresql\n</code></pre> <p>Now a connection from outside the database host is possible e.g.</p> <pre><code>psql -U postgres -d postgres -h databasehostname\n</code></pre>"},{"location":"databases/postgres/#creation-of-additional-database-users","title":"Creation of additional database users","text":"<p>A database user can be created by the following command:</p> <pre><code>create user myuser with encrypted password 'Supersecret';\nCREATE ROLE\n\npostgres=# \\du\n                                   List of roles\n Role name |                         Attributes                         | Member of\n-----------+------------------------------------------------------------+-----------\n myuser    |                                                            | {}\n postgres  | Superuser, Create role, Create DB, Replication, Bypass RLS | {}\n</code></pre>"},{"location":"databases/postgres/#creation-of-additional-databases","title":"Creation of additional databases","text":"<p>One can create new Postgres databases within an instance. Therefore you can use the <code>psql</code> command to login (see above).</p> <pre><code>CREATE DATABASE dbname OWNER myuser;\nCREATE DATABASE\n\npostgres=# \\l\n                                  List of databases\n   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges\n-----------+----------+----------+-------------+-------------+-----------------------\n dbname    | myuser   | UTF8     | en_US.UTF-8 | en_US.UTF-8 |\n postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |\n template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n           |          |          |             |             | postgres=CTc/postgres\n template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/postgres          +\n           |          |          |             |             | postgres=CTc/postgres\n</code></pre> <p>You can leave the <code>OWNER</code> section of the command, when doing so, the current user will become owner of the newly created database.</p> <p>To change the owner of an existing database later, you can use the following command:</p> <pre><code>postgres=# alter database dbname owner to myuser;\nALTER DATABASE\n</code></pre>"},{"location":"databases/postgres/#backup-and-restore","title":"Backup and Restore","text":"<p>There are near to endless combinations in tools and parameters to backup postgres databases. Below you can find some examples using the Postgres built-in tools <code>pgdump</code>, <code>pg_basebackup</code> and <code>pg_restore</code>.</p>"},{"location":"databases/postgres/#pg_dump-pg_dumpall","title":"pg_dump / pg_dumpall","text":"<p>Using <code>pg_dump</code> or <code>pg_dumpall</code> enables you to extract / export a PostgreSQL database(s) into a (SQL) script file or a custom archive file.</p>"},{"location":"databases/postgres/#pg_dump","title":"pg_dump","text":"<p>The following command creates a custom archive file from a database specified with <code>-d</code>.  Using the <code>--create</code> option will include the SQL commands in the dump script that will create the database before importing it later. The <code>-Z 9</code> option in this example compresses the SQL script created with the highest available compression rate (<code>0-9</code>).</p> <pre><code>pg_dump -h vmdocker -U awx -d awx --create -f -Z 9 /tmp/awx_dump.sql.gz\n</code></pre> <p>The following command creates a custom archive file from a database specified with <code>-d</code>. To export data in custom format, you have to specify so with the <code>-F c</code> option. Custom file dumps have the benefit, that they are compressed by default.</p> <pre><code>pg_dump -h &lt;pg_host&gt; -U &lt;username&gt; -d &lt;database&gt; -F c -f /pg_dump/dumpfile.dmp\n</code></pre> <p>Custom format files can only be restored by <code>pg_restore</code> (see below). A SQL dump can be restored by using <code>psql</code>.</p> <pre><code>psql -d newdb -f db.sql\n</code></pre> <p>A complete guide of <code>pg_dump</code> from the official documentation can be found here.</p>"},{"location":"databases/postgres/#pg_dumpall","title":"pg_dumpall","text":"<p>A full dump of all databases of a Postgres instance can be done by <code>pg_dumpall</code>. It will include also user creation information. A difference to <code>pg_dump</code>, you cannot choose for different output formats. <code>pg_dumpall</code> will always create a SQL script as output. Therefore, you don't need <code>pg_restore</code> for restoring a \"full\" dump. Only <code>psql</code> is needed (see below).</p> <pre><code>pg_dumpall -h &lt;pg_host&gt; -U postgres &gt; database.out\n</code></pre> <p>If you use password authentication it will ask for a password each time. It is convenient to have a <code>~/.pgpass</code> file or <code>PGPASSWORD</code> environment variable set.</p> <p>So importing a full dump is really easy by the following <code>psql</code> command:</p> <pre><code>psql -h &lt;pg_host&gt; -f databaseb.out -U postgres\n</code></pre> <p>A complete guide of <code>pg_dumpall</code> from the official documentation can be found here.</p>"},{"location":"databases/postgres/#pg_restore","title":"pg_restore","text":"<p><code>pg_restore</code> can be used to restore custom file dumps created by <code>pg_dump</code>.</p> <p>The following command will create the database (which has been dumped before). </p><pre><code>pg_restore -h &lt;pg_host&gt; -U &lt;pg_user&gt; -d postgres --create -F c /tmp/db.dmp -v\n</code></pre> <p>A complete guide of <code>pg_restore</code> from the official documentation can be found here.</p>"},{"location":"databases/sqlite/","title":"SQLite Cheat-Sheet","text":""},{"location":"databases/sqlite/#sqlite-cheat-sheet","title":"SQLite Cheat-Sheet","text":"<p>SQLite is a relational database contained in a C library. In contrast to many other databases, SQLite is not a client-server database engine. Rather, it's embedded into an end program.</p> <p>SQLite generally follows the PostgreSQL syntax but does not enforce type checking.</p> <p>You can open a SQLite Database with <code>sqlite3 &lt;filename&gt;</code> directly.</p>"},{"location":"databases/sqlite/#commands","title":"Commands","text":"<p><code>.help</code> Shows all commands <code>.databases</code> Show all existing databases <code>.quit</code> Exists <code>.tables</code> Shows all tables <code>.backup</code> Backups current database</p>"},{"location":"hardware/arduino/","title":"Arduino","text":""},{"location":"hardware/raspberry_pi/","title":"Raspberry Pi","text":""},{"location":"hardware/raspberry_pi/#raspberry-pi","title":"Raspberry Pi","text":""},{"location":"hardware/raspberry_pi/#wat-is-een-raspberry-pi","title":"Wat is een Raspberry Pi?","text":"<p>Een Raspberry Pi is een minicomputer.\u00a0De minicomputer is ongeveer zo net zo groot als een creditcard en past makkelijk in je broekzak. Het is een printplaatje en bevat alle belangrijke componenten die een computer nodig heeft, zoals de ARM-processor en alle benodigde aansluitingen.</p> <p>Stel dat jij een monitor, muis en een toetsenbord zou aansluiten op de Raspberry Pi, dan heb je gewoon een echte computer. Zoals we net al zeiden, bevat de Raspberry Pi veel aansluitingen die een \u201cgewone\u201d computer ook heeft, zoals USB, UTP poort (Internetpoort), HDMI en micro USB (Oplaadpoort/voeding).</p> <p>De Raspberry Pi heeft geen opslag en daarom heb je wel een micro-SD kaartje nodig, anders kan je er weinig mee. Het micro-SD kaartje kan je makkelijk in de micro-SD slot/gleuf doen.</p> <p>Op dit micro-SD kaartje zet je bijvoorbeeld software die je zelf hebt geprogrammeerd. Hiermee stuur je bijvoorbeeld motortjes aan of je verwerkt data van sensoren. Het is bijvoorbeeld ook mogelijk om een besturingssysteem erop te zetten, dat is wat makkelijker werken als je het aansluit op een monitor.</p> <p>Misschien kan je je nu al een beetje indenken dat er heel veel mogelijkheden zijn met een Raspberry Pi, maar daar komen we later in dit artikel op terug.</p> <p>Het is ook wel leuk om even het verleden in te duiken. Aan de universiteit van Cambridge is de Raspberry Pi ontwikkeld.\u00a0Het was vooral bedoeld om kinderen enthousiast te maken om te gaan programmeren. De Raspberry Pi is heel goedkoop vergeleken met een \u201cechte\u201d computer en daarom werd het nog toegankelijker.</p> <p>Door de goedkope prijs was ook het doel om mensen in derdewereldlanden meer kennis te laten maken met een (mini)computer. In 2012 kwam de eerste Raspberry Pi Model B op de markt.</p>"},{"location":"hardware/raspberry_pi/#models","title":"Models","text":"Raspberry Pi Platform CPU RAM I/O Ports Price Raspberry Pi 400 1.8 Hz, Quad-core Broadcom BCM2711 (Cortex-A72) 4GB (LPDDR4) 2 \u00d7 USB 3.0, 1 x USB 2.0 ports, 2 x micro HDMI, 1 x Gigabit Ethernet $70 Raspberry Pi 4B 1.8 Hz, Quad-core Broadcom BCM2711 (Cortex-A72) 8GB (LPDDR4) 2x USB 3.0, 2x USB 2.0, 1x Gigabit Ethernet, 2x micro HDMI $75 Raspberry Pi 4B 1.8 Hz, Quad-core Broadcom BCM2711 (Cortex-A72) 4GB (LPDDR4) 2x USB 3.0, 2x USB 2.0, 1x Gigabit Ethernet, 2x micro HDMI $55 Raspberry Pi 4B 1.8 Hz, Quad-core Broadcom BCM2711 (Cortex-A72) 2GB (LPDDR4) 2x USB 3.0, 2x USB 2.0, 1x Gigabit Ethernet, 2x micro HDMI $35 Raspberry Pi 3B+ 1.4-GHz, 4-core Broadcom BCM2837B0 (Cortex-A53) 1GB 4 x USB 2.0, HDMI, 3.5mm audio $35 Raspberry Pi Zero WH 1-GHz, 1-core Broadcom BCM2835 (ARM1176JZF-S) 512MB 1x micro USB, 1x mini HDMI $17 Raspberry Pi Zero W 1-GHz, 1-core Broadcom BCM2835 (ARM1176JZF-S) 512MB 1x micro USB, 1x mini HDMI $10 Raspberry Pi Zero 1-GHz, 1-core Broadcom BCM2835 (ARM1176JZF-S) 512MB 1x micro USB, 1x mini HDMI $5"},{"location":"hardware/raspberry_pi/#raspberry-pi-os","title":"Raspberry Pi OS","text":"<p>Raspberry Pi OS is a Debian-based [[Operating systems]] for Raspberry Pi. Since 2013, it has been officially provided by the Raspberry Pi Foundation as the primary operating system for the Raspberry Pi family of compact single-board computers.</p>"},{"location":"hardware/raspberry_pi/#ssd-aan-een-raspbarry-pi-hangen","title":"SSD aan een raspbarry pi hangen","text":"<p>In <code>cmdline.txt</code> moet je deze tekst plakken op het einde van de eerste regel:</p> <pre><code>usb-storage.quirks=152d:0578:u\n</code></pre>"},{"location":"infra/synology/","title":"Synology","text":""},{"location":"infra/synology/#install-nano-on-synology","title":"Install Nano on Synology","text":"<p>This post will show you how to install Nano on your Synology NAS. Many people prefer Nano since Nano is easier to use than VIM. Luckily the Synology NAS allows you to add additional software repositories and install Nano easily.</p>"},{"location":"infra/synology/#enable-ssh-access","title":"Enable SSH Access","text":"<p>You must enable SSH access to use Nano on your Synology NAS.</p> <p>Click on the \u2018Control Panel\u2019 icon and then click on \u2018Terminal &amp; SNMP\u2019. Finally, tick the option called \u2018Enable SSH Service\u2019 and click \u2018apply\u2019.</p> <p></p> <p>Synology NAS, Terminal &amp; SNMP, Enable SSH Service</p>"},{"location":"infra/synology/#add-a-repository","title":"Add a repository","text":"<p>Nano is not provided or maintained by Synology, but you can get it from the SynoCommunity repository. In addition, SynoCommunity provides free packages for Synology NAS devices. Visit them at https://synocommunity.com/ and feel free to explore some of the other packages they have to offer, like Git, Home Assistant, and of course, Nano.</p> <p>To add the SynoCommunity repository:</p> <p>Click on the \u2018Package Center\u2019 icon and then click on the \u2018settings\u2019 button.</p> <p>In the \u2018settings\u2019 window \u2018general\u2019 tab, click on the \u2018Synology Inc and trusted publishers\u2019 radio button in the\u2019 trust level\u2019 section.</p> <p></p> <p>Synology NAS, Package Center, Settings, Trust Level</p> <p>On the \u2018settings\u2019 window \u2018package sources\u2019 tab, click on the \u2018Add\u2019 button and add the repository: Name: SynoCommunity Location: http://packages.synocommunity.com/</p> <p>Click on the \u2018Ok\u2019 button once you are done.</p> <p></p> <p>Synology NAS, Package Center, Settings, Add Repository</p>"},{"location":"infra/synology/#install-nano-from-the-repository","title":"Install Nano from the Repository","text":"<p>The final step is to install Nano. To do this, make sure you are still in the \u2018package centre\u2019. Then, click on the \u2018community\u2019 section, find \u2018SynoCli File Tools\u2019 and click on the \u2018install\u2019 button. The SynoCli File Tools package provides the following command-line utilities: less, tree, ncdu, jdupes, rhash, mc, nano, file, detox, rmlint, and rnm v1.1-3. Nano was previously a separate package but is now only available via the SynoCli File Tools package.</p>"},{"location":"infra/synology/#wrapping-up","title":"Wrapping up","text":"<p>You can now run Nano using SSH in the usual way! Type \u2018nano\u2019 and the file name you wish to open. Remember that you will need \u2018sudo\u2019 in some circumstances, depending on what you need to do.</p>"},{"location":"infra/unraid/","title":"Unraid","text":""},{"location":"infra/unraid/#unraid","title":"Unraid","text":""},{"location":"infra/unraid/#errors","title":"Errors","text":"Error message Screenshot Error description Solution Invalid folder cache contained within /mnt Generally speaking, most times when other folders get created within /mnt it is a result of an improperly configured application. This error may or may not cause issues for you  More Information ?"},{"location":"infra/zfs/","title":"ZFS","text":""},{"location":"infra/zfs/#zfs","title":"ZFS","text":"<p>WIP</p> <p>Reference: Oracle Solaris ZFS Administration Guide</p>"},{"location":"infra/zfs/#storage-pools","title":"Storage Pools","text":"<p>WIP</p>"},{"location":"infra/zfs/#stripe","title":"Stripe","text":"<p>ZFS dynamically stripes data across all top-level virtual devices. The decision about where to place data is done at write time, so no fixed-width stripes are created at allocation time.</p> <p>When new virtual devices are added to a pool, ZFS gradually allocates data to the new device in order to maintain performance and disk space allocation policies. Each virtual device can also be a mirror or a RAID-Z device that contains other disk devices or files. This configuration gives you flexibility in controlling the fault characteristics of your pool. </p> <p>Although ZFS supports combining different types of virtual devices within the same pool, avoid this practice. For example, you can create a pool with a two-way mirror and a three-way RAID-Z configuration. However, your fault tolerance is as good as your worst virtual device, RAID-Z in this case. A best practice is to use top-level virtual devices of the same type with the same redundancy level in each device.</p>"},{"location":"infra/zfs/#mirror","title":"Mirror","text":"<p>A mirrored storage pool configuration requires at least two disks, preferably on separate controllers. Many disks can be used in a mirrored configuration. In addition, you can create more than one mirror in each pool. </p>"},{"location":"infra/zfs/#striped-mirror","title":"Striped Mirror","text":"<p>Data is dynamically striped across both mirrors, with data being redundant between each disk appropriately.</p> <p>Currently, the following operations are supported in a ZFS mirrored configuration: - Adding another set of disks for an additional top-level virtual device (vdev) to an existing mirrored configuration. - Attaching additional disks to an existing mirrored configuration. Or, attaching additional disks to a non-replicated configuration to create a mirrored configuration. - Replacing a disk or disks in an existing mirrored configuration as long as the replacement disks are greater than or equal to the size of the device to be replaced. - Detaching a disk in a mirrored configuration as long as the remaining devices provide adequate redundancy for the configuration. - Splitting a mirrored configuration by detaching one of the disks to create a new, identical pool.</p>"},{"location":"infra/zfs/#raid-z","title":"RAID-Z","text":"<p>In addition to a mirrored storage pool configuration, ZFS provides a RAID-Z configuration with either single-, double-, or triple-parity fault tolerance. Single-parity RAID-Z (raidz\u00a0or\u00a0raidz1) is similar to RAID-5. Double-parity RAID-Z (raidz2) is similar to RAID-6.</p> <p>A RAID-Z configuration with N disks of size X with P parity disks can hold approximately <code>(N-P)*X</code> bytes and can withstand P device(s) failing before data integrity is compromised. You need at least two disks for a single-parity RAID-Z configuration and at least three disks for a double-parity RAID-Z configuration. For example, if you have three disks in a single-parity RAID-Z configuration, parity data occupies disk space equal to one of the three disks. Otherwise, no special hardware is required to create a RAID-Z configuration.</p> <p>If you are creating a RAID-Z configuration with many disks, consider splitting the disks into multiple groupings. For example, a RAID-Z configuration with 14 disks is better split into two 7-disk groupings. RAID-Z configurations with single-digit groupings of disks should perform better.</p>"},{"location":"infra/zfs/#scrubbing","title":"Scrubbing","text":"<p>The simplest way to check data integrity is to initiate an explicit scrubbing of all data within the pool. This operation traverses all the data in the pool once and verifies that all blocks can be read. Scrubbing proceeds as fast as the devices allow, though the priority of any I/O remains below that of normal operations. This operation might negatively impact performance, though the pool's data should remain usable and nearly as responsive while the scrubbing occurs.</p> <p>Scrub ZFS Pool: </p><pre><code>zpool scrub POOLNAME\n</code></pre> <p>Example: </p><pre><code>zpool status -v POOLNAME\n\n  pool: store\n state: ONLINE\n  scan: scrub in progress since Fri Nov  4 06:43:51 2022\n    317G scanned at 52.9G/s, 1.09M issued at 186K/s, 3.41T total\n    0B repaired, 0.00% done, no estimated completion time\n</code></pre>"},{"location":"infra/zfs/#resilvering","title":"Resilvering","text":"<p>When a device is replaced, a resilvering operation is initiated to move data from the good copies to the new device. This action is a form of disk scrubbing. Therefore, only one such action can occur at a given time in the pool. If a scrubbing operation is in progress, a resilvering operation suspends the current scrubbing and restarts it after the resilvering is completed.</p>"},{"location":"infra/proxmox/certificate-management/","title":"Proxmox Certificate Management","text":""},{"location":"infra/proxmox/certificate-management/#proxmox-certificate-management","title":"Proxmox Certificate Management","text":""},{"location":"infra/proxmox/certificate-management/#certificates-for-intra-cluster-communication","title":"Certificates for Intra-Cluster Communication","text":"<p>Each Proxmox VE cluster creates by default its own (self-signed) Certificate Authority (CA) and generates a certificate for each node which gets signed by the aforementioned CA. These certificates are used for encrypted communication with the cluster's pveproxy service and the Shell/Console feature if SPICE is used.</p> <p>The CA certificate and key are stored in the Proxmox Cluster File System (pmxcfs).</p>"},{"location":"infra/proxmox/certificate-management/#certificates-for-api-and-web-gui","title":"Certificates for API and Web GUI","text":"<p>The REST API and web GUI are provided by the pveproxy service, which runs on each node. You have the following options for the certificate used by pveproxy:</p> <ul> <li>By default the node-specific certificate in <code>/etc/pve/nodes/NODENAME/pve-ssl.pem</code> is used. This certificate is signed by the cluster CA and therefore not automatically trusted by browsers and operating systems.</li> <li>Use an externally provided certificate (e.g. signed by a commercial CA).</li> <li>Use ACME (Let's Encrypt) to get a trusted certificate with automatic renewal, this is also integrated in the Proxmox VE API and web interface.</li> </ul> <p>For options 2 and 3 the file <code>/etc/pve/local/pveproxy-ssl.pem</code> (and <code>/etc/pve/local/pveproxy-ssl.key</code>, which needs to be without password) is used. Keep in mind that <code>/etc/pve/local</code> is a node specific symlink to <code>/etc/pve/nodes/NODENAME</code>.</p> <p>Certificates are managed with the Proxmox VE Node management command (see the <code>pvenode(1)</code> manpage).</p> <p>Do not replace or manually modify the automatically generated node certificate files in <code>/etc/pve/local/pve-ssl.pem</code> and <code>/etc/pve/local/pve-ssl.key</code> or the cluster CA files in <code>/etc/pve/pve-root-ca.pem</code> and <code>/etc/pve/priv/pve-root-ca.key</code>.</p>"},{"location":"infra/proxmox/certificate-management/#upload-custom-certificate","title":"Upload Custom Certificate","text":"<p>If you already have a certificate which you want to use for a Proxmox VE node you can upload that certificate simply over the web interface. Note that the certificates key file, if provided, mustn't be password protected.</p>"},{"location":"infra/proxmox/certificate-management/#trusted-certificates-via-lets-encrypt-acme","title":"Trusted certificates via Let's Encrypt (ACME)","text":"<p>Proxmox VE includes an implementation of the Automatic Certificate Management Environment ACME protocol, allowing Proxmox VE admins to use an ACME provider like Let's Encrypt for easy setup of TLS certificates which are accepted and trusted on modern operating systems and web browsers out of the box.</p> <p>Currently, the two ACME endpoints implemented are the Let's Encrypt (LE) production and its staging environment. Our ACME client supports validation of http-01 challenges using a built-in web server and validation of dns-01 challenges using a DNS plugin supporting all the DNS API endpoints <code>acme.sh</code> does.</p>"},{"location":"infra/proxmox/certificate-management/#acme-account","title":"ACME Account","text":"<p>You need to register an ACME account per cluster with the endpoint you want to use. The email address used for that account will serve as contact point for renewal-due or similar notifications from the ACME endpoint. You can register and deactivate ACME accounts over the web interface <code>Datacenter -&amp;gt; ACME</code> or using the <code>pvenode</code> command line tool.</p> <pre><code> pvenode acme account register account-name mail@example.com\n</code></pre> <p>Because of rate-limits you should use LE staging for experiments or if you use ACME for the first time.</p>"},{"location":"infra/proxmox/certificate-management/#acme-plugins","title":"ACME Plugins","text":"<p>The ACME plugins task is to provide automatic verification that you, and thus the Proxmox VE cluster under your operation, are the real owner of a domain. This is the basis building block for automatic certificate management.</p> <p>The ACME protocol specifies different types of challenges, for example the http-01 where a web server provides a file with a certain content to prove that it controls a domain. Sometimes this isn't possible, either because of technical limitations or if the address of a record to is not reachable from the public internet. The dns-01 challenge can be used in these cases.  This challenge is fulfilled by creating a certain DNS record in the domain's zone.</p> <p>Proxmox VE supports both of those challenge types out of the box, you can configure plugins either over the web interface under <code>Datacenter -&amp;gt; ACME</code>, or using the <code>pvenode acme plugin add</code> command.</p> <p>ACME Plugin configurations are stored in <code>/etc/pve/priv/acme/plugins.cfg</code>. A plugin is available for all nodes in the cluster.</p>"},{"location":"infra/proxmox/certificate-management/#node-domains","title":"Node Domains","text":"<p>Each domain is node specific. You can add new or manage existing domain entries under Node -&gt; Certificates, or using the <code>pvenode config</code> command.</p> <p>After configuring the desired domain(s) for a node and ensuring that the desired ACME account is selected, you can order your new certificate over the web-interface. On success the interface will reload after 10 seconds.</p> <p>Renewal will happen automatically.</p>"},{"location":"infra/proxmox/certificate-management/#acme-http-challenge-plugin","title":"ACME HTTP Challenge Plugin","text":"<p>There is always an implicitly configured standalone plugin for validating http-01 challenges via the built-in webserver spawned on port 80.</p> <p>The name <code>standalone</code> means that it can provide the validation on it's own, without any third party service. So, this plugin works also for cluster nodes.</p> <p>There are a few prerequisites to use it for certificate management with Let's Encrypts ACME.</p> <ul> <li>You have to accept the ToS of Let's Encrypt to register an account.</li> <li>Port 80 of the node needs to be reachable from the internet.</li> <li>There must be no other listener on port 80.</li> <li>The requested (sub)domain needs to resolve to a public IP of the Node.</li> </ul>"},{"location":"infra/proxmox/certificate-management/#acme-dns-api-challenge-plugin","title":"ACME DNS API Challenge Plugin","text":"<p>On systems where external access for validation via the http-01 method is not possible or desired, it is possible to use the dns-01 validation method. This validation method requires a DNS server that allows provisioning of TXT records via an API.</p>"},{"location":"infra/proxmox/certificate-management/#configuring-acme-dns-apis-for-validation","title":"Configuring ACME DNS APIs for validation","text":"<p>Proxmox VE re-uses the DNS plugins developed for the acme.sh project. Please refer to its documentation for details on configuration of specific APIs.</p> <p>The easiest way to configure a new plugin with the DNS API is using the web interface (<code>Datacenter -&amp;gt; ACME</code>).</p> <p>Choose DNS as challenge type. Then you can select your API provider, enter the credential data to access your account over their API.</p> <p>See the <code>acme.sh</code> How to use DNS API wiki for more detailed information about getting API credentials for your provider.</p> <p>As there are many DNS providers and API endpoints Proxmox VE automatically generates the form for the credentials for some providers. For the others you will see a bigger text area, simply copy all the credentials KEY=VALUE pairs in there.</p>"},{"location":"infra/proxmox/certificate-management/#dns-validation-through-cname-alias","title":"DNS Validation through CNAME Alias","text":"<p>A special alias mode can be used to handle the validation on a different domain/DNS server, in case your primary/real DNS does not support provisioning via an API. Manually set up a permanent CNAME record for <code>_acme-challenge.domain1.example</code> pointing to <code>_acme-challenge.domain2.example</code> and set the alias property in the Proxmox VE node configuration file to <code>domain2.example</code> to allow the DNS server of <code>domain2.example</code> to validate all challenges for <code>domain1.example</code>.</p>"},{"location":"infra/proxmox/certificate-management/#combination-of-plugins","title":"Combination of Plugins","text":"<p>Combining http-01 and dns-01 validation is possible in case your node is reachable via multiple domains with different requirements / DNS provisioning capabilities. Mixing DNS APIs from multiple providers or instances is also possible by specifying different plugin instances per domain. Accessing the same service over multiple domains increases complexity and should be avoided if possible.</p>"},{"location":"infra/proxmox/certificate-management/#automatic-renewal-of-acme-certificates","title":"Automatic renewal of ACME certificates","text":"<p>If a node has been successfully configured with an ACME-provided certificate (either via <code>pvenode</code> or via the GUI), the certificate will be automatically renewed by the <code>pve-daily-update.service</code>. Currently, renewal will be attempted if the certificate has expired already, or will expire in the next 30 days.</p>"},{"location":"infra/proxmox/certificate-management/#acme-examples-with-pvenode","title":"ACME Examples with pvenode","text":"<p>Example: Sample <code>pvenode</code> invocation for using Let's Encrypt certificates</p> <pre><code>root@proxmox:~# pvenode acme account register default mail@example.invalid\nDirectory endpoints:\n0) Let's Encrypt V2 (https://acme-v02.api.letsencrypt.org/directory)\n1) Let's Encrypt V2 Staging (https://acme-staging-v02.api.letsencrypt.org/directory)\n2) Custom\nEnter selection: 1\nTerms of Service: https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf\nDo you agree to the above terms? [y|N]y\n...\nTask OK\nroot@proxmox:~# pvenode config set --acme domains=example.invalid\nroot@proxmox:~# pvenode acme cert order\nLoading ACME account details\nPlacing ACME order\n...\nStatus is 'valid'!\nAll domains validated!\n...\nDownloading certificate\nSetting pveproxy certificate and key\nRestarting pveproxy\nTask OK\n</code></pre> <p>Example: Setting up the OVH API for validating a domain</p> <p>The account registration steps are the same no matter which plugins are used, and are not repeated here.</p> <p>OVH_AK and OVH_AS need to be obtained from OVH according to the OVH API documentation</p> <p>First you need to get all information so you and Proxmox VE can access the API.</p> <pre><code>root@proxmox:~# cat /path/to/api-token\nOVH_AK=XXXXXXXXXXXXXXXX\nOVH_AS=YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\nroot@proxmox:~# source /path/to/api-token\nroot@proxmox:~# curl -XPOST -H\"X-Ovh-Application: $OVH_AK\" -H \"Content-type: application/json\" \\\nhttps://eu.api.ovh.com/1.0/auth/credential  -d '{\n  \"accessRules\": [\n    {\"method\": \"GET\",\"path\": \"/auth/time\"},\n    {\"method\": \"GET\",\"path\": \"/domain\"},\n    {\"method\": \"GET\",\"path\": \"/domain/zone/*\"},\n    {\"method\": \"GET\",\"path\": \"/domain/zone/*/record\"},\n    {\"method\": \"POST\",\"path\": \"/domain/zone/*/record\"},\n    {\"method\": \"POST\",\"path\": \"/domain/zone/*/refresh\"},\n    {\"method\": \"PUT\",\"path\": \"/domain/zone/*/record/\"},\n    {\"method\": \"DELETE\",\"path\": \"/domain/zone/*/record/*\"}\n]\n}'\n{\"consumerKey\":\"ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ\",\"state\":\"pendingValidation\",\"validationUrl\":\"https://eu.api.ovh.com/auth/?credentialToken=AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"}\n(open validation URL and follow instructions to link Application Key with account/Consumer Key)\nroot@proxmox:~# echo \"OVH_CK=ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ\" &amp;gt;&amp;gt; /path/to/api-token\n</code></pre> <p>Now you can setup the ACME plugin:</p> <pre><code>root@proxmox:~# pvenode acme plugin add dns example_plugin --api ovh --data /path/to/api_token\nroot@proxmox:~# pvenode acme plugin config example_plugin\n</code></pre> <pre>\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 key    \u2502 value                                    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 api    \u2502 ovh                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 data   \u2502 OVH_AK=XXXXXXXXXXXXXXXX                  \u2502\n\u2502        \u2502 OVH_AS=YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY  \u2502\n\u2502        \u2502 OVH_CK=ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 digest \u2502 867fcf556363ca1bea866863093fcab83edf47a1 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 plugin \u2502 example_plugin                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 type   \u2502 dns                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</pre> <p>At last you can configure the domain you want to get certificates for and place the certificate order for it:</p> <pre><code>root@proxmox:~# pvenode config set -acmedomain0 example.proxmox.com,plugin=example_plugin\nroot@proxmox:~# pvenode acme cert order\nLoading ACME account details\nPlacing ACME order\nOrder URL: https://acme-staging-v02.api.letsencrypt.org/acme/order/11111111/22222222\nGetting authorization details from 'https://acme-staging-v02.api.letsencrypt.org/acme/authz-v3/33333333'\nThe validation for example.proxmox.com is pending!\n[Wed Apr 22 09:25:30 CEST 2020] Using OVH endpoint: ovh-eu\n[Wed Apr 22 09:25:30 CEST 2020] Checking authentication\n[Wed Apr 22 09:25:30 CEST 2020] Consumer key is ok.\n[Wed Apr 22 09:25:31 CEST 2020] Adding record\n[Wed Apr 22 09:25:32 CEST 2020] Added, sleep 10 seconds.\nAdd TXT record: _acme-challenge.example.proxmox.com\nTriggering validation\nSleeping for 5 seconds\nStatus is 'valid'!\n[Wed Apr 22 09:25:48 CEST 2020] Using OVH endpoint: ovh-eu\n[Wed Apr 22 09:25:48 CEST 2020] Checking authentication\n[Wed Apr 22 09:25:48 CEST 2020] Consumer key is ok.\nRemove TXT record: _acme-challenge.example.proxmox.com\nAll domains validated!\nCreating CSR\nChecking order status\nOrder is ready, finalizing order\nvalid!\nDownloading certificate\nSetting pveproxy certificate and key\nRestarting pveproxy\nTask OK\n</code></pre>"},{"location":"infra/proxmox/certificate-management/#example-switching-from-the-staging-to-the-regular-acme-directory","title":"Example: Switching from the staging to the regular ACME directory","text":"<p>Changing the ACME directory for an account is unsupported, but as Proxmox VE supports more than one account you can just create a new one with the production (trusted) ACME directory as endpoint.  You can also deactivate the staging account and recreate it.</p> <p>Example: Changing the default ACME account from staging to directory using <code>pvenode</code></p> <pre><code>root@proxmox:~# pvenode acme account deactivate default\nRenaming account file from '/etc/pve/priv/acme/default' to '/etc/pve/priv/acme/_deactivated_default_4'\nTask OK\nroot@proxmox:~# pvenode acme account register default example@proxmox.com\nDirectory endpoints:\n0) Let's Encrypt V2 (https://acme-v02.api.letsencrypt.org/directory)\n1) Let's Encrypt V2 Staging (https://acme-staging-v02.api.letsencrypt.org/directory)\n2) Custom\nEnter selection: 0\nTerms of Service: https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf\nDo you agree to the above terms? [y|N]y\n...\nTask OK\n</code></pre>"},{"location":"infra/proxmox/docker_lxc/","title":"Installatie van Docker in een LXC container (turnkey-core) op Proxmox","text":""},{"location":"infra/proxmox/docker_lxc/#installatie-van-docker-in-een-lxc-container-turnkey-core-op-proxmox","title":"Installatie van Docker in een LXC container (turnkey-core) op Proxmox","text":"<p>Volg de stappen hieronder om Docker te installeren in een LXC container (turnkey-core) op Proxmox.</p>"},{"location":"infra/proxmox/docker_lxc/#stap-1-download-het-turnkey-core-sjabloon","title":"Stap 1: Download het turnkey-core sjabloon","text":"<p>De eerste stap is om het turnkey-core sjabloon te downloaden naar je opslag.</p> <ul> <li>Klik op je opslag en klik vervolgens op de knop Templates.</li> <li>Zoek naar het core sjabloon en klik op Download.</li> <li>Wacht tot het downloaden is voltooid.</li> </ul>"},{"location":"infra/proxmox/docker_lxc/#stap-2-maak-een-nieuwe-lxc-container","title":"Stap 2: Maak een nieuwe LXC container","text":"<p>De tweede stap is om een nieuwe LXC container te maken met behulp van het turnkey-core sjabloon.</p> <ul> <li>Klik op de knop Create CT in de rechterbovenhoek.</li> <li>Voer een Hostname in, bijvoorbeeld <code>docker</code>.</li> <li>Voer het Password in dat je wilt gebruiken. Dit wachtwoord wordt gebruikt om in te loggen op de root gebruikersaccount. Nadat alle instellingen zijn opgegeven, klik je op Next.</li> <li>Selecteer het Template, bijvoorbeeld <code>local:vztmpl/turnkey-core-16.1-buster-amd64.tar.gz</code>, en klik op Next.</li> <li>Selecteer de Disk Size voor deze container, bijvoorbeeld <code>8 GB</code>, en klik op Next.</li> <li>Selecteer het totale aantal Cores voor de CPU, bijvoorbeeld <code>2</code>, en klik op Next.</li> <li>Stel het totale Memory in, bijvoorbeeld <code>2 GB</code>, en klik op Next. <p>Let op: dit is de limiet die deze container kan gebruiken.</p> </li> <li>Wijzig het Network naar DHCP voor IPv4 en IPv6 (tenzij je ze handmatig wilt opgeven), en klik op Next tot je bij Confirm komt. <p>Let op: we slaan het DNS-gedeelte over, maar je kunt deze instellingen wijzigen als je een andere DNS-server wilt gebruiken dan de Proxmox host.</p> </li> <li>Bevestig de instellingen en klik op Finish om de container te maken!</li> </ul>"},{"location":"infra/proxmox/docker_lxc/#stap-3-start-de-lxc-container-en-log-in","title":"Stap 3: Start de LXC container en log in","text":"<p>De derde stap is om de LXC container te starten en in te loggen met behulp van ssh.</p> <ul> <li>Selecteer de LXC container die we zojuist hebben gemaakt en klik op Start.</li> <li>Klik vervolgens op Console om toegang te krijgen tot de terminal van de container.</li> <li>Log in met de gebruikersnaam <code>root</code> en het wachtwoord dat je in stap twee hebt ingesteld.</li> <li>Je wordt gevraagd om de appliance te initialiseren. Volg de instructies op het scherm om akkoord te gaan met de licentieovereenkomst, een nieuw root wachtwoord in te stellen, een domeinnaam in te voeren, een API-sleutel voor TurnKey Hub over te slaan en beveiligingsupdates toe te staan.</li> </ul>"},{"location":"infra/proxmox/docker_lxc/#stap-4-installeer-docker-in-de-lxc-container","title":"Stap 4: Installeer Docker in de LXC container","text":"<p>De vierde stap is om Docker te installeren in de LXC container.</p> <ul> <li>Voer het volgende commando uit om het systeem bij te werken:</li> </ul> <pre><code>apt update &amp;&amp; apt upgrade -y\n</code></pre> <ul> <li>Voer vervolgens het volgende commando uit om Docker te installeren:</li> </ul> <pre><code>curl -fsSL https://get.docker.com | sh\n</code></pre> <ul> <li>Voeg de root gebruiker toe aan de docker groep met het volgende commando:</li> </ul> <pre><code>usermod -aG docker root\n</code></pre> <ul> <li>Start de docker service met het volgende commando:</li> </ul> <pre><code>systemctl start docker\n</code></pre> <ul> <li>Controleer of docker correct werkt met het volgende commando:</li> </ul> <pre><code>docker run hello-world\n</code></pre> <p>Je zou een bericht moeten zien dat bevestigt dat Docker succesvol is ge\u00efnstalleerd en dat je een container kunt uitvoeren.</p> <p>Gefeliciteerd, je hebt Docker ge\u00efnstalleerd in een LXC container (turnkey-core) op Proxmox!</p>"},{"location":"infra/proxmox/docker_lxc/#links","title":"Links","text":"<ul> <li>How to Set Up Docker Containers in Proxmox - WunderTech</li> <li>Docker | TurnKey GNU/Linux</li> <li>Setup and Install Docker in a Proxmox LXC Conainer | The Homelab Wiki</li> </ul>"},{"location":"infra/proxmox/proxmox/","title":"Proxmox Cheat-Sheet","text":""},{"location":"infra/proxmox/proxmox/#proxmox-cheat-sheet","title":"Proxmox Cheat-Sheet","text":"<p>Proxmox is een krachtige open-source serveroplossing die verschillende producten omvat.</p> <ul> <li>Proxmox VE is een platform voor enterprise virtualisatie dat KVM en Linux Containers (LXC) integreert.</li> <li>Proxmox Mail Gateway is een e-mailbeveiligingsoplossing die je mailserver beschermt tegen alle e-maildreigingen.</li> <li>Proxmox Backup Server is een backupoplossing voor het effici\u00ebnt back-uppen en herstellen van VM\u2019s, containers en fysieke hosts.</li> </ul> <p>Je kunt Proxmox software downloaden van hun website.</p> <p></p>"},{"location":"infra/proxmox/proxmox/#installatie-van-proxmox-ve","title":"Installatie van Proxmox VE","text":"<p>Volg de stappen hieronder om Proxmox VE te installeren op een fysieke of dedicated server.</p>"},{"location":"infra/proxmox/proxmox/#stap-1-download-het-proxmox-iso-bestand","title":"Stap 1: Download het Proxmox ISO-bestand","text":"<p>De eerste stap is om het Proxmox VE ISO-bestand te downloaden.</p> <ul> <li>Ga naar de offici\u00eble Proxmox Downloads pagina en selecteer Proxmox Virtual Environment.</li> <li>Dit brengt je naar het Proxmox Virtual Environment Archive dat ISO-bestanden en offici\u00eble documentatie opslaat. Selecteer ISO Images om verder te gaan.</li> <li>Op het moment van schrijven is de nieuwste versie van de Proxmox VE ISO Installer 7.1. Als er een nieuwere versie beschikbaar is, staat deze bovenaan. Klik op Download en sla het bestand op.</li> </ul>"},{"location":"infra/proxmox/proxmox/#stap-2-bereid-het-installatiemedium-voor","title":"Stap 2: Bereid het installatiemedium voor","text":"<p>Kopieer het Proxmox ISO-bestand op een CD/DVD of een USB-stick.</p> <ul> <li>Hoewel beide opties mogelijk zijn, wordt aangenomen dat de meeste systemen geen optische drive hebben.</li> <li>Steek de USB-stick in en kopieer het ISO-bestand naar de USB-stick met behulp van de opdrachtregel of een USB-formatteringstool (zoals Etcher of Rufus).</li> </ul> <p>Alert</p> <p>Let op: Zorg ervoor dat je USB-stick minstens 1 GB aan opslagruimte heeft. Maak ook een back-up van en verwijder alle gegevens op het apparaat, want het proces zal alle eerder opgeslagen gegevens wissen.</p> <p>Als je op Linux werkt, is de snelste manier om een opstartbare USB te maken, de volgende opdracht uit te voeren:</p> <pre><code>dd bs=1M conv=fdatasync if=./proxmox-ve_*.iso of=/device/name\n</code></pre> <p>Pas indien nodig de bestandsnaam en het pad aan in <code>if=./proxmox-ve_*.iso</code> en zorg ervoor dat je de juiste apparaatnaam opgeeft in <code>of=/device/name</code>.</p> <p>Om de naam van je USB-stick te vinden, voer je de volgende opdracht uit voor en na het inpluggen van het apparaat:</p> <pre><code>lsblk\n</code></pre> <p>Vergelijk de uitvoer. De extra vermelding in de tweede uitvoer is de naam van het apparaat.</p>"},{"location":"infra/proxmox/proxmox/#stap-3-start-de-proxmox-installer","title":"Stap 3: Start de Proxmox Installer","text":"<ul> <li>Ga naar de server (machine) waarop je Proxmox wilt installeren en steek de USB-stick in.</li> <li>Terwijl de server opstart, ga je naar het opstartmenu door op de vereiste toets(en) te drukken. Meestal zijn dit Esc, F2, F10, F11 of F12.</li> <li>Selecteer het installatiemedium met het Proxmox ISO-bestand en start ervan op.</li> <li>Vervolgens verschijnt het Proxmox VE-menu. Selecteer Install Proxmox VE om de standaardinstallatie te starten.</li> </ul>"},{"location":"infra/proxmox/proxmox/#stap-4-voer-proxmox-uit","title":"Stap 4: Voer Proxmox uit","text":"<ul> <li>Volg de instructies op het scherm om Proxmox te installeren. Je moet onder andere akkoord gaan met de licentieovereenkomst, een doelschijf selecteren, een land en tijdzone kiezen, een wachtwoord instellen en een netwerkconfiguratie invoeren.</li> <li>Na het voltooien van de installatie wordt je gevraagd om de server opnieuw op te starten. Verwijder het installatiemedium en klik op Reboot.</li> <li>Zodra de server is herstart, zie je een scherm met informatie over hoe je toegang kunt krijgen tot Proxmox via een webconsole of een commandoregel.</li> </ul>"},{"location":"infra/proxmox/proxmox/#stap-5-maak-een-vm","title":"Stap 5: Maak een VM","text":"<ul> <li>Om toegang te krijgen tot Proxmox via een webconsole, open je een browser en ga je naar het adres dat wordt weergegeven op het scherm, bijvoorbeeld <code>https://192.168.1.100:8006</code>. Je moet een beveiligingswaarschuwing accepteren om door te gaan.</li> <li>Log in met de gebruikersnaam root en het wachtwoord dat je tijdens de installatie hebt ingesteld.</li> <li>Je ziet nu het Proxmox-dashboard, waar je virtuele machines en containers kunt maken en beheren.</li> <li>Om een nieuwe VM te maken, klik je op Create VM in de rechterbovenhoek. Volg de wizard om de VM te configureren met de gewenste opties, zoals naam, besturingssysteem, schijf, netwerk, enz.</li> <li>Nadat je de VM hebt gemaakt, kun je deze starten, stoppen, klonen, verwijderen of wijzigen met behulp van de knoppen in het paneel.</li> </ul>"},{"location":"infra/proxmox/proxmox/#configuratie-van-proxmox-ve","title":"Configuratie van Proxmox VE","text":"<p>Hier zijn enkele veelvoorkomende taken die je kunt uitvoeren om Proxmox VE naar wens te configureren.</p>"},{"location":"infra/proxmox/proxmox/#start-de-vm-bij-het-opstarten","title":"Start de VM bij het opstarten","text":"<ul> <li>Als je wilt dat een VM automatisch wordt gestart wanneer de host wordt opgestart, kun je dit inschakelen in de instellingen van de VM.</li> <li>Selecteer de VM in het linkerpaneel en klik op Options. Klik vervolgens op Start at boot en selecteer Yes in het vervolgkeuzemenu.</li> </ul>"},{"location":"infra/proxmox/proxmox/#vergrootverklein-de-virtuele-schijfgrootte","title":"Vergroot/verklein de virtuele schijfgrootte","text":"<ul> <li>Als je de grootte van de virtuele schijf van een VM wilt wijzigen, moet je eerst de VM uitschakelen.</li> <li>Selecteer de VM in het linkerpaneel en klik op Hardware. Klik vervolgens op Hard Disk en klik op Resize disk in het menu.</li> <li>Voer de nieuwe grootte in die je wilt toewijzen aan de schijf en klik op Resize.</li> </ul> <p>Note</p> <p>Let op: je kunt de schijf alleen vergroten, niet verkleinen.</p>"},{"location":"infra/proxmox/proxmox/#schakel-nat-netwerkmodus-in","title":"Schakel NAT-netwerkmodus in","text":"<ul> <li>Als je wilt dat je VM\u2019s verbinding kunnen maken met internet via een gedeeld IP-adres van de host, kun je NAT-netwerkmodus inschakelen.</li> <li>Selecteer de host in het linkerpaneel en klik op System. Klik vervolgens op Network en klik op Create in het menu.</li> <li>Selecteer Linux Bridge als type en voer een naam in voor de brug, bijvoorbeeld <code>vmbr1</code>. Schakel het selectievakje NAT in en klik op Create.</li> <li>Selecteer nu een VM die je wilt verbinden met internet via NAT en klik op Hardware. Klik vervolgens op Network Device en klik op Edit in het menu.</li> <li>Selecteer <code>vmbr1</code> als brug en klik op OK. Herhaal dit voor elke VM die je wilt verbinden met internet via NAT.</li> </ul>"},{"location":"infra/proxmox/proxmox/#links","title":"Links","text":"<ul> <li>Proxmox VE Documentation</li> <li>Install Proxmox VE {Step-by-Step Guide} - phoenixNAP</li> <li>Installation - Proxmox VE</li> </ul>"},{"location":"infra/proxmox/proxmox/#vm-beheer","title":"VM Beheer","text":""},{"location":"infra/proxmox/proxmox/#basic","title":"Basic","text":"<pre><code># Lijst van vm's\nqm list\n\n# Maak of restore een vm.\nqm create &lt;vmid&gt;\n\n# start een VM\nqm start &lt;vmid&gt;\n\n# vm opschorten.\nqm suspend &lt;vmid&gt;\n\n# vm uitschakelen\nqm shutdown &lt;vmid&gt;\n\n# vm herstarten\nqm reboot &lt;vmid&gt;\n\n# vm resetten\nqm reset &lt;vmid&gt;\n\n# vm stoppen\nqm stop &lt;vmid&gt;\n\n# Vernietig de VM en alle gebruikte/eigen volumes.\n# Verwijdert alle vm-specifieke machtigingen en firewallregels\nqm destroy &lt;vmid&gt;\n\n# Ga naar de Qemu Monitor interface.\nqm monitor &lt;vmid&gt;\n\n# Haal de configuratie van de vm op met zowel de huidige als de in behandeling zijnde waarden.\nqm pending &lt;vmid&gt;\n\n# Stuur key event naar vm.\nqm sendkey &lt;vmid&gt; &lt;key&gt; [OPTIONS]\n\n# Laat de command line zien die wordt gebruikt om de VM te starten (debug info).\nqm showcmd &lt;vmid&gt; [OPTIONS]\n\n# Ontgrendel de vm.\nqm unlock &lt;vmid&gt;\n\n# Clone een VM\nqm clone &lt;vmid&gt; &lt;newid&gt;\n\n# Migreer een VM\nqm migrate &lt;vmid&gt; &lt;target-node&gt;\n\n# Toon VM status\nqm status &lt;vmid&gt;\n\n# Resources voor een vm opschonen\nqm cleanup &lt;vmid&gt; &lt;clean-shutdown&gt; &lt;guest-requested&gt;\n\n# Maak een template\nqm template &lt;vmid&gt; [OPTIONS]\n\n# Opties voor virtuele machines instellen (synchrone API)\nqm set &lt;vmid&gt; [OPTIONS]\n</code></pre>"},{"location":"infra/proxmox/proxmox/#cloudinit","title":"Cloudinit","text":"<pre><code># Get automatically generated cloudinit config.\nqm cloudinit dump &lt;vmid&gt; &lt;type&gt;\n\n# Get the cloudinit configuration with both current and pending values.\nqm cloudinit pending &lt;vmid&gt;\n\n# Regenerate and change cloudinit config drive.\nqm cloudinit update &lt;vmid&gt;\n</code></pre>"},{"location":"infra/proxmox/proxmox/#disk","title":"Disk","text":"<pre><code># Importeer een externe schijfkopie als een ongebruikte schijf in een VM.\n# Het afbeeldingsformaat moet worden ondersteund door qemu-img(1).\nqm disk import &lt;vmid&gt; &lt;source&gt; &lt;storage&gt;\n\n# Verplaats het volume naar een andere opslag of naar een andere VM.\nqm disk move &lt;vmid&gt; &lt;disk&gt; [&lt;storage&gt;] [OPTIONS]\n\n# Scan alle opslag opnieuw en update schijfgroottes en ongebruikte schijfkopie\u00ebn.\nqm disk rescan [OPTIONS]\n\n# Vergroot de volume.\nqm disk resize &lt;vmid&gt; &lt;disk&gt; &lt;size&gt; [OPTIONS]\n\n# Unlink/verwijder disk images.\nqm disk unlink &lt;vmid&gt; --idlist &lt;string&gt; [OPTIONS]\n\n# rescan volumes\nqm rescan\n</code></pre>"},{"location":"infra/proxmox/proxmox/#web-gui","title":"Web GUI","text":"<pre><code># Herstart web GUI\nservice pveproxy restart\n</code></pre>"},{"location":"infra/proxmox/proxmox/#resize-disk","title":"Resize Disk","text":""},{"location":"infra/proxmox/proxmox/#vergroot-de-schijfgrootte","title":"Vergroot de schijfgrootte","text":"<p>Vergroot de schijfgrootte in de GUI of met de volgend command:</p> <pre><code>qm resize 100 virtio0 +5G\n</code></pre>"},{"location":"infra/proxmox/proxmox/#verklein-schijfgrootte","title":"Verklein Schijfgrootte","text":"<p>Voordat u de schijfgrootte in Proxmox verkleint, moet u een back-up maken!</p> <ol> <li>Converteer qcow2 naar raw</li> </ol> <pre><code>qemu-img convert vm-100.qcow2 vm-100.raw\n</code></pre> <ol> <li>Verklein de disk</li> </ol> <pre><code>qemu-img resize -f raw vm-100.raw 10G\n</code></pre> <ol> <li>Converteer terug naar qcow2</li> </ol> <pre><code>qemu-img convert -p -O qcow2 vm-100.raw vm-100.qcow2\n</code></pre>"},{"location":"infra/proxmox/proxmox/#disk-management","title":"Disk Management","text":""},{"location":"infra/proxmox/proxmox/#ubuntu-vm-disk-vergroten-in-proxmox","title":"Ubuntu VM Disk vergroten in Proxmox","text":"<p>Als je in Proxmox een disk vergroot, zal deze door de OS nog niet volledig gebruikt kunnen worden. Daarom moeten we, na de vergroting in proxmox, deze alsnog met GParted en via de CLI resizen zodat de volledige grootte herkend kan worden door het OS.</p>"},{"location":"infra/proxmox/proxmox/#1-virtuele-machine-uitzetten","title":"1. Virtuele machine uitzetten","text":"<p>Schakel de virtuele machine eerst helemaal uit.</p>"},{"location":"infra/proxmox/proxmox/#2-harde-schijf-resizen","title":"2. Harde schijf resizen","text":"<p>Nu kan je de harde schijf vergroten.</p> <p><code>Proxmox</code> &gt; <code>Hardware Settings</code></p>"},{"location":"infra/proxmox/proxmox/#3-gparted-downloaden-en-opstarten","title":"3. GParted downloaden en opstarten","text":"<ol> <li>Download laatste Gparted ISO van de GParted download website</li> <li>Importeer de GParted ISO file in Proxmox</li> <li>Start de VM en laat deze starten vanaf de ISO. (Duw snel op Esc)</li> </ol>"},{"location":"infra/proxmox/proxmox/#4-partitie-resizen-met-gparted","title":"4. Partitie resizen met GParted","text":"<ol> <li>Zoek de correcte partitie</li> <li>Resize de partitie (Right Button -&gt; resize)</li> <li>Duw opt vingske \ud83d\ude42</li> </ol>"},{"location":"infra/proxmox/proxmox/#5-cli-resizing","title":"5. CLI resizing","text":"<p>Check de huidige disksize met commando:</p> <pre><code>df -h\n</code></pre> <p>Laat Ubuntu de volledige disk gebruiken:</p> <pre><code>sudo /sbin/lvresize -l +100%FREE /dev/mapper/ubuntu--vg-ubuntu--lv\n</code></pre> <p>Gebruik resize2fs op deze disk</p> <pre><code>sudo /sbin/resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv\n</code></pre> <p>Hierna kan je nogmaals de disksize bekijken.</p> <pre><code>df -h\n</code></pre> <p>Als er geen fouten opgetreden zijn, heb je nu net de harde schijf vergroot!</p>"},{"location":"infra/proxmox/proxmox/#snapshot","title":"Snapshot","text":"<pre><code># List all snapshots.\nqm listsnapshot &lt;vmid&gt;\n\n# Snapshot a VM\nqm snapshot &lt;vmid&gt; &lt;snapname&gt;\n\n# Delete a snapshot.\nqm delsnapshot &lt;vmid&gt; &lt;snapname&gt;\n\n# Rollback a snapshot\nqm rollback &lt;vmid&gt; &lt;snapname&gt;\n\n# Open a terminal using a serial device\n# (The VM need to have a serial device configured, for example serial0: socket)\nqm terminal &lt;vmid&gt; [OPTIONS]\n\n# Proxy VM VNC traffic to stdin/stdout\nqm vncproxy &lt;vmid&gt;\n</code></pre>"},{"location":"infra/proxmox/proxmox/#misc","title":"Misc","text":"<pre><code># Execute Qemu Guest Agent commands.\nqm guest cmd &lt;vmid&gt; &lt;command&gt;\n\n# Executes the given command via the guest agent\nqm guest exec &lt;vmid&gt; [&lt;extra-args&gt;] [OPTIONS]\n\n# Gets the status of the given pid started by the guest-agent\nqm guest exec-status &lt;vmid&gt; &lt;pid&gt;\n\n# Sets the password for the given user to the given password\nqm guest passwd &lt;vmid&gt; &lt;username&gt; [OPTIONS]\n</code></pre>"},{"location":"infra/proxmox/proxmox/#pv-vg-lv-management","title":"PV, VG, LV Management","text":"<pre><code># Create a PV\npvcreate &lt;disk-device-name&gt;\n\n# Remove a PV\npvremove &lt;disk-device-name&gt;\n\n# List all PVs\npvs\n\n# Create a VG\nvgcreate &lt;vg-name&gt; &lt;disk-device-name&gt;\n\n# Remove a VG\nvgremove &lt;vg-name&gt;\n\n# List all VGs\nvgs\n\n# Create a LV\nlvcreate -L &lt;lv-size&gt; -n &lt;lv-name&gt; &lt;vg-name&gt;\n\n# Remove a LV\nlvremove &lt;vg-name&gt;/&lt;lv-name&gt;\n\n# List all LVs\nlvs\n</code></pre>"},{"location":"infra/proxmox/proxmox/#storage-management","title":"Storage Management","text":"<pre><code># Create a new storage.\npvesm add &lt;type&gt; &lt;storage&gt; [OPTIONS]\n\n# Allocate disk images.\npvesm alloc &lt;storage&gt; &lt;vmid&gt; &lt;filename&gt; &lt;size&gt; [OPTIONS]\n\n# Delete volume\npvesm free &lt;volume&gt; [OPTIONS]\n\n# Delete storage configuration.\npvesm remove &lt;storage&gt;\n\n# List storage content.\npvesm list &lt;storage&gt; [OPTIONS]\n\n# An alias for pvesm scan lvm.\npvesm lvmscan\n\n# An alias for pvesm scan lvmthin.\npvesm lvmthinscan\n\n# List local LVM volume groups.\npvesm scan lvm\n\n# List local LVM Thin Pools.\npvesm scan lvmthin &lt;vg&gt;\n\n# Get status for all datastores.\npvesm status [OPTIONS]\n</code></pre>"},{"location":"infra/proxmox/proxmox/#template-management","title":"Template Management","text":"<pre><code># list all templates\npveam available\n\n# list all templates\npveam list &lt;storage&gt;\n\n# Download appliance templates\npveam download &lt;storage&gt; &lt;template&gt;\n\n# Remove a template.\npveam remove &lt;template-path&gt;\n\n# Update Container Template Database.\npveam update\n</code></pre>"},{"location":"infra/proxmox/proxmox/#certificate-management","title":"Certificate Management","text":"<p>See the Proxmox Certificate Management cheat sheet.</p>"},{"location":"infra/proxmox/proxmox/#container-management","title":"Container Management","text":""},{"location":"infra/proxmox/proxmox/#basic_1","title":"Basic","text":"<pre><code># List containers\npct list\n\n# Create or restore a container.\npct create &lt;vmid&gt; &lt;ostemplate&gt; [OPTIONS]\n\n# Start the container.\npct start &lt;vmid&gt; [OPTIONS]\n\n# Create a container clone/copy\npct clone &lt;vmid&gt; &lt;newid&gt; [OPTIONS]\n\n# Suspend the container. This is experimental.\npct suspend &lt;vmid&gt;\n\n# Resume the container.\npct resume &lt;vmid&gt;\n\n# Stop the container.\n# This will abruptly stop all processes running in the container.\npct stop &lt;vmid&gt; [OPTIONS]\n\n# Shutdown the container.\n# This will trigger a clean shutdown of the container, see lxc-stop(1) for details.\npct shutdown &lt;vmid&gt; [OPTIONS]\n\n# Destroy the container (also delete all uses files).\npct destroy &lt;vmid&gt; [OPTIONS]\n\n# Show CT status.\npct status &lt;vmid&gt; [OPTIONS]\n\n# Migrate the container to another node. Creates a new migration task.\npct migrate &lt;vmid&gt; &lt;target&gt; [OPTIONS]\n\n# Get container configuration.\npct config &lt;vmid&gt; [OPTIONS]\n\n# Print the list of assigned CPU sets.\npct cpusets\n\n# Get container configuration, including pending changes.\npct pending &lt;vmid&gt;\n\n# Reboot the container by shutting it down, and starting it again. Applies pending changes.\npct reboot &lt;vmid&gt; [OPTIONS]\n\n# Create or restore a container.\npct restore &lt;vmid&gt; &lt;ostemplate&gt; [OPTIONS]\n\n# Set container options.\npct set &lt;vmid&gt; [OPTIONS]\n\n# Create a Template.\npct template &lt;vmid&gt;\n\n# Unlock the VM.\npct unlock &lt;vmid&gt;\n</code></pre>"},{"location":"infra/proxmox/proxmox/#container-disks","title":"Container Disks","text":"<pre><code># Get the container?s current disk usage.\npct df &lt;vmid&gt;\n\n# Run a filesystem check (fsck) on a container volume.\npct fsck &lt;vmid&gt; [OPTIONS]\n\n# Run fstrim on a chosen CT and its mountpoints.\npct fstrim &lt;vmid&gt; [OPTIONS]\n\n# Mount the container?s filesystem on the host.\n# This will hold a lock on the container and is meant for emergency maintenance only\n# as it will prevent further operations on the container other than start and stop.\npct mount &lt;vmid&gt;\n\n# Move a rootfs-/mp-volume to a different storage or to a different container.\npct move-volume &lt;vmid&gt; &lt;volume&gt; [&lt;storage&gt;] [&lt;target-vmid&gt;] [&lt;target-volume&gt;] [OPTIONS]\n\n# Unmount the container?s filesystem.\npct unmount &lt;vmid&gt;\n\n# Resize a container mount point.\npct resize &lt;vmid&gt; &lt;disk&gt; &lt;size&gt; [OPTIONS]\n\n# Rescan all storages and update disk sizes and unused disk images.\npct rescan [OPTIONS]\n\n# Connect to container\npct enter &lt;vmid&gt;\n\n# Launch a console for the specified container.\npct console &lt;vmid&gt; [OPTIONS]\n\n# Launch a shell for the specified container.\npct enter &lt;vmid&gt;\n\n# Launch a command inside the specified container.\npct exec &lt;vmid&gt; [&lt;extra-args&gt;]\n\n# Copy a file from the container to the local system.\npct pull &lt;vmid&gt; &lt;path&gt; &lt;destination&gt; [OPTIONS]\n\n# Copy a local file to the container.\npct push &lt;vmid&gt; &lt;file&gt; &lt;destination&gt; [OPTIONS]\n</code></pre>"},{"location":"infra/proxmox/proxmox/#container-snapshot","title":"Container Snapshot","text":"<pre><code># Snapshot a container.\npct snapshot &lt;vmid&gt; &lt;snapname&gt; [OPTIONS]\n\n# List all snapshots.\npct listsnapshot &lt;vmid&gt;\n\n# Rollback LXC state to specified snapshot.\npct rollback &lt;vmid&gt; &lt;snapname&gt; [OPTIONS]\n\n# Delete a LXC snapshot.\npct delsnapshot &lt;vmid&gt; &lt;snapname&gt; [OPTIONS]\n</code></pre>"},{"location":"infra/proxmox/proxmox/#web-gui_1","title":"Web GUI","text":"<pre><code># Restart web GUI\nservice pveproxy restart\n</code></pre>"},{"location":"infra/proxmox/proxmox/#resize-disk_1","title":"Resize Disk","text":""},{"location":"infra/proxmox/proxmox/#increase-disk-size","title":"Increase disk size","text":"<p>Increase disk size in the GUI or with the following command</p> <pre><code>qm resize 100 virtio0 +5G\n</code></pre>"},{"location":"infra/proxmox/proxmox/#decrease-disk-size","title":"Decrease disk size","text":"<p>Before decreasing disk sizes in Proxmox, you should take a backup!</p> <ol> <li>Convert qcow2 to raw</li> </ol> <pre><code>qemu-img convert vm-100.qcow2 vm-100.raw\n</code></pre> <ol> <li>Shrink the disk</li> </ol> <pre><code>qemu-img resize -f raw vm-100.raw 10G\n</code></pre> <ol> <li>Convert back to qcow2#</li> </ol> <pre><code>qemu-img convert -p -O qcow2 vm-100.raw vm-100.qcow2\n</code></pre>"},{"location":"infra/proxmox/proxmox/#further-information","title":"Further information","text":"<p>More examples and tutorials regarding Proxmox can be found in the link list below:</p> <ul> <li>Ansible playbook that automates Linux VM updates running on Proxmox (including snapshots): TheDatabaseMe - update_proxmox_vm</li> <li>Manage Proxmox VM templates with Packer: Use Packer to build Proxmox images</li> </ul>"},{"location":"infra/proxmox/proxmox/#plex-on-proxmox","title":"Plex on Proxmox","text":"<p>Bekijk deze note voor meer informatie om Plex via LXC te installeren op Proxmox</p>"},{"location":"infra/proxmox/proxmox/#post-installatie-script","title":"Post-installatie script","text":"<p>script</p>"},{"location":"infra/proxmox/proxmox/#proxmox-ve-helper-scripts","title":"Proxmox VE Helper Scripts","text":"<p>Bekijk deze website voor enkele interessante scripts.</p>"},{"location":"infra/proxmox/proxmox_terraform/","title":"Proxmox Terraform Integration","text":""},{"location":"infra/proxmox/proxmox_terraform/#proxmox-terraform-integration","title":"Proxmox Terraform Integration","text":"<p>You can use Terraform to automate certain tasks on Proxmox. This allows you to manage virtual machines and lxc containers with infrastructure-as-code. We're using the third-party plugin telmate/terraform-provider-proxmox.</p>"},{"location":"infra/proxmox/proxmox_terraform/#authenticate-to-proxmox","title":"Authenticate to Proxmox","text":""},{"location":"infra/proxmox/proxmox_terraform/#create-an-api-token-on-proxmox","title":"Create an API Token on Proxmox","text":"<p>WIP</p>"},{"location":"infra/proxmox/proxmox_terraform/#add-provider-config-to-terraform","title":"Add Provider config to Terraform","text":"<p>WIP</p>"},{"location":"infra/proxmox/proxmox_terraform/#templates","title":"Templates","text":"<p>WIP</p>"},{"location":"infra/proxmox/proxmox_terraform/#useful-commands","title":"Useful commands","text":""},{"location":"infra/proxmox/proxmox_terraform/#import-existing-virtual-machines-to-terraform","title":"Import existing virtual machines to Terraform","text":"<p>Existing virtual machines can be imported to the Terraform state file with the following command. Make sure, you have created a corresponding Resource in the Terraform File.</p> <pre><code>terraform import &lt;resourcetype.resourcename&gt; &lt;id&gt;\n</code></pre> <p>In the telmate/terraform-provider-proxmox, the id needs to be set according to <code>&lt;node&gt;/&lt;type&gt;/&lt;vmid&gt;</code>, like in the following example.</p> <pre><code>terraform import proxmox_vm_qemu.srv-prod-1 prx-prod-1/proxmox_vm_qemu/102\n</code></pre>"},{"location":"infra/proxmox/tips/","title":"Voordat ik iets op Proxmox doe, doe ik eerst...","text":""},{"location":"infra/proxmox/tips/#voordat-ik-iets-op-proxmox-doe-doe-ik-eerst","title":"Voordat ik iets op Proxmox doe, doe ik eerst...","text":""},{"location":"infra/proxmox/tips/#updates","title":"Updates","text":"<p>Bewerk de file <code>/etc/apt/sources.list</code></p>"},{"location":"infra/proxmox/tips/#proxmox-versie-6x","title":"Proxmox-versie 6.X","text":"<pre><code>deb http://ftp.us.debian.org/debian buster main contrib\n\ndeb http://ftp.us.debian.org/debian buster-updates main contrib\n\n# security updates\ndeb http://security.debian.org buster/updates main contrib\n\n# not for production use\ndeb http://download.proxmox.com/debian buster pve-no-subscription\n</code></pre>"},{"location":"infra/proxmox/tips/#proxmox-versie-7x","title":"Proxmox-versie 7.X","text":"<pre><code>deb http://ftp.debian.org/debian bullseye main contrib\n\ndeb http://ftp.debian.org/debian bullseye-updates main contrib\n\n# security updates\ndeb http://security.debian.org/debian-security bullseye-security main contrib\n\n# PVE pve-no-subscription repository provided by proxmox.com,\n# NOT recommended for production use\ndeb http://download.proxmox.com/debian/pve bullseye pve-no-subscription\n</code></pre> <p>Bewerk <code>/etc/apt/sources.list.d/pve-enterprise.list</code></p> <pre><code># deb https://enterprise.proxmox.com/debian/pve buster pve-enterprise\n</code></pre> <p>Voer volgende commando's uit:</p> <pre><code>apt-get update\napt dist-upgrade\nreboot\n</code></pre>"},{"location":"infra/proxmox/tips/#storage","title":"Storage","text":"<p>Danger</p> <p>WEES VOORZICHTIG. Hiermee worden uw schijven gewist.</p> <pre><code>fdisk /dev/sda\n</code></pre> <p>Dan <code>P</code> voor partitie, dan <code>D</code> voor verwijderen, dan <code>W</code> voor schrijven.</p> <p>Controleer SMART Monitoring</p> <pre><code>smartctl -a /dev/sda\n</code></pre>"},{"location":"infra/proxmox/tips/#vlan-bewust","title":"VLAN bewust","text":"<p>Als u uw VLANS wilt beperken</p> <pre><code>nano /etc/network/interfaces\n</code></pre> <p>Stel hier uw VLAN in </p><pre><code>bridge-vlan-aware yes\nbridge-vids 20\n</code></pre>"},{"location":"infra/proxmox/tips/#voorbeeld-van-het-nic-team","title":"Voorbeeld van het NIC-team","text":"<pre><code>nano /etc/network/interfaces\n</code></pre> <pre><code>auto eno1\niface eno1 inet manual\n\nauto eno2\niface eno2 inet manual\n\nauto bond0\niface bond0 inet manual\nbond-slaves eno1 eno2\nbond-miimon 100\nbond-mode 802.3ad\nbond-xmit-hash-policy layer2+3\n\nauto vmbr0\niface vmbr0 inet static\naddress 192.168.0.11/24\ngateway 192.168.0.1\nbridge-ports bond0\nbridge-stp off\nbridge-fd 0\nbridge-vlan-aware yes\nbridge-vids 2-4094\n#lacp nic team\n</code></pre> <p>Als u Proxmox 7 gebruikt, bekijk dan hier de gewijzigde configuratie voor LAGG / LACP</p>"},{"location":"infra/truenas/truenas-scale/","title":"TrueNAS Scale","text":""},{"location":"infra/truenas/truenas-scale/#truenas-scale","title":"TrueNAS Scale","text":"<p>WIP</p>"},{"location":"infra/truenas/truenas-scale/#acme","title":"ACME","text":"<p>WIP</p> <ol> <li>Create DNS Credentials</li> <li>Create Signing Request</li> <li>Configure email address for your current user (in case of root, info)</li> <li>Create ACME Cert</li> <li>Switch Admin Cert</li> </ol>"},{"location":"infra/truenas/truenas/","title":"TrueNAS","text":""},{"location":"infra/truenas/truenas/#truenas","title":"TrueNAS","text":""},{"location":"infra/truenas/truenas/#initial-login","title":"Initial login","text":"User Password admin <code>password set in installation</code>"},{"location":"linux/cron/","title":"Cron","text":""},{"location":"linux/cron/#cron","title":"Cron","text":"<p>Een CRON-expressie is gewoon een tekenreeks die bestaat uit zes velden die elk een specifieke tijdseenheid defini\u00ebren.</p> <p>Ze zijn geschreven in het volgende formaat:</p> <pre><code>{second} {minute} {hour} {day} {month} {day of the week}\n</code></pre>"},{"location":"linux/cron/#waardes","title":"Waardes","text":"<p>De volgende waarden zijn toegestaan binnen elke tijdelijke aanduiding voor een datum/tijd-eenheid.</p> Field Allowed Values \u00a0Description {second} 0-59 Trigger every {second} second(s) {minute} 0-59 Trigger every {minute} minute(s) {hour} 0-23 Trigger every {hour} hour(s) {day} 1-31 Trigger every {day} day(s) of month {month} 1-12 Trigger every {month} month(s) {day of week} 0-6 MON-SUN Trigger on specific"},{"location":"linux/cron/#speciale-characters","title":"Speciale Characters","text":"<p>Daarnaast kunt u ook de volgende speciale tekens gebruiken om meer geavanceerde uitdrukkingen te maken:</p> Special Character Description <code>*</code> Trigger on tick of every time unit <code>,</code> List separator <code>\u2013</code> Specifies a range <code>/</code> Defines an increment"},{"location":"linux/cron/#enkele-voorbeelden","title":"Enkele voorbeelden","text":"<p><code>0 * * * * *</code> - Executes every minute <code>0 0 * * * *</code> - Executes every hour <code>0 0 0 * * *</code> - Executes every day <code>0 0 0 0 * *</code> - Executes every month <code>0 0 0 1 1 *</code> - Executes on first day of Jan\u00a0each year <code>30 20 * * SAT</code> - Executes at 08:30pm every Saturday <code>30 20 * * 6</code> - Executes at 08:30pm every Saturday <code>0 */5 * * * *</code> - Executes every five minutes <code>0 0 8-10/1 * * *</code> - Executes every hour between 8am and 10am</p>"},{"location":"linux/docker/","title":"Docker","text":""},{"location":"linux/docker/#docker","title":"Docker","text":""},{"location":"linux/docker/#docker-engine-installeren-op-ubuntu","title":"Docker Engine installeren op Ubuntu","text":"<p>Om aan de slag te gaan met Docker Engine op Ubuntu, moet u ervoor zorgen dat u aan de vereisten voldoet en vervolgens Docker installeert .</p>"},{"location":"linux/docker/#vereisten","title":"Vereisten","text":""},{"location":"linux/docker/#os-vereisten","title":"OS-vereisten","text":"<p>Om Docker Engine te installeren, hebt u de 64-bits versie van een van deze Ubuntu-versies nodig:</p> <ul> <li>Ubuntu Jammy 22.04 (LTS)</li> <li>Ubuntu Impish 21.10</li> <li>Ubuntu Focal 20.04 (LTS)</li> <li>Ubuntu Bionic 18.04 (LTS)</li> </ul> <p>Docker Engine wordt ondersteund op <code>x86_64</code>(of <code>amd64</code>), <code>armhf</code>, <code>arm64</code>, en <code>s390x</code>architecturen.</p>"},{"location":"linux/docker/#oude-versies-verwijderen","title":"Oude versies verwijderen","text":"<p>Oudere versies van Docker werden <code>docker</code>, <code>docker.io</code>, of <code>docker-engine</code>. Als deze zijn ge\u00efnstalleerd, verwijder ze dan:</p> <pre><code>sudo apt-get remove docker docker-engine docker.io containerd runc\n</code></pre> <p>Het is ok\u00e9 als <code>apt-get</code>wordt gemeld dat geen van deze pakketten is ge\u00efnstalleerd.</p> <p>De inhoud van <code>/var/lib/docker/</code>, inclusief afbeeldingen, containers, volumes en netwerken, blijft behouden. Als u uw bestaande gegevens niet hoeft op te slaan en met een schone installatie wilt beginnen, raadpleegt u het gedeelte Docker Engine verwijderen onderaan deze pagina.</p>"},{"location":"linux/docker/#installatiemethoden-_","title":"Installatiemethoden _","text":"<p>U kunt Docker Engine op verschillende manieren installeren, afhankelijk van uw behoeften:</p> <ul> <li> <p>De meeste gebruikers stellen de repositories van Docker in en installeren van daaruit, voor eenvoudige installatie en upgradetaken. Dit is de aanbevolen aanpak.</p> </li> <li> <p>Sommige gebruikers downloaden het DEB-pakket en installeren het handmatig en beheren upgrades volledig handmatig. Dit is handig in situaties zoals het installeren van Docker op air-gapped systemen zonder toegang tot internet.</p> </li> <li> <p>In test- en ontwikkelomgevingen kiezen sommige gebruikers ervoor om geautomatiseerde gemaksscripts te gebruiken om Docker te installeren.</p> </li> </ul>"},{"location":"linux/docker/#installeren-met-behulp-van-de-repository","title":"Installeren met behulp van de repository","text":"<p>Voordat u Docker Engine voor de eerste keer op een nieuwe hostcomputer installeert, moet u de Docker-repository instellen. Daarna kunt u Docker installeren en bijwerken vanuit de repository.</p>"},{"location":"linux/docker/#de-opslagplaats-instellen","title":"De opslagplaats instellen","text":"<ol> <li> <p>Werk de <code>apt</code>pakketindex bij en installeer pakketten om het <code>apt</code>gebruik van een repository via HTTPS toe te staan:</p> <pre><code>$ sudo apt-get update\n\n$ sudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n</code></pre> </li> <li> <p>Voeg de offici\u00eble GPG-sleutel van Docker toe:</p> <pre><code>sudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n</code></pre> </li> <li> <p>Gebruik de volgende opdracht om de repository in te stellen:</p> <pre><code>$ echo \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> </li> </ol>"},{"location":"linux/docker/#docker-engine-installeren","title":"Docker Engine installeren","text":"<ol> <li> <p>Werk de <code>apt</code>pakketindex bij en installeer de nieuwste versie van Docker Engine, containerd en Docker Compose, of ga naar de volgende stap om een specifieke versie te installeren:</p> <pre><code> sudo apt-get update\n sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre> </li> <li> <p>Om een specifieke versie van Docker Engine te installeren, vermeldt u de beschikbare versies in de repo, selecteert u en installeert u:</p> <p>a. Maak een lijst van de beschikbare versies in uw repo:</p> <pre><code>$ apt-cache madison docker-ce\n\ndocker-ce | 5:20.10.16~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\ndocker-ce | 5:20.10.15~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\ndocker-ce | 5:20.10.14~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\ndocker-ce | 5:20.10.13~3-0~ubuntu-jammy | https://download.docker.com/linux/ubuntu jammy/stable amd64 Packages\n</code></pre> <p>b. Installeer een specifieke versie met behulp van de versiereeks uit de tweede kolom, bijvoorbeeld <code>5:20.10.16~3-0~ubuntu-jammy</code>.</p> <pre><code>sudo apt-get install docker-ce=&lt;VERSION_STRING&gt; docker-ce-cli=&lt;VERSION_STRING&gt; containerd.io docker-compose-plugin\n</code></pre> </li> <li> <p>Controleer of Docker Engine correct is ge\u00efnstalleerd door de <code>hello-world</code> afbeelding uit te voeren.</p> <pre><code>sudo service docker start\nsudo docker run hello-world\n</code></pre> <p>Met deze opdracht wordt een testimage gedownload en uitgevoerd in een container. Wanneer de container wordt uitgevoerd, drukt deze een bericht af en wordt afgesloten.</p> </li> </ol> <p>Docker Engine is ge\u00efnstalleerd en draait. De <code>docker</code>groep is gemaakt, maar er worden geen gebruikers aan toegevoegd. U moet gebruiken <code>sudo</code>om Docker-opdrachten uit te voeren. Ga door naar Linux na de installatie om niet-bevoegde gebruikers toe te staan Docker-opdrachten uit te voeren en voor andere optionele configuratiestappen.</p>"},{"location":"linux/docker/#docker-engine-upgraden","title":"Docker-engine upgraden","text":"<p>Om Docker Engine te upgraden, voert u eerst uit <code>sudo apt-get update</code>, volgt u de installatie-instructies en kiest u de nieuwe versie die u wilt installeren.</p>"},{"location":"linux/docker/#uninstall-docker-engine","title":"Uninstall Docker Engine","text":"<ol> <li> <p>Uninstall the Docker Engine, CLI, Containerd, and Docker Compose packages:</p> <pre><code>sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre> </li> <li> <p>Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:</p> <pre><code>sudo rm -rf /var/lib/docker\nsudo rm -rf /var/lib/containerd\n</code></pre> </li> </ol> <p>You must delete any edited configuration files manually.</p>"},{"location":"linux/environment-variables-in-linux/","title":"Environment Variables in Linux","text":""},{"location":"linux/find/","title":"Find commando","text":""},{"location":"linux/find/#find-commando","title":"Find commando","text":""},{"location":"linux/find/#lijst-generen-van-alle-folders-in-een-bepaalde-directory","title":"Lijst generen van alle folders in een bepaalde directory","text":"<pre><code>find . -maxdepth 1 -type d -printf '%f\\n'\n</code></pre>"},{"location":"linux/find/#zoek-alle-files-type-f-in-map-youtube-met-in-de-naam-trailer","title":"Zoek alle files (-type f) in map youtube met in de naam trailer","text":"<pre><code>find ./youtube -type f -name '*trailer*'\n</code></pre>"},{"location":"linux/find/#delete-al-deze-files","title":"Delete al deze files","text":"<pre><code>find ./youtube -type f -name '*trailer*' -delete\n</code></pre>"},{"location":"linux/gnome/","title":"Gnome","text":""},{"location":"linux/gpu-passtrough/","title":"GPU Passtrough","text":""},{"location":"linux/gpu-passtrough/#gpu-passtrough","title":"GPU Passtrough","text":""},{"location":"linux/gpu-passtrough/#stap-1","title":"Stap 1","text":"<p>Pas je grub aan als volgt:</p>"},{"location":"linux/gpu-passtrough/#cowarol-setup","title":"Cowarol setup","text":"<pre><code>sudo nano /etc/default/grub\nGRUB_CMDLINE_LINUX_DEFAULT=\"intel_iommu=on loglevel=3 vfio-pci.ids=01:00.1,01:00.0 quiet\"\nsudo grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre>"},{"location":"linux/gpu-passtrough/#bedar-setup","title":"Bedar setup","text":"<pre><code>sudo nano /etc/default/grub\nGRUB_CMDLINE_LINUX_DEFAULT=\"intel_iommu=on quiet\"\nsudo grub-mkconfig -o /boot/grub/grub.cfg\n</code></pre> <p>Note</p> <p>Bij Bedar werkte het de eerste optie niet. Daarom hebben we beide opties gegeven.</p> <p>Als je de ID`s van je GPU PCI slot wilt weten, gebruik je volgend commando:</p> <pre><code>lspci\n</code></pre>"},{"location":"linux/gpu-passtrough/#stap-2","title":"Stap 2","text":"<p>Maak een nieuwe virtuele machine. Tijdens de wizard moet je aangeven dat je de <code>VM eerst nog wilt bewerken</code>.</p>"},{"location":"linux/gpu-passtrough/#tab-overview","title":"TAB: Overview","text":"<p>BIOS \u2192 x64/OVMF_code.secboot.fd</p>"},{"location":"linux/gpu-passtrough/#tab-cpus","title":"TAB: CPUs","text":"<ul> <li>Current allocation &lt;2</li> <li>Socket 1</li> <li>cores &lt;2</li> <li>treads &lt;1</li> </ul>"},{"location":"linux/gpu-passtrough/#knop-add-hardware","title":"KNOP: Add Hardware","text":"<ul> <li>TPM</li> <li>Model: CRB</li> <li>Backend: Emulated device</li> <li>Version 2.0</li> </ul>"},{"location":"linux/gpu-passtrough/#start-vm","title":"Start VM","text":"<p>Nu zie je dat er problemen optreden.</p>"},{"location":"linux/gpu-passtrough/#installeer-swtpm","title":"Installeer SWTPM","text":""},{"location":"linux/gpu-passtrough/#debian","title":"Debian","text":"<pre><code>sudo apt install swtpm\n</code></pre> <p>Note</p> <p>Als deze niet bestaat zoek je op welke linux versie je hebt. In ons geval is dit Zorin OS (focal) Dan voeg je eerst nog de repo toe.</p> <pre><code>sudo add-apt-repository ppa:stefanberger/swtpm-focal\nsudo apt update**\nsudo apt-get install swtpm swtpm-tools\n</code></pre>"},{"location":"linux/gpu-passtrough/#arch","title":"Arch","text":"<pre><code>sudo pacman -S swtpm\n</code></pre>"},{"location":"linux/gpu-passtrough/#stap-3","title":"Stap 3","text":"<p>Start vm nogmaals en stel deze nu in met volgende wijzigingen:</p> <ul> <li>Updates</li> <li>Fedora kvm guest tools</li> </ul> <p>Note</p> <p>Een rechtstreekse link en klik op de .exe https://github.com/virtio-win/virtio-win-pkg-scripts/blob/master/README.md</p> <p>Schakel de VM terug uit.</p>"},{"location":"linux/gpu-passtrough/#stap-4","title":"Stap 4","text":"<ul> <li>Clone de VM</li> <li>Share de disk als het mogelijk is met de nieuwe VM</li> <li>Geef de VM een naam \"name\"-gpu-passtrough</li> </ul>"},{"location":"linux/gpu-passtrough/#bewerk-de-vm","title":"Bewerk de VM","text":"<ul> <li>[Add Hardware]</li> <li>voeg nu alle USB en PCI(GPU) Ids toe.</li> <li><code>Delete</code> \"Display Spice, Serial 1, Channel Spice, and Video QXL\"</li> </ul>"},{"location":"linux/gpu-passtrough/#install-libvirt","title":"Install Libvirt","text":"<p>Note</p> <p>https://passthroughpo.st/simple-per-vm-libvirt-hooks-with-the-vfio-tools-hook-helper/</p> <pre><code>sudo mkdir -p /etc/libvirt/hooks\nsudo wget 'https://raw.githubusercontent.com/PassthroughPOST/VFIO-Tools/master/libvirt_hooks/qemu' \\ -O /etc/libvirt/hooks/qemu\nsudo chmod +x /etc/libvirt/hooks/qemu\nsudo service libvirtd restart\n</code></pre>"},{"location":"linux/gpu-passtrough/#gpu-loskoppelen-en-terug-koppelen","title":"GPU loskoppelen en terug koppelen","text":"<p>Nu ga je 2 schripts maken die de GPU gaan loskoppelen en terug koppelen aan je Linux device.</p> <p>Note</p> <p>Zet in de 2 scripts <code>pci_0000_01_00_0</code> naar jouw ID.</p> <pre><code>sudo mkdir -p /etc/libvirt/hooks/qemu.d/\"VMNAME\"/prepare/\nsudo mkdir -p /etc/libvirt/hooks/qemu.d/\"VMNAME\"/prepare/begin\nsudo nano /etc/libvirt/hooks/qemu.d/\"VMNAME\"/prepare/begin/script.sh\n</code></pre> <pre><code>#!/bin/bash\n# Helpful to read output when debugging\nset -x\n\n# Stop display manager\nsystemctl stop display-manager.service\n## Uncomment the following line if you use GDM\nkillall gdm-x-session\n\n# Unbind VTconsoles\necho 0 &gt; /sys/class/vtconsole/vtcon0/bind\necho 0 &gt; /sys/class/vtconsole/vtcon1/bind\n\n# Unbind EFI-Framebuffer\necho efi-framebuffer.0 &gt; /sys/bus/platform/drivers/efi-framebuffer/unbind\n\n# Avoid a Race condition by waiting 2 seconds. This can be calibrated to be shorter or longer if required for your system\nsleep 2\n\n# Unbind the GPU from display driver\nvirsh nodedev-detach pci_0000_01_00_0\nvirsh nodedev-detach pci_0000_01_00_1\n\n# Load VFIO Kernel Module\nmodprobe vfio-pci\n</code></pre> <pre><code>sudo chmod +x /etc/libvirt/hooks/qemu.d/\"VMNAME\"/prepare/begin/script.sh\nsudo mkdir -p /etc/libvirt/hooks/qemu.d/\"VMNAME\"/release/end\nsudo nano /etc/libvirt/hooks/qemu.d/\"VMNAME\"/release/end/script.sh\n</code></pre> <pre><code>#!/bin/bash\nset -x\n\n# Re-Bind GPU to Nvidia Driver\nvirsh nodedev-reattach pci_0000_01_00_1\nvirsh nodedev-reattach pci_0000_01_00_0\n\n# Reload nvidia modules\nmodprobe nvidia\nmodprobe nvidia_modeset\nmodprobe nvidia_uvm\nmodprobe nvidia_drm\n\n# Rebind VT consoles\necho 1 &gt; /sys/class/vtconsole/vtcon0/bind\n# Some machines might have more than 1 virtual console. Add a line for each corresponding VTConsole\necho 1 &gt; /sys/class/vtconsole/vtcon1/bind\n\nnvidia-xconfig --query-gpu-info &gt; /dev/null 2&gt;&amp;1\necho \"efi-framebuffer.0\" &gt; /sys/bus/platform/drivers/efi-framebuffer/bind\n\n# Restart Display Manager\nsystemctl start display-manager.service\n</code></pre> <pre><code>sudo chmod +x /etc/libvirt/hooks/qemu.d/win10/prepare/begin/script.sh\n</code></pre>"},{"location":"linux/gpu-passtrough/#stap-5","title":"Stap 5","text":"<p>Start VM Enjoy :D</p> <p>Note</p> <p>https://www.youtube.com/watch?v=qaA7kxcnXaM</p>"},{"location":"linux/grep/","title":"Grep","text":""},{"location":"linux/grep/#grep","title":"Grep","text":"<p>Grep is a command-line utility for searching plain-text data sets for lines that match a regular expression. Its name comes from the ed command g/re/p (globally search for a regular expression and print matching lines), which has the same effect. grep was originally developed for the Unix operating system like Linux ([[linux]]), but later available for all Unix-like systems and some others such as OS-9.</p>"},{"location":"linux/linux/","title":"Linux","text":""},{"location":"linux/linux/#nuttige-links","title":"Nuttige links","text":"<ul> <li>https://github.com/jlevy/the-art-of-command-line</li> </ul>"},{"location":"linux/netplan/","title":"Netplan","text":""},{"location":"linux/netplan/#netplan","title":"Netplan","text":"<p>Netplan is een hulpprogramma voor het configureren van netwerkinterfaces in moderne versies van Ubuntu en andere Linux-distributies. Netplan genereert de overeenkomstige configuratiebestanden voor het onderliggende netwerkconfiguratiesubsysteem, zoals systemd-networkd of NetworkManager.</p>"},{"location":"linux/netplan/#hoe-te-gebruiken","title":"Hoe te gebruiken","text":"<p>Netplan gebruikt YAML-configuratiebestanden in <code>/etc/netplan/</code> om netwerkinterfaces, IP-adressen, routes en andere netwerkgerelateerde parameters te beschrijven.</p> <p>Example: <code>/etc/netplan/01-netcfg.yaml</code> </p><pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n</code></pre> <p>Deze configuratie stelt een DHCP-client in voor de <code>enp0s3</code> Ethernet-interface, met behulp van de systemd-networkd-renderer.</p> <p>To apply this configuration, run the following command.</p> <pre><code>sudo netplan apply.\n</code></pre> <p>You can also test a new Netplan configuration without applying it permanently. This is useful if you want to try out a new network configuration without disrupting your current network connection.</p> <pre><code>sudo netplan try\n</code></pre>"},{"location":"linux/netplan/#static-ip-addresses","title":"Static IP addresses","text":"<p>To define a static IP address in Netplan, you can use the addresses key in the configuration file for the relevant network interface. Here\u2019s an example configuration file that sets a static IP address of 192.168.1.10 with a net mask of 24 bits for the <code>enp0s3</code> Ethernet interface:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      addresses:\n        - 192.168.1.10/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\n</code></pre> <p>In this configuration, the addresses key sets the static IP address and net mask for the <code>enp0s3</code> interface. The gateway4 key sets the default gateway, and the nameserver's key sets the DNS servers.</p>"},{"location":"linux/netplan/#vlans","title":"VLANs","text":"<p>Example 1: Simple VLAN configuration </p><pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n  vlans:\n    vlan10:\n      id: 10\n      link: enp0s3\n      dhcp4: true\n</code></pre> <p>In this configuration, the <code>enp0s3</code> Ethernet interface is configured to use DHCP to obtain an IP address. A VLAN with ID 10 is also configured on the <code>enp0s3</code> interface, and DHCP is enabled for this VLAN as well. The link key specifies that the VLAN is associated with the <code>enp0s3</code> interface.</p> <p>Example 2: Advanced VLAN configuration </p><pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n  vlans:\n    vlan10:\n      id: 10\n      link: enp0s3\n      addresses:\n        - 192.168.10.2/24\n      routes:\n        - to: 0.0.0.0/0\n          via: 192.168.10.1\n      nameservers:\n        addresses: [8.8.8.8, 8.8.4.4]\n</code></pre> <p>In this configuration, a VLAN with ID 10 is configured on the <code>enp0s3</code> interface, and a static IP address of <code>192.168.10.2</code> with a net mask of <code>24</code> bits is assigned to the VLAN interface. The routes key specifies a default route via the gateway at <code>192.168.10.1</code>. The nameserver's key sets the DNS servers to <code>8.8.8.8</code> and <code>8.8.4.4</code>.</p>"},{"location":"linux/netplan/#bridges-and-bonding","title":"Bridges and Bonding","text":"<p>Bridging and bonding are two techniques used to combine multiple network interfaces into a single logical interface.</p>"},{"location":"linux/netplan/#bonding","title":"Bonding","text":"<p>Bonding involves combining two or more physical interfaces into a single logical interface, called a bond interface. The bond interface acts like a single network interface, providing higher bandwidth and redundancy. Bonding is often used in high-performance computing environments, where multiple network interfaces are required to handle the high volume of network traffic.</p> <p>Example 1: Bonding configuration </p><pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n    enp0s4:\n      dhcp4: true\n  bonds:\n    bond0:\n      interfaces:\n        - enp0s3\n        - enp0s4\n      dhcp4: true\n      parameters:\n        mode: active-backup\n</code></pre> <p>In this configuration, two Ethernet interfaces (enp0s3 and enp0s4) are configured with DHCP to obtain IP addresses. A bond interface (bond0) is also configured, which combines the two Ethernet interfaces into a single logical interface. The interfaces key specifies the physical interfaces to include in the bond, and the mode key specifies the bonding mode (in this case, active-backup).</p>"},{"location":"linux/netplan/#bridging","title":"Bridging","text":"<p>Bridging involves creating a bridge interface that connects two or more physical interfaces. The bridge interface acts like a virtual switch, allowing devices connected to any of the physical interfaces to communicate with each other as if they were on the same network segment. Bridging is often used to connect two separate network segments or to provide redundancy in case one physical interface fails.</p> <p>Example 2: Bridging configuration </p><pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp0s3:\n      dhcp4: true\n    enp0s4:\n      dhcp4: true\n  bridges:\n    br0:\n      interfaces:\n        - enp0s3\n        - enp0s4\n      dhcp4: true\n</code></pre> <p>In this configuration, two Ethernet interfaces (enp0s3 and enp0s4) are configured with DHCP to obtain IP addresses. A bridge interface (br0) is also configured, which combines the two Ethernet interfaces into a single logical interface. The interfaces key specifies the physical interfaces to include in the bridge.</p>"},{"location":"linux/nfs_share/","title":"Nfs share","text":""},{"location":"linux/nfs_share/#nfs-sharing","title":"NFS Sharing","text":"<p>There are a few ways to mount a share from your unraid server on your ubuntu docker vm. One way is to use SMB/CIFS protocol and mount the share using fstab file. Another way is to use NFS protocol and mount the share using /etc/fstab file. A third way is to use --cap-add flag with docker run to enable mount privileges inside the container.</p> <p>Here are some examples of how to do each method:</p> <ul> <li>SMB/CIFS with fstab:</li> </ul> <pre><code># Install cifs-utils package\nsudo apt-get install cifs-utils\n\n# Create a mount point\nsudo mkdir /mnt/unraid\n\n# Edit /etc/fstab file and add a line like this\n//&lt;unraid_server_ip&gt;/&lt;share_name&gt; /mnt/unraid cifs username=&lt;unraid_user&gt;,password=&lt;unraid_password&gt;,uid=&lt;ubuntu_user&gt;,gid=&lt;ubuntu_group&gt; 0 0\n\n# Mount the share\nsudo mount -a\n</code></pre> <ul> <li>NFS with /etc/fstab:</li> </ul> <pre><code># Install nfs-common package\nsudo apt-get install nfs-common\n\n# Create a mount point\nsudo mkdir /mnt/unraid\n\n# Edit /etc/fstab file and add a line like this\n&lt;unraid_server_ip&gt;:/mnt/user/&lt;share_name&gt; /mnt/unraid nfs defaults,_netdev 0 0\n\n# Mount the share\nsudo mount -a\n</code></pre> <ul> <li>--cap-add with docker run:</li> </ul> <pre><code># Run the docker container with --cap-add SYS_ADMIN --cap-add DAC_READ_SEARCH flags\ndocker run -it --cap-add SYS_ADMIN --cap-add DAC_READ_SEARCH ubuntu bash\n\n# Inside the container, install cifs-utils package\napt-get update &amp;&amp; apt-get install cifs-utils\n\n# Create a mount point\nmkdir /mnt/unraid\n\n# Mount the share using mount command\nmount -t cifs //&lt;unraid_server_ip&gt;/&lt;share_name&gt; /mnt/unraid -o user=&lt;unraid_user&gt;,password=&lt;unraid_password&gt;\n</code></pre>"},{"location":"linux/parallel/","title":"Parallel","text":"","tags":["linux","parallel","command"]},{"location":"linux/parallel/#parallel","title":"Parallel","text":"","tags":["linux","parallel","command"]},{"location":"linux/parallel/#1-introduction","title":"1. Introduction","text":"<p>There are many common tasks in Linux that we may want to consider running in parallel, such as:</p> <ul> <li>Downloading a large number of files</li> <li>Encoding/decoding a large number of images on a machine with multiple CPU cores</li> <li>Making a computation with many different parameters and storing the results</li> </ul> <p>Of course, we can accomplish all these tasks without using parallelization. But if we process each file, connection, or\u00a0computation in several parallel processes, we can have a great advantage in terms of speed. Luckily, there are multiple powerful command-line tools for parallelization in Linux systems that can help us achieve this.</p> <p>In this tutorial, we\u2019re going to see how to use the Bash ampersand\u00a0&amp;\u00a0operator,\u00a0xargs, and\u00a0GNU\u00a0parallel\u00a0to achieve parallelization on the Linux command line.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#2-a-sample-task","title":"2. A Sample Task","text":"<p>First, let\u2019s create a simple script that we\u2019ll run in parallel.</p> <p>Let\u2019s create a file named\u00a0./process\u00a0with contents:</p> <pre><code>#!/bin/bash\n\necho \"started processing $*..\"\nsleep $((2 + RANDOM % 3)); echo finished processing \"$*\";\n</code></pre> <p>This script will fake an actual process that takes 2 to 5 seconds to complete. Let\u2019s make it executable to be able to use it:</p> <pre><code>chmod +x ./process\n</code></pre>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#3-using","title":"3. Using &amp;","text":"<p>As a basic way to run commands in parallel, we can use the built-in\u00a0Bash ampersand\u00a0&amp;\u00a0operator\u00a0to run a command asynchronously so that the shell doesn\u2019t wait for the current command to complete before moving on to the next one:</p> <pre><code>./process 1 &amp;\n./process 2 &amp;\n</code></pre> <p>This will create two processes that will start at essentially the same instant and run in parallel. Because we\u2019ve introduced random\u00a0sleep\u00a0times in our example script, the output may look like this:</p> <pre><code>[1] 25254\n[2] 25255\nstarted processing 1..\nstarted processing 2..\nfinished processing 2\nfinished processing 1\n\n[1]-  Done                    ./process 1\n[2]+  Done                    ./process 2\n</code></pre> <p>Clearly, we can use this approach to run many parallel processes. But if we have many tasks \u2013 for example, a hundred images to be converted \u2013 we wouldn\u2019t want to start all hundred tasks at once, but instead, process them in batches to utilize our cores better.\u00a0To achieve this, we need to wait for some tasks to complete before starting others.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#31-using-wait-with","title":"3.1. Using\u00a0wait\u00a0with &amp;","text":"<p>The\u00a0wait\u00a0command will, by default, wait for all child processes to exit. So, using the\u00a0wait\u00a0command, we can run batches of operations:</p> <p>AD</p> <pre><code>echo \"starting batch 1..\"\n./process 1.jpg &amp;\n./process 2.jpg &amp;\n./process 3.jpg &amp;\nwait\necho \"starting batch 2..\"\n./process 4.jpg &amp;\n./process 5.jpg &amp;\n./process 6.jpg &amp;\nwait\necho \"finished\"\n</code></pre> <p>However, there\u2019s one big downside to this approach. To utilize our CPU cores effectively, we\u2019d want a new process to start as soon as a running process ends.\u00a0But with this solution, we wouldn\u2019t start new processes until all the tasks in the previous batch were completed. To overcome this limitation, we can use\u00a0xargs.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#4-using-_xargs","title":"4. Using\u00a0_xargs","text":"<p>xargs\u00a0is a command-line tool\u00a0that helps us run commands with arguments parsed from standard input. It can also parallelize our tasks for us.</p> <p>Let\u2019s try the previous input we used with &amp;, but this time with\u00a0xargs:</p> <pre><code>$ echo '1.jpg 2.jpg 3.jpg 4.jpg 5.jpg 6.jpg' | xargs -n 1 -P 3 ./process\nstarted processing 1.jpg..\nstarted processing 2.jpg..\nstarted processing 3.jpg..\nfinished processing 1.jpg\nfinished processing 2.jpg\nstarted processing 4.jpg..\nstarted processing 5.jpg..\nfinished processing 3.jpg\nstarted processing 6.jpg..\nfinished processing 5.jpg\nfinished processing 4.jpg\nfinished processing 6.jpg\n</code></pre> <p>xargs\u00a0immediately creates the next process once a process is completed.\u00a0We specify the number of arguments per call using the\u00a0-n\u00a0argument and the number of parallel tasks using the\u00a0-P\u00a0argument.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#41-using-replacement","title":"4.1. Using Replacement","text":"<p>If the executable we\u2019re using requires us to put the arguments to some specific place rather than appending them directly after the executable name, we can use replacement.</p> <p>Let\u2019s try it:</p> <pre><code>$ args=\"1\\n2\\n3\\n4\\n5\\n6\"\n$ echo -e $args | xargs -I \"{}\" -P 2 ./process {}.jpg\nstarted processing 1.jpg..\nstarted processing 2.jpg..\nfinished processing 2.jpg\nstarted processing 3.jpg..\nfinished processing 1.jpg\nstarted processing 4.jpg..\nfinished processing 3.jpg\nstarted processing 5.jpg..\nfinished processing 5.jpg\nstarted processing 6.jpg..\nfinished processing 4.jpg\nfinished processing 6.jpg\n</code></pre>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#42-handling-arguments-with-newlines","title":"4.2. Handling Arguments With Newlines","text":"<p>If the arguments we want to use with our processes include newline characters, we can use a null character (\\0) delimited input stream. For example, with the\u00a0find\u00a0command, we can set the output to be null-delimited instead of newline-delimited by using the\u00a0-print0\u00a0flag:</p> <pre><code>find . -print0 | xargs -0 -n 2 -P 2 ./process\n</code></pre> <p>As the arguments are now null-delimited, we can be sure that newline characters in the input will be preserved.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#5-using-gnu-parallel","title":"5. Using GNU\u00a0parallel","text":"<p>GNU\u00a0parallel\u00a0is one of the most advanced command-line tools available for running parallel tasks. It has many features, including the ability to distribute and run tasks remotely on multiple machines using\u00a0ssh.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#51-basic-usage","title":"5.1. Basic Usage","text":"<p>The basic usage of\u00a0parallel\u00a0is very similar to\u00a0xargs. Actually, for simple cases, we can use it interchangeably with\u00a0xargs.</p> <p>Let\u2019s try:</p> <pre><code>$ args=\"1\\n2\\n3\\n4\\n5\\n6\"\n$ echo -e $args | parallel --ungroup --jobs 3 ./process\nstarted processing 1..\nstarted processing 2..\nstarted processing 3..\nfinished processing 1\nfinished processing 2\nfinished processing 3\nstarted processing 4..\nstarted processing 5..\nstarted processing 6..\nfinished processing 5\nfinished processing 4\nfinished processing 6\n</code></pre> <p>The\u00a0\u2013jobs\u00a0argument is the same as the\u00a0xargs\u00a0command\u2019s\u00a0-P\u00a0argument, which determines the maximum number of parallel jobs to be running at the same time.</p> <p>By default,\u00a0parallel\u00a0will print the output of a process only after it is finished. The\u00a0\u2013ungroup\u00a0flag disables this functionality. We can use it to see the actual execution order of commands as they are running.</p> <p>We can supply the input arguments also via the command line. Let\u2019s try running it to get the same output as above:</p> <pre><code>parallel --ungroup --jobs 3 ./process ::: 1 2 3 4 5 6\n</code></pre> <p>when supplying command-line arguments, we can use ::: (three colons) to supply arguments directly, and :::: (four colons) to supply arguments from a file.</p> <p>Let\u2019s see an example that supplies input from a file:</p> <pre><code>args=\"1\\n2\\n3\\n4\\n5\\n6\"\necho -e $args &gt; input.txt\nparallel --ungroup --jobs 3 ./process :::: input.txt\n</code></pre> <p>The output would be similar to the above.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#52-running-combinations-of-multiple-sources","title":"5.2. Running Combinations of Multiple Sources","text":"<p>We can use\u00a0parallel\u00a0to run tasks for every possible combination of two sources.</p> <p>Let\u2019s try it for two sample sources:</p> <pre><code>$ parallel --ungroup ./process ::: 1 2 3 ::: 1 2 3\nstarted processing 1 1..\nstarted processing 1 2..\nstarted processing 1 3..\nstarted processing 2 1..\nstarted processing 2 2..\nstarted processing 2 3..\nstarted processing 3 1..\nstarted processing 3 2..\nfinished processing 1 1\nfinished processing 1 2\nfinished processing 2 1\nfinished processing 2 2\nfinished processing 3 1\nstarted processing 3 3..\nfinished processing 1 3\nfinished processing 3 2\nfinished processing 2 3\nfinished processing 3 3\n</code></pre>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#53-linking-sources","title":"5.3. Linking Sources","text":"<p>If instead of running for every possible combination, we want to \u201clink\u201d them after one another, we would use the\u00a0\u2013link\u00a0flag. Let\u2019s try it with two different input sources:</p> <pre><code>$ parallel --link --ungroup ./process ::: 1 2 3 ::: 1 2 3\nstarted processing 1 1..\nstarted processing 2 2..\nstarted processing 3 3..\nfinished processing 1 1\nfinished processing 3 3\nfinished processing 2 2\n</code></pre>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#54-replacement-strings","title":"5.4. Replacement Strings","text":"<p>Like in\u00a0xargs, we can use replacement strings in\u00a0parallel. The default replacement string is {}.</p> <p>Let\u2019s try it with a prefix:</p> <pre><code>$ parallel --ungroup ./process item-{} ::: 1 2 3\nstarted processing item-1..\nstarted processing item-2..\nstarted processing item-3..\nfinished processing item-1\nfinished processing item-2\nfinished processing item-3\n</code></pre> <p>Other replacement strings do different kinds of manipulations on the input. For example, {.} will remove the extension from the argument:</p> <pre><code>$ parallel --ungroup ./process {.} ::: 1.jpg 2.jpg 3.jpg\nstarted processing 1..\nstarted processing 2..\nstarted processing 3..\nfinished processing 2\nfinished processing 1\nfinished processing 3\n</code></pre> <p>If we want to use multiple different variables for each command, we can also do this using special replacement strings:</p> <pre><code>$ parallel --ungroup --link ./process {1}.jpg {2}.jpg {3}.jpg ::: 1 2 3 ::: 4 5 6 ::: 7 8 9\nstarted processing 1.jpg 4.jpg 7.jpg..\nstarted processing 2.jpg 5.jpg 8.jpg..\nstarted processing 3.jpg 6.jpg 9.jpg..\nfinished processing 1.jpg 4.jpg 7.jpg\nfinished processing 2.jpg 5.jpg 8.jpg\nfinished processing 3.jpg 6.jpg 9.jpg\n</code></pre> <p>There are also many more options for replacement strings that can be found in the\u00a0parallel\u00a0tutorial.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#55-reading-input-from-file-columns","title":"5.5. Reading Input From File Columns","text":"<p>We can read the input from different columns of a text file. Let\u2019s try it with a tab-separated text file:</p> <pre><code>$ args=\"1\\t4\\n2\\t5\\n3\\t6\"\n$ echo -e $args &gt; input_cols.txt\n$ parallel --colsep '\\t' --ungroup ./process [{1}] [{2}] :::: input_cols.txt\nstarted processing [1] [4]..\nstarted processing [2] [5]..\nstarted processing [3] [6]..\nfinished processing [2] [5]\nfinished processing [3] [6]\nfinished processing [1] [4]\n</code></pre>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#56-saving-output","title":"5.6. Saving Output","text":"<p>We can save the output of each process into a file by using the\u00a0\u2013files\u00a0flag:</p> <pre><code>$ parallel --files --link ./process ::: 1 2 3 ::: 1 2 3\n/tmp/parnqFzp.par\n/tmp/parSv0nW.par\n/tmp/parGyNbz.par\n</code></pre> <p>This will create\u00a0*.par\u00a0files with the output of our commands as the content.</p> <p>If we want to have a more friendly directory structure, we can use the\u00a0\u2013results\u00a0and\u00a0\u2013header\u00a0arguments to write the results to a folder in a hierarchy.</p> <p>Let\u2019s run a command to generate the directory tree:</p> <pre><code>parallel --results outdir --link ./process ::: a b c ::: d e f\n</code></pre> <p>Now, let\u2019s check the output using the\u00a0tree\u00a0command:</p> <pre><code>outdir\n\u2514\u2500\u2500 1\n    \u251c\u2500\u2500 a\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 2\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 d\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 seq\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 stderr\n    \u2502\u00a0\u00a0         \u2514\u2500\u2500 stdout\n    \u251c\u2500\u2500 b\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 2\n    \u2502\u00a0\u00a0     \u2514\u2500\u2500 e\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 seq\n    \u2502\u00a0\u00a0         \u251c\u2500\u2500 stderr\n    \u2502\u00a0\u00a0         \u2514\u2500\u2500 stdout\n    \u2514\u2500\u2500 c\n        \u2514\u2500\u2500 2\n            \u2514\u2500\u2500 f\n                \u251c\u2500\u2500 seq\n                \u251c\u2500\u2500 stderr\n                \u2514\u2500\u2500 stdout\n</code></pre> <p>parallel\u00a0generates the directory structure based on argument positions and values.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#57-progress-information","title":"5.7. Progress Information","text":"<p>We can also have\u00a0parallel\u00a0show an estimate of the remaining time based on current task runs:</p> <pre><code>$ parallel --eta --colsep '\\t' --ungroup ./process [{1}] [{2}] :::: input_cols.txt\n\nstarted processing [1] [4]..\nstarted processing [2] [5]..\n\nComputers / CPU cores / Max jobs to run\n1:local / 8 / 3\nstarted processing [3] [6]..\n\nComputer:jobs running/jobs completed/%of started jobs/Average seconds to complete\nETA: 0s Left: 3 AVG: 0.00s  local:3/0/100%/0.0s finished processing [1] [4]\nETA: 0s Left: 2 AVG: 0.00s  local:2/1/100%/3.0s finished processing [2] [5]\nETA: 0s Left: 2 AVG: 0.00s  local:2/1/100%/3.0s finished processing [3] [6]\nETA: 0s Left: 1 AVG: 0.00s  local:1/2/100%/1.5s\nETA: 0s Left: 0 AVG: 0.00s  local:0/3/100%/1.0s\n</code></pre>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#58-running-parallel-tasks-on-remote-machines","title":"5.8. Running Parallel Tasks on Remote Machines","text":"<p>We can run our parallel tasks on remote machines using\u00a0parallel\u00a0through\u00a0ssh.</p> <p>Let\u2019s assume we have access to\u00a0host1\u00a0and\u00a0host2\u00a0using our username and\u00a0ssh\u00a0keys that are added to our system. Let\u2019s try it:</p> <pre><code>$ parallel -S host1 -S host2 echo ::: running on remote hosts\nrunning\non\nremote\nhosts\n</code></pre> <p>The hosts that will run each command and the order of execution will change randomly with every run.</p>","tags":["linux","parallel","command"]},{"location":"linux/parallel/#6-conclusion","title":"6. Conclusion[","text":"<p>In this article, we learned how to use the Bash ampersand\u00a0&amp;\u00a0operator,\u00a0xargs, and GNU\u00a0parallel\u00a0to parallelize our tasks on the command line.</p>","tags":["linux","parallel","command"]},{"location":"linux/rsync/","title":"Rsync","text":""},{"location":"linux/rsync/#rsync","title":"Rsync","text":""},{"location":"linux/rsync/#limiteer-resource-gebruik-tijdens-rsync","title":"Limiteer resource gebruik tijdens Rsync","text":"<p>Je kan de prestaties van rsync verbeteren door enkele opties te gebruiken:</p> <ul> <li>U kunt de vlag <code>-z</code> weglaten als u bestanden lokaal kopieert, aangezien compressie niet nodig is.</li> <li>U kunt de vlag <code>-W</code> gebruiken om hele bestanden over te zetten zonder de prescan, wat sneller kan zijn voor kleine bestanden of bestanden die veel zijn veranderd.</li> <li>U kunt de vlag <code>--delete</code> gebruiken om bestanden op de bestemming te verwijderen die niet op de bron staan, wat ruimte en tijd kan besparen.</li> </ul> <p>Hier is een voorbeeld van een aangepaste rsync-opdracht:</p> <pre><code>rsync -avhW --delete --exclude='.git/' bedar@10.10.10.67:/home/bedar/fivem/havenstad/resources ./resources\n</code></pre>"},{"location":"linux/rsync/#backup-maken-van-folder-met-include-en-exclude","title":"Backup maken van folder met include en exclude","text":"<pre><code>rsync -av --progress --include= {'.ssh/','.vscode/','.zsh/','.gitconfig/','.zshrc/'} --exclude='.*/' bronmap /doelmap\n</code></pre> <p>De optie <code>--include</code> laat je toe om specifieke mappen op te geven die je wilt kopi\u00ebren, terwijl de optie <code>--exclude</code> alle andere verborgen mappen uitsluit.</p>"},{"location":"linux/snippets/","title":"Linux snippets","text":""},{"location":"linux/snippets/#linux-snippets","title":"Linux snippets","text":""},{"location":"linux/snippets/#beschrijving","title":"Beschrijving","text":"<p>Dit bestand bevat een verzameling van handige Ubuntu snippets die ik heb gevonden of gemaakt. Ze kunnen worden gebruikt om verschillende taken uit te voeren op ubuntu systemen, zoals het installeren van pakketten, het configureren van netwerken, het beheren van processen en nog veel meer</p>"},{"location":"linux/snippets/#laat-de-5-laatst-bewerkte-bestanden-zien","title":"Laat de 5 laatst bewerkte bestanden zien","text":"<pre><code>ls -lht | head -6\n</code></pre>"},{"location":"linux/snippets/#uitleg","title":"Uitleg","text":"<p><code>-l</code> geeft de uitvoer in een lijstformaat weer</p> <p><code>-h</code> maakt de uitvoer leesbaar voor mensen (d.w.z. bestandsgroottes verschijnen in kb, mb, etc.)</p> <p><code>-t</code> sorteert de uitvoer door het meest recent gewijzigde bestand eerst te plaatsen</p> <p><code>head -6</code> zal 5 bestanden laten zien omdat ls de blokgrootte in de eerste regel van de uitvoer afdrukt.</p> <p>Voorbeeld resultaat</p> <p>total 26960312 -rw-r--r--@ 1 user staff 1.2K 11 Jan 11:22 phone2.7.py -rw-r--r--@ 1 user staff 2.7M 10 Jan 15:26 03-cookies-1.pdf -rw-r--r--@ 1 user staff 9.2M 9 Jan 16:21 Wk1_sem.pdf -rw-r--r--@ 1 user staff 502K 8 Jan 10:20 lab-01.pdf -rw-rw-rw-@ 1 user staff 2.0M 5 Jan 22:06 0410-1.wmv</p>"},{"location":"linux/snippets/#set-static-ip","title":"Set static IP","text":"<pre><code>sudo nano /etc/netplan/00-installer-config.yaml\n</code></pre> <pre><code># This file describes the network interfaces available on your system\n# For more information, see netplan(5).\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    ens33:                #pas dit aan\n      dhcp4: no                #yes/no\n      dhcp6: no                #yes/no\n      addresses: [192.168.1.100/24]    #pas dit aan\n      gateway4: 192.168.1.1        #pas dit aan\n      nameservers:\n        addresses: [8.8.8.8,8.8.4.4]\n</code></pre> <pre><code>sudo netplan apply\n</code></pre>"},{"location":"linux/snippets/#upgrade-ubuntu-2004-to-2204","title":"Upgrade Ubuntu 20.04 to 22.04","text":"<pre><code>sudo apt update &amp; sudo apt upgrade -y\nsudo do-release-upgrade\n</code></pre>"},{"location":"linux/snippets/#sluit-een-process-op-een-gegeven-poort","title":"Sluit een process op een gegeven poort","text":"<pre><code>sudo kill -9 `sudo lsof -t -i:9001`\n</code></pre>"},{"location":"linux/snippets/#log-all-bash-commandos-in-een-file","title":"Log all Bash commando's in een file","text":"<p>Om alle bash commando's bij te houden in een file geef je volgend commando in:</p> <pre><code>trap 'echo \"$USER\":\"$BASH_COMMAND\" &gt;&gt;/path/to/log' DEBUG\n</code></pre>"},{"location":"linux/ssh/","title":"SSH","text":""},{"location":"linux/ufw/","title":"UFW (uncomplicated firewall)","text":""},{"location":"linux/ufw/#ufw-uncomplicated-firewall","title":"UFW (uncomplicated firewall)","text":"<p>UFW (uncomplicated firewall) is a firewall configuration tool for Linux ([[linux]]) that runs on top of IPTables ([[iptables]]), included by default within Ubuntu distributions. It provides a streamlined interface for configuring common firewall use cases via the command line.</p>"},{"location":"linux/ufw/#enable-ufw","title":"Enable UFW","text":"<p>To check if ufw is enabled, run: </p><pre><code>sudo ufw status\n</code></pre> <p>To enable UFW on your system, run: </p><pre><code>sudo ufw enable\n</code></pre> <p>If for some reason you need to disable UFW, you can do so with the following command: </p><pre><code>sudo ufw disable\n</code></pre> <p>Block an IP Address</p>"},{"location":"linux/ufw/#block-an-ip-addresssubnet","title":"Block an IP Address/Subnet","text":"<pre><code>sudo ufw deny from 203.0.113.0/24\n</code></pre>"},{"location":"linux/user/","title":"User Management","text":""},{"location":"linux/user/#user-management","title":"User Management","text":"COMMAND DESCRIPTION <code>sudo adduser username</code> Maak een nieuwe gebruiker <code>sudo userdel username</code> verwijder een gebruiker <code>sudo usermod -aG groupname username</code> Voeg gebruiker toe aan een groep <code>sudo deluser username groupname</code> Verwijder gebruiker van een groep"},{"location":"linux/distros/centos/","title":"CentOS","text":""},{"location":"linux/distros/centos/#centos","title":"CentOS","text":"<p>CentOS, from Community Enterprise Operating System; also known as CentOS Linux) is a Linux distribution that provides a free and open-source community-supported computing platform, functionally compatible with its upstream source, Red Hat Enterprise Linux (RHEL). CentOS announced the official joining with Red Hat while staying independent from RHEL, under a new CentOS governing board.</p>"},{"location":"linux/distros/debian/","title":"Debian","text":""},{"location":"linux/distros/debian/#debian","title":"Debian","text":"<p>Debian also known as Debian GNU/Linux, is a Linux distribution composed of free and open-source software, developed by the community-supported Debian Project. The Debian Stable branch is the most popular edition for personal computers and servers. Debian is also the basis for many other distributions, most notably Ubuntu.</p>"},{"location":"linux/distros/rpi_os/","title":"Raspberry Pi OS","text":""},{"location":"linux/distros/ubuntu/","title":"Ubuntu","text":""},{"location":"linux/distros/ubuntu/#ubuntu","title":"Ubuntu","text":"<p>Ubuntu is a Linux distribution based on Debian and composed mostly of free and open-source software.Ubuntu is officially released in three editions: Desktop, Server, and Core for Internet of things devices and robots. Ubuntu is a popular operating system for cloud computing, with support for OpenStack.</p>"},{"location":"linux/distros/ubuntu/#how-to-enable-sudo-without-a-password-for-a-user","title":"How to enable sudo without a password for a user","text":"<p>Open a Terminal window and type:</p> <pre><code>sudo visudo\n</code></pre> <p>In the bottom of the file, add the following line:</p> <pre><code>$USER ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>Where <code>$USER</code> is your username on your system. Save and close the sudoers file (if you haven't changed your default terminal editor (you'll know if you have), press Ctl + x to exit <code>nano</code> and it'll prompt you to save).</p>"},{"location":"linux/distros/ubuntu/#networking","title":"Networking","text":"<p>In Ubuntu, networking can be managed using various tools and utilities, including the following:</p> <ol> <li> <p>NetworkManager: NetworkManager is a system service that manages network connections and devices. It provides a graphical user interface (GUI) for configuring network settings, as well as a command-line interface (CLI) for advanced configuration. NetworkManager is the default network management tool in Ubuntu.</p> </li> <li> <p>Netplan: Netplan is a command-line utility for configuring network interfaces in modern versions of Ubuntu. It uses YAML configuration files to describe network interfaces, IP addresses, routes, and other network-related parameters. Netplan generates the corresponding configuration files for the underlying network configuration subsystem, such as systemd-networkd or NetworkManager.</p> </li> <li> <p>ifupdown: ifupdown is a traditional command-line tool for managing network interfaces in Ubuntu. It uses configuration files located in the \ufeff/etc/network/ directory to configure network interfaces, IP addresses, routes, and other network-related parameters.</p> </li> </ol> <p>To manage networking in Ubuntu, you can use one or more of these tools depending on your needs and preferences. For example, you can use the NetworkManager GUI to configure basic network settings and use Netplan or ifupdown for advanced configuration. You can also use the command-line tools to automate network configuration tasks or to configure networking on headless servers.</p>"},{"location":"linux/distros/ubuntu/#ubuntu-upgraden-van-bv-2004-naar-2204","title":"Ubuntu upgraden van bv 20.04 naar 22.04","text":"<pre><code>sudo apt update &amp; sudo apt upgrade -y\nsudo do-release-upgrade\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/","title":"Fedora","text":""},{"location":"linux/distros/Fedora/fedora/#fedora","title":"Fedora","text":"<p>Fedora Linux is a Linux distribution developed by the Fedora Project. Fedora contains software distributed under various free and open-source licenses and aims to be on the leading edge of open-source technologies. Fedora is the upstream source for Red Hat Enterprise Linux.</p> <p>Since the release of Fedora 35, six different editions are made available tailored to personal computer, server, cloud computing, container and Internet of Things installations. A new version of Fedora Linux is released every six months.</p> <p>Project Homepage: Home - Fedora Documentation: Fedora Documentation</p>"},{"location":"linux/distros/Fedora/fedora/#post-install-steps","title":"Post Install Steps","text":""},{"location":"linux/distros/Fedora/fedora/#1-enable-caching-in-dnf-package-manager","title":"1- Enable Caching in dnf Package Manager","text":"<p>Caching is Enabled to increase dnf speed</p> <p>Edit dnf configuration: </p><pre><code>sudo nano /etc/dnf/dnf.conf\n</code></pre> Add this lines add the end: <pre><code># Added for speed:\nfastestmirror=True\n#change to 10 if you have fast internet speed\nmax_parallel_downloads=5\n#when click enter the default is yes\ndefaultyes=True\n#Keeps downloaded packages in the cache\nkeepcache=True\n</code></pre> To clean dnf cache periodically: <pre><code>sudo dnf clean dbcache\n#or\nsudo dnf clean all\n</code></pre> for more configuration options: DNF Configuration Reference"},{"location":"linux/distros/Fedora/fedora/#2-system-update","title":"2- System Update","text":"<p>Run the following command: </p><pre><code>sudo dnf update\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/#3-enable-rpm-fusion","title":"3- Enable RPM Fusion","text":"<p>RPM Fusion\u00a0provides software that the Fedora Project or Red Hat doesn't want to ship. That software is provided as precompiled RPMs for all current Fedora versions and current Red Hat Enterprise Linux or clones versions; you can use the RPM Fusion repositories with tools like yum and PackageKit.</p> <p>Installing both free and non-free RPM Fusion: </p><pre><code>sudo dnf install https://mirrors.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://mirrors.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/#appstream-metadata","title":"AppStream metadata","text":"<p>to enable users to install packages using Gnome Software/KDE Discover. Please note that these are a subset of all packages since the metadata are only generated for GUI packages.</p> <p>The following command will install the required packages: </p><pre><code>sudo dnf groupupdate core\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/#4-adding-flatpak","title":"4- Adding Flatpak","text":"<p>Flatpak, formerly known as xdg-app, is a utility for software deployment and package management for Linux. It is advertised as offering a sandbox environment in which users can run application software in isolation from the rest of the system.</p> <p>Flatpak is installed by default on Fedora Workstation, Fedora Silverblue, and Fedora Kinoite. To get started, all you need to do is enable Flathub, which is the best way to get Flatpak apps. Just download and install the\u00a0Flathub repository file</p> <p>The above links should work on the default GNOME and KDE Fedora installations, but if they fail for some reason you can manually add the Flathub remote by running: </p><pre><code>flatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/#5-change-hostname","title":"5- Change Hostname","text":"<p>Run the following command: </p><pre><code>sudo hostnamectl set-hostname #your-name\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/#6-add-multimedia-codecs","title":"6- Add Multimedia Codecs","text":"<p>Run the following commands: </p><pre><code>sudo dnf groupupdate multimedia --setop=\"install_weak_deps=False\" --exclude=PackageKit-gstreamer-plugin\n\nsudo dnf groupupdate sound-and-video\n</code></pre>"},{"location":"linux/distros/Fedora/fedora/#7-make-it-more-customizable","title":"7- Make it More  Customizable","text":"<p>Open GNOME software installer and install the following: - GNOME Tweaks - Extensions</p> <p>Consider the following GNOME Extensions: - Vitals - ArcMenu - Custom Hot Corners - Extended - Dash to Panel - Sound input &amp; ouput Device Chooser - OpenWeather - Impatience - Screenshot Tool - Tiling Assistant - Extension List - Clipboard Indicator</p>"},{"location":"linux/distros/Fedora/login%20fix/","title":"Login fix","text":""},{"location":"linux/distros/Fedora/login%20fix/#gdm-login-scherm-op-ultrawide-monitor-fedora","title":"GDM Login Scherm op Ultrawide Monitor - Fedora","text":""},{"location":"linux/distros/Fedora/login%20fix/#het-probleem","title":"Het Probleem","text":"<p>Bij een multi-monitor setup met een ultrawide monitor verschijnt het GDM (GNOME Display Manager) login scherm vaak op het verkeerde scherm of is helemaal niet zichtbaar. Dit gebeurt omdat GDM zijn eigen monitor configuratie gebruikt, los van jouw gebruikersinstellingen.</p>"},{"location":"linux/distros/Fedora/login%20fix/#wat-we-gaan-doen","title":"Wat we gaan doen","text":"<p>We kopi\u00ebren de monitor configuratie van jouw gebruikersaccount naar GDM, zodat het login scherm dezelfde instellingen gebruikt als jouw desktop. Hierdoor verschijnt het login scherm op de juiste monitor met de juiste resolutie.</p>"},{"location":"linux/distros/Fedora/login%20fix/#oplossing","title":"Oplossing","text":""},{"location":"linux/distros/Fedora/login%20fix/#stap-1-configureer-je-schermen","title":"Stap 1: Configureer je schermen","text":"<ol> <li>Log in op je systeem</li> <li>Open Settings \u2192 Displays</li> <li>Stel je ultrawide monitor in als Primary (primaire monitor)</li> <li>Controleer of de positie en resolutie correct zijn</li> <li>Klik op Apply</li> </ol> <p>Dit maakt automatisch een <code>monitors.xml</code> bestand aan in <code>~/.config/</code></p>"},{"location":"linux/distros/Fedora/login%20fix/#stap-2-kopieer-de-configuratie-naar-gdm","title":"Stap 2: Kopieer de configuratie naar GDM","text":"<p>Open een terminal en voer deze commando's uit:</p> <pre><code># Maak de directory aan als deze nog niet bestaat\nsudo mkdir -p /etc/xdg\n\n# Kopieer de monitor configuratie\nsudo cp ~/.config/monitors.xml /etc/xdg/monitors.xml\n</code></pre>"},{"location":"linux/distros/Fedora/login%20fix/#stap-3-herstart","title":"Stap 3: Herstart","text":"<pre><code>sudo systemctl reboot\n</code></pre> <p>Na het herstarten zou je login scherm nu op de juiste monitor moeten verschijnen.</p>"},{"location":"linux/distros/Fedora/login%20fix/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/distros/Fedora/login%20fix/#het-werkt-nog-steeds-niet","title":"Het werkt nog steeds niet","text":"<p>Als het nog steeds niet werkt, controleer dan of het bestand correct is gekopieerd:</p> <pre><code>ls -l /etc/xdg/monitors.xml\n</code></pre> <p>Je zou iets moeten zien zoals: </p><pre><code>-rw-r--r--. 1 root root 1234 Nov 24 10:30 /etc/xdg/monitors.xml\n</code></pre>"},{"location":"linux/distros/Fedora/login%20fix/#na-een-monitor-wijziging","title":"Na een monitor wijziging","text":"<p>Als je later je monitor setup wijzigt, herhaal dan gewoon stap 1 en 2.</p>"},{"location":"linux/distros/Fedora/login%20fix/#wayland-vs-xorg","title":"Wayland vs X.Org","text":"<p>Deze oplossing werkt voor zowel Wayland als X.Org sessies op moderne Fedora versies.</p>"},{"location":"linux/distros/popos/customization/","title":"Pop!_OS changes","text":""},{"location":"linux/distros/popos/customization/#gnome","title":"Gnome","text":"<p>Pop!_OS gebruikt Gnome als window manager.</p>"},{"location":"linux/distros/popos/customization/#gnome-extensions","title":"Gnome extensions","text":"<ol> <li>Ga naar https://extensions.gnome.org/</li> <li>Download en installeer de Browser Extension in je browser (zie link bovenaan de pagina)    !!! note    The extension allows GNOME to look in the user directory for themes and icons</li> <li>Click op <code>User Themes</code> en activeer deze.</li> </ol>"},{"location":"linux/distros/popos/customization/#folder-creatie","title":"Folder creatie","text":"<p>Voor je van start kunt, moet je eerst 2 folders aanmaken.</p> <ol> <li>Ga naar je home directory.</li> <li>Maak de folders <code>.themes</code> en <code>.icons</code>.</li> </ol>"},{"location":"linux/distros/popos/customization/#dracula-theme","title":"Dracula Theme","text":"<ol> <li>Ga naar https://draculatheme.com.</li> <li>Vul <code>gtk</code> in de zoekbalk</li> <li>Download het zip bestand van Github</li> <li>Drag-and-drop de folder in de zip file naar <code>~/.themes</code></li> <li>Hernoem de folder naar <code>Dracula</code></li> </ol>"},{"location":"linux/distros/popos/customization/#gnome-tweaks","title":"Gnome Tweaks","text":""},{"location":"linux/distros/popos/customization/#installatie-gnome-tweaks","title":"Installatie gnome-tweaks","text":"<p>Installeer <code>gnome-tweaks</code> met <code>sudo apt install gnome-tweaks</code></p>"},{"location":"linux/distros/popos/customization/#aanpassingen","title":"Aanpassingen","text":"<p>Open <code>gnome-tweaks</code> en ga naar de <code>Appearance</code> tab en verander het volgende:</p> <ul> <li>Applications: <code>Dracula</code></li> <li>Shell: <code>Dracula</code></li> </ul> <p>Danger</p> <p>Er zullen vermoedelijk al enkele zaken aangepast zijn, maar om zeker te zijn, is het best om uit te loggen en terug in te loggen.</p>"},{"location":"linux/distros/popos/customization/#icon-pack-cursor","title":"Icon pack &amp; Cursor","text":""},{"location":"linux/distros/popos/customization/#icon-pack","title":"Icon pack","text":"<ol> <li>Ga naar https://www.gnome-look.org</li> <li>Zoek naar <code>Flatery</code> </li> <li>Download de <code>indigo</code> versie.</li> </ol>"},{"location":"linux/distros/popos/customization/#cursor","title":"Cursor","text":"<ol> <li>Ga naar https://www.gnome-look.org</li> <li>Zoek naar <code>McMojave cursors</code> </li> <li>Download</li> </ol>"},{"location":"linux/distros/popos/customization/#installatie-flatery-mcmojave","title":"Installatie flatery &amp; McMojave","text":"<ol> <li>Sleep de <code>flatery</code> &amp; <code>McMojave</code> folders in de zip file naar <code>~/.icons</code></li> <li>Open <code>gnome-tweaks</code> opnieuw</li> <li>Ga naar de <code>Appearance</code> tab</li> <li>Verander volgende zaken</li> <li>Icons: <code>Flatery-Indigo</code></li> <li>Cursor: <code>McMojave-cursors</code></li> </ol>"},{"location":"linux/distros/popos/customization/#andere-theme-voor-de-shell","title":"Andere theme voor de Shell","text":"<ol> <li>Ga naar https://www.gnome-look.org</li> <li>Zoek naar <code>Sweet - New Flavor</code>.    </li> <li>Download <code>Sweet-Dark-v40.tar.xz</code></li> <li>Sleep de folder naar <code>~/.themes</code> folder.</li> <li>Open <code>gnome-tweaks</code> opnieuw</li> <li>Ga naar de <code>Appearance</code> tab</li> <li>Verander volgende zaken</li> <li>Shell: <code>Sweet-Dark-v40</code></li> </ol>"},{"location":"linux/distros/popos/customization/#andere-gnome-extensions","title":"Andere Gnome extensions","text":""},{"location":"linux/distros/popos/customization/#dash-to-panel","title":"Dash to Panel","text":"<ol> <li>Ga naar https://extensions.gnome.org/</li> <li>Zoek naar <code>Dash to Panel</code> </li> <li>Activeer de extension</li> </ol>"},{"location":"linux/distros/popos/customization/#configuratie-dash-to-panel","title":"Configuratie Dash to Panel","text":"<ol> <li>Open de <code>Extensions</code> app</li> <li>Neem volgende instellingen over:     </li> </ol> <p>Note</p> <p>Indien gewenst, kan je mijn export file gebruiken.</p>"},{"location":"linux/distros/popos/customization/#andere-interessante-extensies","title":"Andere interessante extensies","text":"Nr. Extensie Beschrijving URL 1. Dash to Dock Verandert het GNOME-dash in een dock-stijl interface. Dash to Dock 2. Arc Menu Biedt een toegankelijk en aanpasbaar startmenu. Arc Menu 3. User Themes Stelt gebruikers in staat thema's toe te passen op GNOME Shell. User Themes 4. OpenWeather Toont het weerbericht en de weersvoorspellingen in de GNOME Shell. OpenWeather 5. Desktop Icons Herstelt de mogelijkheid om pictogrammen op het bureaublad weer te geven. Desktop Icons 6. Caffeine Voorkomt dat je computer in de slaapstand gaat. Caffeine 7. Clipboard Indicator Houdt een geschiedenis bij van gekopieerde items op het klembord. Clipboard Indicator 8. GSConnect Integreert je Android-apparaat met GNOME Shell via KDE Connect. GSConnect 9. AppIndicator Support Ondersteunt legacy-appindicatoren in de GNOME Shell. AppIndicator Support 10. Night Light Slider Biedt een schuifregelaar voor het aanpassen van de Night Light-instellingen. Night Light Slider 11. Sound Input &amp; Output Device Chooser Maakt snel wisselen tussen audioapparaten mogelijk. Sound Input &amp; Output Device Chooser 12. Places Status Indicator Geeft snelle toegang tot mappen en recent geopende bestanden. Places Status Indicator 13. NetSpeed Toont de huidige netwerksnelheid in het systeemvak. NetSpeed 14. Pixel Saver Verkleint de titelbalk van vensters om ruimte te besparen. Pixel Saver 15. Screenshot Tool Biedt een verbeterde interface voor het maken van schermafbeeldingen. Screenshot Tool 16. AlternateTab Voegt previews toe aan de applicatieswitcher. AlternateTab 17. Dynamic Panel Transparency Past de paneeltransparantie aan op basis van achtergrondinhoud. Dynamic Panel Transparency 18. Coverflow Alt-Tab Biedt een alternatieve, visueel aantrekkelijke applicatieswitcher. Coverflow Alt-Tab 19. Removable Drive Menu Maakt het eenvoudig om externe schijven te beheren en los te koppelen. Removable Drive Menu 20. Extensions Beheert GNOME Shell-extensies rechtstreeks vanuit het systeemvak. Extensions 21. Places GNOME Shell Extension Voegt bladwijzers en recente bestanden toe aan het toepassingsmenu. Places GNOME Shell Extension 22. Panel OSD Verplaatst meldingen van de GNOME Shell naar het paneel. Panel OSD 23. Frippery Move Clock Verplaatst de klok van de rechterbovenhoek naar het paneel. Frippery Move Clock 24. Lock Keys Geeft meldingen weer wanneer Caps Lock of Num Lock is ingeschakeld. Lock Keys 25. Emoji Selector Biedt een eenvoudige interface voor het invoegen van emoji's. Emoji Selector 26. Native Window Placement Behoudt de grootte en positie van vensters tussen sessies. Native Window Placement 27. Battery Status Toont het batterijniveau en laadstatus in het systeemvak. Battery Status 28. Dynamic Top Bar Verbergt het bovenste paneel bij het maximaliseren van vensters. Dynamic Top Bar 29. Refresh Wi-Fi Connections Biedt een snelkoppeling om draadloze netwerken te vernieuwen. Refresh Wi-Fi Connections 30. Bluetooth quick connect Voegt snelkoppelingen toe voor Bluetooth-apparaten in het menu. Bluetooth quick connect 31. No Topleft Hot Corner Schakelt de actieve hoekfunctie van de linkerbovenhoek uit. No Topleft Hot Corner 32. Transparent GNOME Panel Maakt het bovenste paneel transparant. Transparent GNOME Panel 33. Impatience Versnelt de animatiesnelheid van GNOME Shell. Impatience 34. Appfolders Management Extension Beheert toepassingsmappen rechtstreeks vanuit het toepassingsoverzicht. Appfolders Management Extension 35. TopIcons Plus Brengt appindicatoren terug naar de bovenste balk. TopIcons Plus 36. Drop Down Terminal Biedt een neerklapbare terminal op volledig scherm. Drop Down Terminal 37. Workspace Indicator Toont een indicator voor het huidige werkblad in het systeemvak. Workspace Indicator 38. Auto Move Windows Verplaatst vensters automatisch naar specifieke werkbladen. Auto Move Windows 39. CPU Power Manager Beheert de CPU-prestaties en energiebesparing. CPU Power Manager 40. Places Biedt snelle toegang tot veelgebruikte mappen. Places 41. Proxy Switcher Schakelt eenvoudig tussen proxy-instellingen. Proxy Switcher 42. Dynamic Wallpaper Stelt dynamische wallpapers in die automatisch veranderen. Dynamic Wallpaper 43. Steal My Focus Voorkomt dat vensters de focus stelen. Steal My Focus 44. Workspace Grid Biedt een rasterlay-out voor werkbladen. Workspace Grid 45. GSConnect Clipboard Indicator Synchroniseert het klembord tussen apparaten met GSConnect. GSConnect Clipboard Indicator 46. Just Perfection Voegt verschillende visuele aanpassingen toe aan GNOME Shell. Just Perfection 47. Blur My Shell Voegt onscherpte toe aan de GNOME Shell-interface. Blur My Shell 48. Hide Top Bar Verbergt het bovenste paneel wanneer vensters worden gemaximaliseerd. Hide Top Bar 49. Time ++ Voegt extra functies toe aan de klok in het bovenste paneel. Time ++ 50. Vitals Toont systeemmonitoringgegevens, zoals CPU- en geheugengebruik. Vitals"},{"location":"linux/distros/popos/customization/#tilix","title":"Tilix","text":"<p>Tilix is een terminalemulator voor Linux die is ontwikkeld door het Tilix-project. Het is een krachtige en aanpasbare terminalemulator met een groot aantal functies.</p>"},{"location":"linux/distros/popos/customization/#installatie-tilix","title":"Installatie Tilix","text":"<p>Installeer Tilix met <code>sudo apt install tilix</code>.</p>"},{"location":"linux/distros/popos/customization/#verander-kleurenschema-van-tilix","title":"Verander kleurenschema van Tilix","text":"<ol> <li>Ga naar https://gogh-co.github.io/Gogh</li> <li>Scroll op de pagina tot je een gewenste theme wilt gebruiken. Bedar gebruikt momenteel <code>Agronaut</code>.</li> <li>Vul in terminal het Linux commando <code>bash -c  \"$(wget -qO- https://git.io/vQgMr)\"</code>.</li> <li>Zoek het gewenste schema in de lijst en vul het correcte cijfer in. (bv als je het 9de item wilt nemen, vul dan <code>09</code> in)</li> <li>Ga in <code>timix</code> naar <code>Settings &gt; Preferences</code> en selecteer het nieuwe profiel.</li> <li>Klik op de pijl en selecteer <code>Use for new terminals</code>.</li> </ol>"},{"location":"linux/distros/popos/keyboard-shortcuts/","title":"Keyboard Shortcuts","text":""},{"location":"linux/distros/popos/keyboard-shortcuts/#systeembrede-toetsencombinaties","title":"Systeembrede toetsencombinaties","text":""},{"location":"linux/distros/popos/keyboard-shortcuts/#toetsencombinaties-voor-het-bureaublad-en-vensterbeheer","title":"Toetsencombinaties voor het bureaublad en vensterbeheer","text":"Toetsencombinatie Beschrijving ++Super++ Toont het overzicht van de beschikbare toetsencombinaties ++Super++ + ++D++ Toont het bureaublad ++Super++ + ++E++ Opent de bestandsbeheerder ++Super++ + ++F++ Opent de zoekfunctie ++Super++ + ++L++ Vergrendelt het scherm ++Super++ + ++M++ Minimaliseert het huidige venster ++Super++ + ++P++ Schakelt tussen schermmodi (PAS OP: Heeft Cowarol Linux kapot gemaakt) ++Super++ + ++S++ Neemt een schermafbeelding ++Super++ + ++T++ Opent een nieuw terminalvenster ++Super++ + ++W++ Sluit het huidige venster ++Super++ + ++Plus++ Vergroot het scherm ++Super++ + ++Minus++ Verkleint het scherm ++Super++ + ++1-9++ Schakelt naar het bijbehorende venster ++Super++ + ++Shift++ + ++D++ Versleept een venster naar een ander scherm ++Super++ + ++Tab++ Schakelt tussen vensters ++Super++ + ++Arrow++ Verplaatst en richt vensters uit"},{"location":"linux/distros/popos/keyboard-shortcuts/#toetsencombinaties-voor-taal-en-invoerinstellingen","title":"Toetsencombinaties voor taal- en invoerinstellingen","text":"Toetsencombinatie Beschrijving ++Super++ + ++Space++ Schakelt tussen invoertalen"},{"location":"linux/distros/popos/keyboard-shortcuts/#vensterbeheer","title":"Vensterbeheer","text":""},{"location":"linux/distros/popos/keyboard-shortcuts/#toetsencombinaties-voor-vensterverplaatsing","title":"Toetsencombinaties voor vensterverplaatsing","text":"Toetsencombinatie Beschrijving ++Super++ + ++Left/Right++ Plaatst een venster aan de linkerkant of rechterkant van het scherm ++Super++ + ++Up/Down++ Maximaliseert of herstelt een venster ++Super++ + ++Ctrl++ + ++Left/Right++ Wisselt tussen werkruimtes aan de linkerkant of rechterkant ++Super++ + ++Ctrl++ + ++Up/Down++ Wisselt tussen werkruimtes boven of onder het huidige werkruimte ++Super++ + ++Ctrl++ + ++Alt++ + ++Left/Right++ Verplaatst een venster naar het vorige of volgende scherm ++Super++ + ++Ctrl++ + ++Alt++ + ++Up/Down++ Verplaatst een venster naar het scherm boven of onder het huidige scherm ++Super++ + ++Ctrl++ + ++Shift++ + ++Left/Right++ Plaatst een venster naar het linkervenster of rechtervenster ++Super++ + ++Ctrl++ + ++Shift++ + ++Up/Down++ Plaatst een venster naar het bovenste venster of onderste venster"},{"location":"linux/distros/popos/keyboard-shortcuts/#toetsencombinaties-voor-vensterselectie","title":"Toetsencombinaties voor vensterselectie","text":"Toetsencombinatie Beschrijving ++Super++ + ++Shift++ + ++S++ Selecteert een gedeelte van het scherm voor het maken van een schermafbeelding"},{"location":"linux/distros/popos/keyboard-shortcuts/#overige-toetsencombinaties","title":"Overige toetsencombinaties","text":""},{"location":"linux/distros/popos/keyboard-shortcuts/#algemene-toetsencombinaties","title":"Algemene toetsencombinaties","text":"Toetsencombinatie Beschrijving ++Ctrl++ + ++Alt++ + ++T++ Opent een terminalvenster ++Ctrl++ + ++Alt++ + ++L++ Vergrendelt het scherm ++Ctrl++ + ++Alt++ + ++D++ Toont het bureaublad ++Ctrl++ + ++Alt++ + ++Up/Down++ Verplaatst tussen vensters boven en onder elkaar ++Ctrl++ + ++Alt++ + ++Left/Right++ Verplaatst tussen vensters links en rechts van elkaar <p>Bron: Pop!_OS Keyboard Shortcuts</p>"},{"location":"linux/distros/popos/popos/","title":"Pop OS","text":""},{"location":"misc/awesome-lists/","title":"Awesome Lists","text":""},{"location":"misc/awesome-lists/#awesome-lists","title":"Awesome Lists","text":"<p>Dit is een verzameling van \"Awesome List\" repo's</p>"},{"location":"misc/awesome-lists/#linux","title":"Linux","text":"<ul> <li>Awesome Shell</li> </ul>"},{"location":"misc/awesome-lists/#netwerk","title":"Netwerk","text":"<ul> <li>Awesome Networking</li> </ul>"},{"location":"misc/awesome-lists/#programming","title":"Programming","text":"<ul> <li>GitHub - coder/awesome-coder: A curated list of awesome Coder resources.</li> </ul>"},{"location":"misc/awesome-lists/#automation","title":"Automation","text":"<ul> <li>Awesome Home Assistant</li> </ul>"},{"location":"misc/awesome-lists/#selfhosting","title":"Selfhosting","text":"<ul> <li>Most used self-hosted services in 2022</li> <li>selfh.st/releases</li> </ul>"},{"location":"misc/awesome-lists/#gaming","title":"Gaming","text":""},{"location":"misc/awesome-lists/#fivem","title":"Fivem","text":"<ul> <li>Awesome Fivem</li> </ul>"},{"location":"misc/http-status-codes/","title":"HTTP Status Codes","text":""},{"location":"misc/http-status-codes/#http-status-codes","title":"HTTP Status Codes","text":""},{"location":"misc/http-status-codes/#categories","title":"Categories","text":"<ul> <li>1XX status codes: Informational Requests</li> <li>2XX status codes: Successful Requests</li> <li>3XX status codes: Redirects</li> <li>4XX status codes: Client Errors</li> <li>5XX status codes: Server Errors</li> </ul>"},{"location":"misc/http-status-codes/#complete-list","title":"Complete List","text":"Code Name Description 100 Continue Everything so far is OK and that the client should continue with the request or ignore it if it is already finished. 101 Switching Protocols The client has asked the server to change protocols and the server has agreed to do so. 102 Processing The server has received and is processing the request, but that it does not have a final response yet. 103 Early Hints Used to return some response headers before final HTTP message. 200 OK Successful request. 201 Created The server acknowledged the created resource. 202 Accepted The client's request has been received but the server is still processing it. 203 Non-Authoritative Information The response that the server sent to the client is not the same as it was when the server sent it. 204 No Content There is no content to send for this request 205 Reset Content Tells the user agent to reset the document which sent this request. 206 Partial Content This response code is used when the range-header is sent from the client to request only part of a resource. 207 Multi-Status Conveys information about multiple resources, for situations where multiple status codes might be appropriate. 208 Already Reported The members of a DAV binding have already been enumerated in a preceding part of the multi-status response. 226 IM Used IM is a specific extension of the HTTP protocol. The extension allows a HTTP server to send diffs (changes) of resources to clients. 300 Multiple Choices The request has more than one possible response. The user agent should choose one. 301 Moved Permanently The URL of the requested resource has been changed permanently. The new URL is given in the response. 302 Found This response code means that the URI of requested resource has been changed temporarily 303 See Other The server sent this response to direct the client to get the requested resource at another URI with a GET request. 304 Not Modified It tells the client that the response has not been modified, so the client can continue to use the same cached version of the response. 305 Use Proxy Defined in a previous version of the HTTP specification to indicate that a requested response must be accessed by a proxy. (discontinued) 307 Temporary Redirect The server sends this response to direct the client to get the requested resource at another URI with same method that was used in the prior request. 308 Permanent Redirect This means that the resource is now permanently located at another URI, specified by the Location: HTTP Response header. 400 Bad Request The server could not understand the request 401 Unauthorized The client didn't authenticate himself. 402 Payment Required This response code is reserved for future use. The initial aim for creating this code was using it for digital payment systems, however this status code is used very rarely and no standard convention exists. 403 Forbidden The client does not have access rights to the content 404 Not Found The server can not find the requested resource 405 Method Not Allowed The request method is known by the server but is not supported by the target resource 406 Not Acceptable The reponse doens't conforms to the creteria given by the client 407 Proxy Authentication Required This is similar to 401 Unauthorized but authentication is needed to be done by a proxy. 408 Request Timeout This response is sent on an idle connection by some servers, even without any previous request by the client. 409 Conflict This response is sent when a request conflicts with the current state of the server. 410 Gone This response is sent when the requested content has been permanently deleted from server, with no forwarding address. 411 Length Required Server rejected the request because the Content-Length header field is not defined and the server requires it. 412 Precondition Failed Access to the target resource has been denied. 413 Payload Too Large Request entity is larger than limits defined by server. 414 Request-URI Too Long The URI requested by the client is longer than the server is willing to interpret. 415 Unsupported Media Type The media format is not supported by the server. 416 Requested Range Not Satisfiable The range specified by the Range header field in the request cannot be fulfilled. 417 Expectation Failed the expectation indicated by the Expect request header field cannot be met by the server. 418 I'm a teapot The server refuses the attempt to brew coffee with a teapot. 421 Misdirected Request The request was directed at a server that is not able to produce a response. 422 Unprocessable Entity The request was well-formed but was unable to be followed due to semantic errors. 423 Locked The resource that is being accessed is locked. 424 Failed Dependency The request failed due to failure of a previous request. 426 Upgrade Required The server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol. 428 Precondition Required his response is intended to prevent the 'lost update' problem, where a client GETs a resource's state, modifies it and PUTs it back to the server, when meanwhile a third party has modified the state on the server, leading to a conflict. 429 Too Many Requests The user has sent too many requests in a given amount of time 431 Request Header Fields Too Large The server is can't process the request because its header fields are too large. 444 Connection Closed Without Response The connection opened, but no data was written. 451 Unavailable For Legal Reasons The user agent requested a resource that cannot legally be provided (such as a web page censored by a government) 499 Client Closed Request The client closed the connection, despite the server was processing the request already. 500 Internal Server Error The server has encountered a situation it does not know how to handle. 501 Not Implemented The request method is not supported by the server and cannot be handled. 502 Bad Gateway This error response means that the server, while working as a gateway to get a response needed to handle the request, got an invalid response. 503 Service Unavailable The server is not ready to handle the request. 504 Gateway Timeout This error response is given when the server is acting as a gateway and cannot get a response in time. 505 HTTP Version Not Supported The HTTP version used in the request is not supported by the server. 506 Variant Also Negotiates the chosen variant resource is configured to engage in transparent content negotiation itself, and is therefore not a proper end point in the negotiation process. 507 Insufficient Storage The method could not be performed on the resource because the server is unable to store the representation needed to successfully complete the request. 508 Loop Detected The server detected an infinite loop while processing the request. 510 Not Extended Further extensions to the request are required for the server to fulfill it. 511 Network Authentication Required Indicates that the client needs to authenticate to gain network access. 599 Network Connect Timeout Error The connection timed out due to a overloaded server, a hardware error or a infrastructure error."},{"location":"misc/markdown/","title":"Markdown","text":""},{"location":"misc/markdown/#markdown","title":"Markdown","text":"<p>Markdown is a text-to-HTML conversion tool for web writers. Markdown allows you to write using an easy-to-read, easy-to-write plain text format, then convert it to structurally valid XHTML (or HTML).</p> <p>Documentation: Markdown Docs RFC: RFC 7763 GitHub Documentation: Writing Markdown on GitHub</p>"},{"location":"misc/markdown/#cheat-sheet","title":"Cheat-Sheet","text":""},{"location":"misc/markdown/#headings","title":"Headings","text":"<pre><code># Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n##### Heading 5\n###### Heading 6\n</code></pre> <p>Here is a heading: <code># Heading</code>, don't do this: <code>#Heading</code></p>"},{"location":"misc/markdown/#emphasis","title":"Emphasis","text":"<pre><code>Emphasis, aka italics, with *asterisks* or _underscores_.\n\nStrong emphasis, aka bold, with **asterisks** or __underscores__.\n\nCombined emphasis with **asterisks and _underscores_**.\n\nStrikethrough uses two tildes. ~~Scratch this.~~\n</code></pre>"},{"location":"misc/markdown/#line-breaks","title":"Line Breaks","text":"<pre><code>First line with two spaces after.\nAnd the next line.\n</code></pre>"},{"location":"misc/markdown/#lists","title":"Lists","text":""},{"location":"misc/markdown/#ordered-lists","title":"Ordered Lists","text":"<pre><code>1. First item\n2. Second item\n3. Third item\n</code></pre>"},{"location":"misc/markdown/#unordered-lists","title":"Unordered Lists","text":"<pre><code>- First item\n- Second item\n- Third item\n</code></pre>"},{"location":"misc/markdown/#links","title":"Links","text":"<pre><code>Link with text: [link-text](https://www.google.com)\n</code></pre>"},{"location":"misc/markdown/#images","title":"Images","text":"<pre><code>Image with alt text: ![alt-text](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067)\n\nImage without alt text: ![](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067)\n</code></pre>"},{"location":"misc/markdown/#code-blocks","title":"Code Blocks","text":""},{"location":"misc/markdown/#inline-code-block","title":"Inline Code Block","text":"<pre><code>Inline `code` has `back-ticks around` it.\n</code></pre>"},{"location":"misc/markdown/#blocks-of-code","title":"Blocks of Code","text":"<pre>\n<pre><code>var s = \"JavaScript syntax highlighting\";\nalert(s);\n</code></pre>\n\n<pre><code>s = \"Python syntax highlighting\"\nprint s\n</code></pre>\n\n<pre><code>No language indicated, so no syntax highlighting.\nBut let's throw in a &lt;b&gt;tag&lt;/b&gt;.\n</code></pre>\n</pre>"},{"location":"misc/markdown/#tables","title":"Tables","text":"<p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily.</p> <pre><code>| Heading 1 | Heading 2 | Heading 3 |\n|---|---|---|\n| col1 | col2 | col3 |\n| col1 | col2 | col3\u00a0|\n</code></pre>"},{"location":"misc/markdown/#task-list","title":"Task list","text":"<p>To create a task list start line with square brackets with an empty space. Ex: [  ] and add text for task. To check the task replace the space between the bracket with \"x\".</p> <pre><code>[x] Write the post\n[ ] Update the website\n[ ] Contact the user\n</code></pre>"},{"location":"misc/markdown/#reference","title":"Reference","text":"<p>Link: markdown guide</p>"},{"location":"network/networking/","title":"Networking","text":""},{"location":"network/twisted-pair-cables/","title":"Twisted Pair Cables Cheat-Sheet","text":""},{"location":"network/twisted-pair-cables/#twisted-pair-cables-cheat-sheet","title":"Twisted Pair Cables Cheat-Sheet","text":""},{"location":"network/twisted-pair-cables/#cable-types","title":"Cable Types","text":""},{"location":"network/twisted-pair-cables/#unshielded-twisted-pair-utp","title":"Unshielded Twisted Pair (UTP)","text":"<p>As the title states, a UTP cable has no shielding. This is the most used and most basic type of cable. The cable contains pairs of wires twisted together to help reduce and prevent electromagnetic interference.</p>"},{"location":"network/twisted-pair-cables/#shielded-twisted-pair-stp","title":"Shielded Twisted Pair (STP)","text":"<p>STP cables are similar to UTP cables, where the wires are twisted together and then wrapped with a shielding or screening material which consits of foil wrapping or a copper braid jacket.</p>"},{"location":"network/twisted-pair-cables/#foil-twisted-pair-ftp","title":"Foil Twisted Pair (FTP)","text":"<p>With FTP cables, each twisted pair of cables is wrapped in a shielding of foil to protect the cable from EMI and crosstalk.</p>"},{"location":"network/twisted-pair-cables/#shielded-foil-twisted-pair-sftp","title":"Shielded Foil Twisted Pair (S/FTP)","text":"<p>A cable that is classified as S/FTP or Shielded Foil Twisted Pair is a combination of both FTP and STP shielding. The wires inside the cable are twisted and then shielded with a foil wrapping, then the 4-pair grouping of foiled wires are shielded by a wrapping of either foil or a flexible braided screening. This provides the highest level of protection against EMI and crosstalk.</p>"},{"location":"network/twisted-pair-cables/#wiring","title":"Wiring","text":""},{"location":"network/twisted-pair-cables/#tiaeia-568a-wiring","title":"TIA/EIA 568A Wiring","text":"PIN COLOR COLOR-TEXT 1 \u2588\u2588\u2588\u2588\u2588\u2588 White and Green 2 \u2588\u2588\u2588\u2588\u2588\u2588 Green 3 \u2588\u2588\u2588\u2588\u2588\u2588 White and Orange 4 \u2588\u2588\u2588\u2588\u2588\u2588 Blue 5 \u2588\u2588\u2588\u2588\u2588\u2588 White and Blue 6 \u2588\u2588\u2588\u2588\u2588\u2588 Orange 7 \u2588\u2588\u2588\u2588\u2588\u2588 White and Brown 8 \u2588\u2588\u2588\u2588\u2588\u2588 Brown"},{"location":"network/twisted-pair-cables/#tiaeia-568b-wiring","title":"TIA/EIA 568B Wiring","text":"PIN COLOR COLOR-TEXT 1 \u2588\u2588\u2588\u2588\u2588\u2588 White and Orange 2 \u2588\u2588\u2588\u2588\u2588\u2588 Orange 3 \u2588\u2588\u2588\u2588\u2588\u2588 White and Green 4 \u2588\u2588\u2588\u2588\u2588\u2588 Blue 5 \u2588\u2588\u2588\u2588\u2588\u2588 White and Blue 6 \u2588\u2588\u2588\u2588\u2588\u2588 Green 7 \u2588\u2588\u2588\u2588\u2588\u2588 White and Brown 8 \u2588\u2588\u2588\u2588\u2588\u2588 Brown"},{"location":"network/twisted-pair-cables/#categories","title":"Categories","text":"CATEGORY MHz Speed CAT 3 UTP 16MHz 10Mps up to 100m CAT 4 UTP 20MHz 16Mps up to 100m CAT 5 UTP 100MHz 100Mbps up to 100m CAT 5e UTP 100MHz 1000Mbps up to 100m CAT 5e STP 100MHz 1000Mbps up to 100m CAT 6 UTP 250MHz 10Gbps over to 33-55m CAT 6a STP 500MHz 10Gbps over 100m CAT 7 STP 600MHz 10Gbps over 100m CAT 7a STP 1000MHz 10Gbps over 100m CAT 8 STP 2000MHz 25/40Gps up to 30m"},{"location":"network/dns/cloudflare/","title":"Cloudflare","text":""},{"location":"network/dns/ddns/","title":"DDNS","text":""},{"location":"network/dns/ddns/#ddns","title":"DDNS","text":"<p>Een DDNS is noodzakelijk als je met een Dynamisch WAN ip zit. Deze cheked om de zoveel tijd of je WAN IP veranderd is en past dit dan automatisch aan in Cloudflare.</p> docker-compose.yaml <pre><code>services:\ncloudflare-ddns:\n    image: oznu/cloudflare-ddns:latest\n    restart: always\n    environment:\n    - API_KEY=xxxxxxx\n    - ZONE=example.com\n    - SUBDOMAIN=subdomain #optional\n    - PROXIED=false #its better to use true\n</code></pre>"},{"location":"network/dns/ddns/#creating-a-cloudflare-api-token","title":"Creating a Cloudflare API token","text":"<p>To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens\u2060 and follow these steps:</p> <ol> <li>Click Create Token</li> <li>Provide the token a name, for example, cloudflare-ddns</li> <li>Grant the token the following permissions:<ul> <li>Zone - Zone Settings - Read</li> <li>Zone - Zone - Read</li> <li>Zone - DNS - Edit</li> </ul> </li> <li>Set the zone resources to:<ul> <li>Include - All zones</li> </ul> </li> <li>Complete the wizard and copy the generated token into the API_KEY variable for the container</li> </ol>"},{"location":"network/dns/dns-record-mailserver/","title":"Mail Server DNS Records Cheat-Sheet","text":""},{"location":"network/dns/dns-record-mailserver/#mail-server-dns-records-cheat-sheet","title":"Mail Server DNS Records Cheat-Sheet","text":"<p>If you want to run a mail server\u00a0on the public internet, you need to set up\u00a0your DNS Records correctly. While some DNS Records are necessary to send and receive emails, others are recommended to build a good reputation.</p>"},{"location":"network/dns/dns-record-mailserver/#required-mail-server-dns-records","title":"Required Mail Server DNS Records","text":""},{"location":"network/dns/dns-record-mailserver/#a-record","title":"A Record","text":"<p>DNS A Record that will resolve to the public IP address of your mail server. This is also needed when your web\u00a0server has a different IP address than your mail server.</p> <p>Recommended Settings Example:</p> Type Host Points to TTL <code>A</code> <code>mail</code> <code>your-mail-servers-ipv4</code> <code>1 hour</code>"},{"location":"network/dns/dns-record-mailserver/#mx-record","title":"MX Record","text":"<p>The MX record is important when you want to receive\u00a0emails. This tells everyone which IP address to contact.</p> <p>If you have multiple Mail Servers that need to be load-balanced use the same priority. Lower numbers are prioritized. Higher numbers can be used as backup servers.</p> <p>Recommended Settings:</p> Type Host Points to Priority TTL <code>MX</code> <code>@</code> <code>mail.your-domain</code> <code>0</code> <code>1 hour</code>"},{"location":"network/dns/dns-record-mailserver/#rdns-or-ptr-record","title":"RDNS or PTR Record","text":"<p>The reverse DNS record\u00a0or also called PTR\u00a0(Pointer Resource Record)\u00a0is important when you want to send mails. Almost all mail servers check the\u00a0RDNS record to perform simple anti-spam checks. RDNS is\u00a0just like a DNS query, just backward.</p> <p>Your RDNS record is not configured on your DNS server, instead,\u00a0it\u2019s\u00a0configured on your hosting provider where you got your public IP address from.</p>"},{"location":"network/dns/dns-record-mailserver/#optional-but-recommended-dns-records","title":"(Optional but recommended) DNS Records","text":""},{"location":"network/dns/dns-record-mailserver/#spf-record","title":"SPF Record","text":"<p>The SPF (Sender Policy Framework)\u00a0is a TXT record on your\u00a0DNS server that specifies\u00a0which hosts\u00a0are allowed to\u00a0send mails\u00a0for\u00a0a given domain.\u00a0When a mail server receives a mail\u00a0that seems to come\u00a0from your domain it can check\u00a0if\u00a0it\u2019s\u00a0a valid message. Some mail servers\u00a0reject mails\u00a0if they\u00a0can\u2019t\u00a0validate that the message comes from an authorized mail server.</p> <p>Recommended Settings:</p> Type Host TXT Value TTL <code>TXT</code> <code>@</code> <code>v=spf1 ip4:your-mail-servers-ipv4 -all</code> <code>1 hour</code>"},{"location":"network/dns/dns-record-mailserver/#dkim-record","title":"DKIM Record","text":"<p>DKIM (Domain Keys Identified Mail) allows the receiving mail server to check that an email was indeed sent by the owner of that domain. The sending mail server adds a digital signature to every mail that is sent. This signature is added as a header and secured with encryption. These signatures are not visible to the end-user.</p> <p>If you want to add DKIM to your mail\u00a0server\u00a0you first need to create\u00a0a\u00a0private and a public keypair</p> <p>We use the tool OpenSSL to generate a DKIM private and public keypair.</p> <pre><code>openssl genrsa -out dkim_private.pem 2048\nopenssl rsa -in dkim_private.pem -pubout -outform der 2&gt;/dev/null | openssl base64 -A\n</code></pre> <p>Recommended Settings:</p> Type Host TXT Value TTL <code>TXT</code> <code>dkim._domainkey</code> <code>v=DKIM1;k=rsa;p=public-dkim-key</code> <code>1 hour</code>"},{"location":"network/dns/dns-record-mailserver/#dmarc-record","title":"DMARC Record","text":"<p>DMARC\u00a0(Domain-based Message Authentication, Reporting,\u00a0and Conformance)\u00a0extends your existing SPF and DKIM\u00a0records.\u00a0It makes sure that\u00a0the sender's emails are protected by SPF and DKIM and tells the receiving mail server what to do if\u00a0these\u00a0checks\u00a0fail. \u00a0 Recommended Settings:</p> Type Host TXT Value TTL <code>TXT</code> <code>_dmarc</code> <code>v=DMARC1;p=quarantine</code> <code>1 hour</code>"},{"location":"network/dns/dns-record-mailserver/#optional-dns-records","title":"(Optional) DNS Records","text":""},{"location":"network/dns/dns-record-mailserver/#autoconfiguration-dns-records","title":"Autoconfiguration DNS Records","text":"<p>If\u00a0you\u2019re\u00a0using mail clients like Outlook, Thunderbird\u00a0on your Computer,\u00a0or Mobile devices they offer the ability to do an \u201cautoconfiguration\u201d\u00a0also called \u201cAutodiscover\u201d. That means you just need to enter your email address and password and the mail client tries to resolve the mail server\u00a0IP addresses, used ports, and encryption settings for IMAP and SMTP.\u00a0You can achieve this by\u00a0adding SRV DNS records that are defined in the\u00a0RFC 6186 standard\u00a0and some specific\u00a0records that are used in Outlook clients.</p>"},{"location":"network/dns/dns-record-types/","title":"DNS Record Types","text":""},{"location":"network/dns/dns-record-types/#dns-record-types","title":"DNS Record Types","text":"<p>TODO: WIP</p>"},{"location":"network/dns/dns-record-types/#most-common-types-of-dns-records","title":"Most common types of DNS Records","text":"Type Description A The record that holds the IP address of a domain. AAAA The record that contains the IPv6 address for a domain (as opposed to A records, which list the IPv4 address). CNAME Forwards one domain or subdomain to another domain, does NOT provide an IP address. MX Directs mail to an email server. TXT Lets an admin store text notes in the record. These records are often used for email security. NS Stores the name server for a DNS entry. SOA Stores admin information about a domain. SRV Specifies a port for specific services. PTR Provides a domain name in reverse-lookups."},{"location":"network/dns/dns-record-types/#less-commonly-used-dns-records","title":"Less commonly used DNS Records","text":"Type Description APL The \u2018address prefix list\u2019 is an experiment record that specifies lists of address ranges. AFSDB This record is used for clients of the Andrew File System (AFS) developed by Carnegie Melon. The AFSDB record functions to find other AFS cells. CAA This is the \u2018certification authority authorization\u2019 record, it allows domain owners state which certificate authorities can issue certificates for that domain. If no CAA record exists, then anyone can issue a certificate for the domain. These records are also inherited by subdomains. DNSKEY The \u2018DNS Key Record\u2019 contains a public key used to verify Domain Name System Security Extension (DNSSEC) signatures. CDNSKEY This is a child copy of the DNSKEY record, meant to be transferred to a parent. CERT The \u2018certificate record\u2019 stores public key certificates. DCHID The \u2018DHCP Identifier\u2019 stores info for the Dynamic Host Configuration Protocol (DHCP), a standardized network protocol used on IP networks. DNAME The \u2018delegation name\u2019 record creates a domain alias, just like CNAME, but this alias will redirect all subdomains as well. For instance if the owner of \u2018example.com\u2019 bought the domain \u2018website.net\u2019 and gave it a DNAME record that points to \u2018example.com\u2019, then that pointer would also extend to \u2018blog.website.net\u2019 and any other subdomains. HIP This record uses \u2018Host identity protocol\u2019, a way to separate the roles of an IP address; this record is used most often in mobile computing. IPSECKEY The \u2018IPSEC key\u2019 record works with the Internet Protocol Security (IPSEC), an end-to-end security protocol framework and part of the Internet Protocol Suite (TCP/IP). LOC The \u2018location\u2019 record contains geographical information for a domain in the form of longitude and latitude coordinates. NAPTR The \u2018name authority pointer\u2019 record can be combined with an SRV record to dynamically create URI\u2019s to point to based on a regular expression. NSEC The \u2018next secure record\u2019 is part of DNSSEC, and it\u2019s used to prove that a requested DNS resource record does not exist. RRSIG The \u2018resource record signature\u2019 is a record to store digital signatures used to authenticate records in accordance with DNSSEC. RP This is the \u2018responsible person\u2019 record and it stores the email address of the person responsible for the domain. SSHFP This record stores the \u2018SSH public key fingerprints\u2019; SSH stands for Secure Shell and it\u2019s a cryptographic networking protocol for secure communication over an unsecure network."},{"location":"network/dns/dns/","title":"DNS","text":""},{"location":"network/dns/dns/#dns","title":"DNS","text":"<p>TODO: WIP</p>"},{"location":"network/dns/dns/#dns-encryption","title":"DNS Encryption","text":"<p>Ever since DNS was created in 1987, it has been largely unencrypted. Everyone between your device and the resolver is able to snoop on or even modify your DNS queries and responses.</p> <p>The UDP source port is 53 which is the standard port number for unencrypted DNS. The UDP payload is therefore likely to be a DNS answer.</p> <p>Encrypting DNS makes it much harder for snoopers to look into your DNS messages, or to corrupt them in transit.</p> <p>Two standardized mechanisms exist to secure the DNS transport between you and the resolver, DNS over TLS, and DNS queries over HTTPS.</p> <p>Both are based on Transport Layer Security (TLS) which is also used to secure communication between you and a website using HTTPS.</p> <p>As both DoT and DoH are relatively new, they are not universally deployed yet.</p>"},{"location":"network/dns/dns/#dns-over-https","title":"DNS over HTTPS","text":"<p>DNS over HTTPS, or DoH, is an alternative to DoT. With DoH, DNS queries and responses are encrypted, but they are sent via the HTTP or HTTP/2 protocols instead of directly over UDP.</p> <p>Like DoT, DoH ensures that attackers can't forge or alter DNS traffic. DoH traffic looks like other HTTPS traffic \u2013 e.g. normal user-driven interactions with websites and web apps \u2013 from a network administrator's perspective.</p> <pre><code>  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2500\u2500\u2510\n  \u2502 \ufa9e HTTP Protocol \u2502   \u2502 \uf023 encrypted\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u251c\u2500\u2500 traffic\n  \u2502 \uf80a TLS Protocol  \u2502   \u2502   via HTTPS\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2500\u2500\u2518\n  \u2502   TCP Protocol  \u2502\n  \u2502   (Port 443)    \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502   IP Protocol   \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  GET/POST\n  url/dns-request?dns-...\n</code></pre>"},{"location":"network/dns/dns/#dns-over-tls","title":"DNS over TLS","text":"<p>DNS over TLS, or DoT, is a standard for encrypting DNS queries to keep them secure and private. DoT uses the same security protocol, TLS, that HTTPS websites use to encrypt and authenticate communications. (TLS is also known as \"SSL.\") DoT adds TLS encryption on top of the user datagram protocol (UDP), which is used for DNS queries.</p> <pre><code>  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2500\u2500\u2510\n  \u2502   DNS Protocol  \u2502   \u2502 \uf023 encrypted\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   \u251c\u2500\u2500 traffic\n  \u2502 \uf80a TLS Protocol  \u2502   \u2502   via TLS\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2500\u2500\u2518\n  \u2502   UDP Protocol  \u2502\n  \u2502   (Port 853)    \u2502\n  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n  \u2502   IP Protocol   \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"network/dns/local_dns/","title":"Local DNS","text":""},{"location":"network/dns/local_dns/#local-dns","title":"Local DNS","text":""},{"location":"network/dns/local_dns/#wat-is-local-dns","title":"Wat is local DNS?","text":"<p>Local DNS is een systeem dat een domeinnaam zoals example.com vertaalt naar het numerieke IP-adres van de server waar de inhoud zich bevindt. Wanneer je een netwerkverzoek doet met een domeinnaam, zal je systeem een DNS-zoekopdracht uitvoeren om het serveradres te bepalen waarmee het contact moet opnemen. Dit voegt een extra vertraging toe aan elk verzoek dat je doet.</p> <p>Je kunt je eigen DNS-server draaien om meer controle te hebben over je netwerk. Een veelvoorkomende reden is dat je netwerk-niveau domeinmappings kunt configureren, zoals web-server naar <code>192.168.0.101</code>. Door je router zo in te stellen dat hij je DNS gebruikt, kun je met elk van je verbonden apparaten toegang krijgen tot <code>192.168.0.101</code> via <code>http://web-server.example.com</code></p>"},{"location":"network/dns/local_dns/#hoe-local-dns-opzetten","title":"Hoe Local DNS opzetten","text":"<p>Dit is heel simpel op te zetten door middel van volgende tools:</p> <ul> <li>PiHole</li> <li>PfSense</li> <li>Unifi</li> <li>Windows server</li> <li>andere dns software</li> </ul>"},{"location":"network/dns/local_dns/#praktische-voorbeelden","title":"Praktische voorbeelden","text":"<p><code>tower.lan</code> -&gt; <code>172.16.0.5</code></p> <p><code>router1.lan</code> -&gt; <code>192.168.1.11</code></p>"},{"location":"network/dns/local_dns/#pihole","title":"PiHole","text":"<p>Hier heb ik een voorbeeld van hoe je dit configureerd in PiHole. </p>"},{"location":"network/dns/local_dns/#suffix","title":"Suffix","text":""},{"location":"network/dns/local_dns/#wat-is-een-dns-suffix","title":"Wat is een DNS Suffix?","text":"<p>Een DNS-Suffix is het eerste deel van een domeinnaam, zoals <code>example.com</code>. Het wordt gebruikt om een domein te identificeren en te onderscheiden van andere domeinen.</p> <p>Geef in een command prompt volgende in:</p> <pre><code>ipconfig /all\n</code></pre> <p></p> <p>Je zult zien dat bij iedere netwerkadapter (wifi, eth, vpn,...) er <code>Connection-specific DNS Suffix</code> zal staan.</p> <p>In dit voorbeeld staat hier <code>lan</code>. Dat wil zeggen dat ik dus met mijn browser kan navigeren naar <code>tower\\</code>, die uitkomt op mijn server, genaamd <code>tower</code>. Je moet je geen zorgen maken over de poorten, want elke service zal automatisch volgende poorten aanspreken:</p> <ul> <li>RDP: <code>3389</code></li> <li>ssh: <code>22</code></li> <li>http: <code>80</code></li> <li>minecraft: <code>25565</code></li> </ul> <p>Note</p> <p>Bovenstaande stapppen houden geen rekening met custom poorten voor een service. Dit kan je wel op andere manieren oplossen.(comming soon).</p> <p>Je kan meer dan 1 suffix statisch instellen of meegeven met je DHCP release. Als je dit in Wireshark zou capturen zal je zien dat hij achter <code>tower</code> alle suffixen gaat plakken en dat over het netwerk naar de local dns server zal sturen. Dit kan je capturen volgens deze methode:</p> <p></p> <p></p>"},{"location":"network/dns/local_dns/#local-dns-met-custom-poorten","title":"Local DNS met custom poorten","text":"<p>In ons voorbeeld gebruiken we Traefik. Als je de configuratie van deze pagina gedaan hebt is het maar een kleine uitbreiding.</p>"},{"location":"network/dns/local_dns/#configuratie-pihole","title":"configuratie Pihole","text":"<p>Wij gebruiken Pihole maar dit kan met elke DNS software.</p> <p>Er zijn 2 manieren maar die komen op het zelfde neer. Ofwel gebruik je jouw real domain. ofwel gebruik je .local, .lan, etc. Deze kan je ook vermelden in de Labels.</p> <p>In pihole ga je naar Local DNS \u2192 DNS/CNAME Record. Bij A record vul je een url in die verwijst naar je traefik met het IP van traefik uiteraard. Bij CNAME vul je in wat je wilt intyppen als url die doorverwijst naar de URL van traefik.  </p> <p>Tip</p> <p>Wat er exact gebeurd is wanneer jij in je browser cloud.cowadar.be zou intyppen dan word eerst het verkeer naar Pihole gestuurd. Pihole zegt aah ik heb een CNAME met de naam \"cloud.cowadar.be\" die vervolgens ziet dat dit word dooverwezen naar \"rpi5.cowdar.be\". deze gaat dan op zijn beurt \"rpi5.cowadat.be\" resolven en ziet in zijn eigen database dat dit verwijst naar 172.16.0.50. Het verkeer word nu naar jouw traefik gestuurd. Nu is het aan Treafik om met het verkeer om te gaan.</p> <p>Warning</p> <p>als je met je real domain heb gewerkt zal de URL waarsschijnlijk bestaan. Is de url niet aanwezig zal je deze handmatig moeten toevoegen in de config file van Traefik. Of mee in de labels zetten.</p>"},{"location":"network/dns/local_dns/#coming-soon","title":"Coming Soon","text":"<p>Note</p> <p>dns via Unifi + custom domain + fallback dns WAN</p>"},{"location":"network/dns/npm/","title":"Nginx Proxy Manager (NPM)","text":""},{"location":"network/dns/npm/#nginx-proxy-manager-npm","title":"Nginx Proxy Manager (NPM)","text":"<p>Nginx Proxy Manager is een applicatie die je kunt gebruiken om eenvoudig en veilig je webdiensten op je netwerk bloot te stellen. Het maakt gebruik van Nginx als een reverse proxy om verkeer te routeren naar je interne webserver. Het biedt ook gratis SSL-certificaten met Let's Encrypt en een mooie webinterface om je virtuele hosts te beheren.</p> <p>Om Nginx Proxy Manager te installeren, heb je Docker en Docker Compose nodig. Je kunt een YAML-bestand maken met de configuratie voor de Nginx Proxy Manager container en deze uitvoeren met docker-compose. Daarna kun je inloggen op de admin panel op poort <code>81</code> en je webdiensten toevoegen als proxy hosts.</p> <p></p>"},{"location":"network/dns/npm/#vergelijking-met-traefik","title":"Vergelijking met Traefik","text":"Kenmerk Traefik Nginx Proxy Manager Webinterface Ja, maar alleen voor monitoring en statistieken Ja, voor het beheren en configureren van proxy hosts, SSL-certificaten en gebruikers Automatische SSL-certificaten met Let's Encrypt Ja, met DNS-uitdaging of HTTP-uitdaging Ja, met HTTP-uitdaging Ondersteuning voor meerdere gebruikers Nee Ja, met verschillende toegangsniveaus Configuratie via labels Ja, voor docker containers Nee Configuratie via bestanden Ja, met YAML of TOML Nee Ondersteuning voor OAuth Ja, met externe providers zoals Google of Github Nee Dynamische routering Ja, met service discovery en load balancing Nee Ondersteuning voor Kubernetes Ja, met een ingebouwde controller Nee"},{"location":"network/dns/pihole/","title":"Pihole","text":""},{"location":"network/dns/pihole/#pihole","title":"Pihole","text":""},{"location":"network/dns/pihole/#setting-up-pi-hole-as-a-recursive-dns-server-solution","title":"Setting up Pi-hole as a recursive DNS server solution","text":"<p>We will use <code>unbound</code>, a secure open-source recursive DNS server primarily developed by NLnet Labs, VeriSign Inc., Nominet, and Kirei. The first thing you need to do is to install the recursive DNS resolver:</p> <pre><code>sudo apt install unbound\n</code></pre> <p>If you are installing unbound from a package manager, it should install the <code>root.hints</code> file automatically with the dependency <code>dns-root-data</code>. The root hints will then be automatically updated by your package manager.</p> <p>Optional: Download the current root hints file (the list of primary root servers which are serving the domain \".\" - the root domain). Update it roughly every six months. Note that this file changes infrequently. This is only necessary if you are not installing unbound from a package manager. If you do this optional step, you will need to uncomment the <code>root-hints:</code> configuration line in the suggested config file.</p> <pre><code>wget https://www.internic.net/domain/named.root -qO- | sudo tee /var/lib/unbound/root.hints\n</code></pre>"},{"location":"network/dns/pihole/#configure-unbound","title":"Configure <code>unbound</code>","text":"<p>Highlights:</p> <ul> <li>Listen only for queries from the local Pi-hole installation (on port 5335)</li> <li>Listen for both UDP and TCP requests</li> <li>Verify DNSSEC signatures, discarding BOGUS domains</li> <li>Apply a few security and privacy tricks</li> </ul> <p><code>/etc/unbound/unbound.conf.d/pi-hole.conf</code>:</p> <pre><code>server:\n    # If no logfile is specified, syslog is used\n    # logfile: \"/var/log/unbound/unbound.log\"\n    verbosity: 0\n\n    interface: 127.0.0.1\n    port: 5335\n    do-ip4: yes\n    do-udp: yes\n    do-tcp: yes\n\n    # May be set to yes if you have IPv6 connectivity\n    do-ip6: no\n\n    # You want to leave this to no unless you have *native* IPv6. With 6to4 and\n    # Terredo tunnels your web browser should favor IPv4 for the same reasons\n    prefer-ip6: no\n\n    # Use this only when you downloaded the list of primary root servers!\n    # If you use the default dns-root-data package, unbound will find it automatically\n    #root-hints: \"/var/lib/unbound/root.hints\"\n\n    # Trust glue only if it is within the server's authority\n    harden-glue: yes\n\n    # Require DNSSEC data for trust-anchored zones, if such data is absent, the zone becomes BOGUS\n    harden-dnssec-stripped: yes\n\n    # Don't use Capitalization randomization as it known to cause DNSSEC issues sometimes\n    # see https://discourse.pi-hole.net/t/unbound-stubby-or-dnscrypt-proxy/9378 for further details\n    use-caps-for-id: no\n\n    # Reduce EDNS reassembly buffer size.\n    # IP fragmentation is unreliable on the Internet today, and can cause\n    # transmission failures when large DNS messages are sent via UDP. Even\n    # when fragmentation does work, it may not be secure; it is theoretically\n    # possible to spoof parts of a fragmented DNS message, without easy\n    # detection at the receiving end. Recently, there was an excellent study\n    # &gt;&gt;&gt; Defragmenting DNS - Determining the optimal maximum UDP response size for DNS &lt;&lt;&lt;\n    # by Axel Koolhaas, and Tjeerd Slokker (https://indico.dns-oarc.net/event/36/contributions/776/)\n    # in collaboration with NLnet Labs explored DNS using real world data from the\n    # the RIPE Atlas probes and the researchers suggested different values for\n    # IPv4 and IPv6 and in different scenarios. They advise that servers should\n    # be configured to limit DNS messages sent over UDP to a size that will not\n    # trigger fragmentation on typical network links. DNS servers can switch\n    # from UDP to TCP when a DNS response is too big to fit in this limited\n    # buffer size. This value has also been suggested in DNS Flag Day 2020.\n    edns-buffer-size: 1232\n\n    # Perform prefetching of close to expired message cache entries\n    # This only applies to domains that have been frequently queried\n    prefetch: yes\n\n    # One thread should be sufficient, can be increased on beefy machines. In reality for most users running on small networks or on a single machine, it should be unnecessary to seek performance enhancement by increasing num-threads above 1.\n    num-threads: 1\n\n    # Ensure kernel buffer is large enough to not lose messages in traffic spikes\n    so-rcvbuf: 1m\n\n    # Ensure privacy of local IP ranges\n    private-address: 192.168.0.0/16\n    private-address: 169.254.0.0/16\n    private-address: 172.16.0.0/12\n    private-address: 10.0.0.0/8\n    private-address: fd00::/8\n    private-address: fe80::/10\n</code></pre> <p>Start your local recursive server and test that it's operational:</p> <pre><code>sudo service unbound restart\ndig pi-hole.net @127.0.0.1 -p 5335\n</code></pre> <p>Warning</p> <p>Note that you first have to install dnsutils (sudo apt install dnsutils) if dig command is not found</p> <p>The first query may be quite slow, but subsequent queries, also to other domains under the same TLD, should be fairly quick.</p> <p>You should also consider adding</p> <pre><code>edns-packet-max=1232\n</code></pre> <p>to a config file like <code>/etc/dnsmasq.d/99-edns.conf</code> to signal FTL to adhere to this limit.</p>"},{"location":"network/dns/pihole/#test-validation","title":"Test validation\u00b6","text":"<p>You can test DNSSEC validation using</p> <pre><code>dig fail01.dnssec.works @127.0.0.1 -p 5335\ndig dnssec.works @127.0.0.1 -p 5335\n</code></pre> <p>The first command should give a status report of <code>SERVFAIL</code> and no IP address. The second should give <code>NOERROR</code> plus an IP address.</p>"},{"location":"network/dns/pihole/#configure-pi-hole","title":"Configure Pi-hole","text":"<p>Finally, configure Pi-hole to use your recursive DNS server by specifying <code>127.0.0.1#5335</code> as the Custom DNS (IPv4):</p> <p></p> <p>(don't forget to hit Return or click on <code>Save</code>)</p>"},{"location":"network/dns/pihole/#web-password-terugvinden","title":"Web password terugvinden","text":"<pre><code>cat /etc/pihole/setupVars.conf |grep WEBPASSWORD\n</code></pre>"},{"location":"network/dns/traefik/","title":"Treafik","text":""},{"location":"network/dns/traefik/#treafik","title":"Treafik","text":""},{"location":"network/dns/traefik/#certificaten-voor-meerdere-domeinen-in-traefik","title":"Certificaten voor meerdere domeinen in Traefik","text":"<p>Zie https://doc.traefik.io/traefik/routing/routers/#certresolver</p>"},{"location":"network/dns/traefik/#treafik_1","title":"Treafik","text":"<p>Traefik is een reverse proxy. Dit wil zeggen dat je heel gemakkelijk verschillende services kunt bereiken vanaf het internet zonder elke keer een port open te zetten. De enigeste poort die je moet openzetten is 443. En verwijzen naar het toest (IP) waar Traefik op draait.</p> <p>In dit voorbeeld gebruiken we een firewall van het met Unifi. Dit kan je ook perfect in de router(modem) van uw provider doen. </p> <p>Bij je DNS provider verwijs je een A record door naar je Publiek IP (dit kan ook automatisch gebeuren door DDNS). Voor alle services gebruik je een CNAME record die verwijst naar @ (@ = jouw domein).  </p>"},{"location":"network/dns/traefik/#installatie-bestanden","title":"Installatie bestanden","text":"<p>Als je dat eenmaal gedaan hebt kan je beginnen aan de configuratie van Traefik.</p> <p>Info</p> <p>Onze Traefik gebruikt een dynamische file. Dat wilt zeggen dat je als je de configuratie aanpast dat je niet elke keer de docker opnieuw moet genereren.</p> <p>Info</p> <p>Graag volgens volgende map structuur maken.</p> <pre><code>docker\n  \u251c\u2500\u2500 appdata\n  \u2502     \u251c\u2500\u2500 acme\n  \u2502     \u2502   \u2514\u2500\u2500 acme.json\n  \u2502     \u251c\u2500\u2500 logs\n  \u2502     \u2502   \u251c\u2500\u2500 access.log\n  \u2502     \u2502   \u2514\u2500\u2500 traefik.log\n  \u2502     \u2514\u2500\u2500 rules\n  \u2502         \u251c\u2500\u2500 app-name.yml\n  \u2502         \u251c\u2500\u2500 chain-basic-auth.yml\n  \u2502         \u251c\u2500\u2500 chain-no-auth.yml\n  \u2502         \u251c\u2500\u2500 middlewares-basic-auth.yml\n  \u2502         \u251c\u2500\u2500 middlewares-buffering.yml\n  \u2502         \u251c\u2500\u2500 middlewares-crowdsec.yml\n  \u2502         \u251c\u2500\u2500 middlewares-headers.yml\n  \u2502         \u251c\u2500\u2500 middlewares-rate-limit.yml\n  \u2502         \u251c\u2500\u2500 middlewares-secure-headers.yml\n  \u2502         \u251c\u2500\u2500 middlewares-websocket.yml\n  \u2502         \u2514\u2500\u2500 tls-opts.yml\n  \u2514\u2500\u2500docker-compose\n        \u251c\u2500\u2500 secrets\n        \u2502   \u251c\u2500\u2500 basic_auth_credentials\n        \u2502   \u2514\u2500\u2500 cf_dns_api_token\n\n        \u251c\u2500\u2500 compose.yml\n        \u2514\u2500\u2500env\n</code></pre> Configuratie bestanden <p>Warning</p> <p>Vergeet niet alle gegevens naar die van jou te veranderen!!</p> compose.yamlcf_dns_api_token.envbasic_auth_credentialsacme.jsonapp-name.ymlchain-basic-auth.ymlchain-no-auth.ymlmiddlewares-basic-auth.ymlmiddlewares-buffering.ymlmiddlewares-crowdsec.ymlmiddlewares-headers.ymlmiddlewares-rate-limit.ymlmiddlewares-secure-headers.ymlmiddlewares-websocket.ymltls-opts.yml <pre><code>services:\n  # Traefik 3 - Reverse Proxy\n  traefik:\n    container_name: traefik\n    image: traefik:latest\n    security_opt:\n      - no-new-privileges:true\n    restart: unless-stopped\n    # depends_on:\n    #   - socket-proxy\n    networks:\n      - socket_proxy\n      #- swarm-traefik\n    command: # CLI arguments\n      - --global.checkNewVersion=true\n      - --global.sendAnonymousUsage=false\n      - --entrypoints.web-external.address=:80\n      - --entrypoints.web-internal.address=:81\n      - --entrypoints.websecure-external.address=:444\n      - --entrypoints.websecure-internal.address=:443\n      # - --entrypoints.traefik.address=:8080\n      - --entrypoints.web-external.http.redirections.entrypoint.to=websecure-external\n      - --entrypoints.web-external.http.redirections.entrypoint.scheme=https\n      - --entrypoints.web-external.http.redirections.entrypoint.permanent=true\n      - --entrypoints.web-internal.http.redirections.entrypoint.to=websecure-internal\n      - --entrypoints.web-internal.http.redirections.entrypoint.scheme=https\n      - --entrypoints.web-internal.http.redirections.entrypoint.permanent=true\n      - --api=true\n      - --api.dashboard=true\n      # - --api.insecure=true\n      # - --serversTransport.insecureSkipVerify=true\n      # Allow these IPs to set the X-Forwarded-* headers - Cloudflare IPs: https://www.cloudflare.com/ips/\n      - --entrypoints.websecure-external.forwardedHeaders.trustedIPs=$CLOUDFLARE_IPS,$LOCAL_IPS\n      - --entrypoints.websecure-internal.forwardedHeaders.trustedIPs=$CLOUDFLARE_IPS,$LOCAL_IPS\n      - --log=true\n      - --log.filePath=/logs/traefik.log\n      - --log.level=INFO # (Default: error) DEBUG, INFO, WARN, ERROR, FATAL, PANIC\n      - --accessLog=true\n      - --accessLog.filePath=/logs/access.log\n      - --accessLog.bufferingSize=100 # Configuring a buffer of 100 lines\n      - --accessLog.filters.statusCodes=204-299,400-499,500-599\n      - --providers.docker=true\n      # --providers.docker.endpoint=unix:///var/run/docker.sock # Disable for Socket Proxy. Enable otherwise.\n      - --providers.docker.endpoint=tcp://socket-proxy:2375 # Enable for Socket Proxy. Disable otherwise.\n      - --providers.docker.exposedByDefault=false\n      - --providers.docker.network=t3_proxy\n      # - --providers.docker.swarmMode=true # Traefik v2 Swarm\n      # - --providers.swarm.endpoint=tcp://127.0.0.1:2377 # Traefik v3 Swarm\n      - --entrypoints.websecure-external.http.tls=true\n      - --entrypoints.websecure-external.http.tls.options=tls-opts@file\n      - --entrypoints.websecure-internal.http.tls=true\n      - --entrypoints.websecure-internal.http.tls.options=tls-opts@file\n      # Add dns-cloudflare as default certresolver for all services. Also enables TLS and no need to specify on individual services\n      - --entrypoints.websecure-external.http.tls.certresolver=dns-cloudflare\n      - --entrypoints.websecure-external.http.tls.domains[0].main=$DOMAINNAME_1\n      - --entrypoints.websecure-external.http.tls.domains[0].sans=*.$DOMAINNAME_1\n      - --entrypoints.websecure-internal.http.tls.certresolver=dns-cloudflare\n      - --entrypoints.websecure-internal.http.tls.domains[1].main=$DOMAINNAME_2\n      - --entrypoints.websecure-internal.http.tls.domains[1].sans=*.$DOMAINNAME_2\n      # - DOMAINS-PLACEHOLDER-DO-NOT-DELETE\n      - --providers.file.directory=/rules # Load dynamic configuration from one or more .toml or .yml files in a directory\n      - --providers.file.watch=true # Only works on top level files in the rules folder\n      # - --certificatesResolvers.dns-cloudflare.acme.caServer=https://acme-staging-v02.api.letsencrypt.org/directory # LetsEncrypt Staging Server - uncomment when testing\n      - --certificatesResolvers.dns-cloudflare.acme.storage=/acme.json\n      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.provider=cloudflare\n      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.resolvers=1.1.1.1:53,1.0.0.1:53\n      - --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.delayBeforeCheck=120 # To delay DNS check and reduce LE hitrate\n      #- --certificatesResolvers.dns-cloudflare.acme.dnsChallenge.disablePropagationCheck=true\n      # - METRICS-PLACEHOLDER-DO-NOT-DELETE\n    ports:\n      - \"80:80\"\n      - \"81:81\"\n      - \"443:443\"\n      - \"444:444\"\n      # - \"8080:8080\"\n    volumes:\n      - $APPDATADIR/traefik/rules:/rules\n      # - /var/run/docker.sock:/var/run/docker.sock:ro # Use Docker Socket Proxy instead for improved security\n      - $APPDATADIR/traefik/acme/acme.json:/acme.json\n      - $LOGDIR/traefik:/logs\n    environment:\n      - TZ=$TZ\n      - CF_DNS_API_TOKEN_FILE=/run/secrets/cf_dns_api_token\n      - HTPASSWD_FILE=/run/secrets/basic_auth_credentials # HTTP Basic Auth Credentials\n      - DOMAINNAME_1 # Passing the domain name to traefik container to be able to use the variable in rules.\n      - DOMAINNAME_2\n      # - TRAEFIK_AUTH_BYPASS_KEY\n    secrets:\n      - cf_dns_api_token\n      - basic_auth_credentials\n    labels:\n      - \"traefik.enable=true\"\n      # HTTP Routers\n      - \"traefik.http.routers.traefik-rtr.entrypoints=websecure-internal,websecure-external\"\n      - \"traefik.http.routers.traefik-rtr.rule=Host(`traefik-dashboard.$DOMAINNAME_1`)\"\n      # Services - API\n      - \"traefik.http.routers.traefik-rtr.service=api@internal\"\n      # Middlewares\n      - \"traefik.http.routers.traefik-rtr.middlewares=chain-basic-auth@file\" # For Basic HTTP Authentication\n\n  # Traefik Error Log (traefik.log) for Dozzle\n  traefik-error-log:\n    container_name: traefik-error-log\n    image: alpine\n    volumes:\n      - $LOGDIR/traefik/traefik.log:/var/log/stream.log\n    command:\n      - tail\n      - -f\n      - /var/log/stream.log\n    network_mode: none\n    restart: unless-stopped\n\n  # Traefik Access Log (access.log) for Dozzle\n  traefik-access-log:\n    container_name: traefik-access-log\n    image: alpine\n    volumes:\n      - $LOGDIR/traefik/access.log:/var/log/stream.log\n    command:\n      - tail\n      - -f\n      - /var/log/stream.log\n    network_mode: none\n    restart: unless-stopped\n\n  # Traefik Certs Dumper - Extract LetsEncrypt Certificates - Traefik2 Compatible\n  traefik-certs-dumper:\n    container_name: traefik-certs-dumper\n    image: humenius/traefik-certs-dumper:latest\n    security_opt:\n      - no-new-privileges:true\n    restart: unless-stopped\n    network_mode: none\n    # command: --restart-containers container1,container2,container3\n    volumes:\n      - $APPDATADIR/traefik/acme:/traefik:ro\n      - $APPDATADIR/traefik-certs/$DOMAINNAME_1:/output:rw\n      # - /var/run/docker.sock:/var/run/docker.sock:ro # Only needed if restarting containers (use Docker Socket Proxy instead)\n    environment:\n      DOMAIN: $DOMAINNAME_1\n\n  # Cloudflare Companion\n  cloudflare-companion:\n    image: tiredofit/traefik-cloudflare-companion\n    container_name: cloudflare-companion\n    volumes:\n      - $LOGDIR:/logs\n      # - /var/run/docker.sock:/var/run/docker.sock\n    secrets:\n      - cf_dns_api_token\n    environment:\n      - TIMEZONE=$TZ\n      - LOG_TYPE=BOTH\n      - LOG_LEVEL=INFO\n      - TRAEFIK_VERSION=2\n      - CF_EMAIL=$CF_EMAIL\n      - CF_TOKEN=$CF_GLOBAL_TOKEN\n      - RC_TYPE=CNAME\n      - DOMAIN1_PROXIED=TRUE\n      - TARGET_DOMAIN=$DOMAINNAME_1\n      - DOMAIN1=$DOMAINNAME_1\n      - DOMAIN1_ZONE_ID=$DOMAIN1_ZONE_ID\n      - DOCKER_HOST=tcp://socket-proxy:2375 \n      - REFRESH_ENTRIES=TRUE\n      #- DOCKER_CERT_PATH=/docker-certs\n      #- DOCKER_TLS_VERIFY=1\n      - TRAEFIK_FILTER_LABEL=traefik.constraint\n      - TRAEFIK_FILTER=proxy-public\n    # depends_on:\n    #   - socket-proxy\n    networks:\n      - socket_proxy\n    restart: always\n    # labels:\n      # Add hosts specified in rules here to force cf-companion to create the CNAMEs\n      # Since cf-companion creates CNAMEs based on host rules, this a workaround for non-docker/external apps\n      # - \"traefik.http.routers.cf-companion-rtr.rule=HostHeader(`vault.$DOMAINNAME_1`) || HostHeader(`ha.$DOMAINNAME_1`) || HostHeader(`overseerr.$DOMAINNAME_1`) || HostHeader(`nas.$DOMAINNAME_1`) || HostHeader(`todo.$DOMAINNAME_1`) || HostHeader(`auth.$DOMAINNAME_1`)\"\n      # - traefik.http.routers.example.rule=Host(`ha.$DOMAINNAME_1`) || Host(`overseerr.$DOMAINNAME_1`)\n\nnetworks:\n  socket_proxy:\n    external: true\n  swarm-traefik:\n    external: true\n\nsecrets:\n  cf_dns_api_token:\n    file: $SECRETDIR/cf_dns_api_token\n  basic_auth_credentials:\n    file: $SECRETDIR/basic_auth_credentials\n</code></pre> <pre><code># API token Cloudflare\n# Cloudflare --&gt; Right above user --&gt; Appearance --&gt; API tokens --&gt; Create token\n# Kies 1 of meer domeinen\n# Plain tekst hieronder\n</code></pre> <p></p> <pre><code>###### Cloudflare\nCF_EMAIL=&lt;cloudflare-email&gt;\nDOMAIN1_ZONE_ID=&lt;zone-id&gt;\nCF_GLOBAL_TOKEN=&lt;global-token&gt;\n\n###### Domein namen\nDOMAINNAME_1=example.com\nDOMAINNAME_2=example.local\n\n###### Directory paden\nAPPDATADIR=/path/to/appdata\nLOGDIR=/path/to/logs\nSECRETDIR=/path/to/secrets\n\n###### Timezone\nTZ=Europe/Brussels\n\n###### IP's\nCLOUDFLARE_IPS=173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22,141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20,197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/13,104.24.0.0/14,172.64.0.0/13,131.0.72.0/22\nLOCAL_IPS=127.0.0.1/32,10.0.0.0/8,192.168.0.0/16,172.16.0.0/12\n</code></pre> <p>Warning</p> <p>Declaring the user list</p> <p>Note: when used in docker-compose.yml all dollar signs in the hash need to be doubled for escaping. To create a user:password pair, the following command can be used: </p><pre><code>echo $(htpasswd -nb user password) | sed -e s/\\\\$/\\\\$\\\\$/g\n</code></pre> <p>Also note that dollar signs should NOT be doubled when they not evaluated (e.g. Ansible docker_container module).</p> <pre><code># Voorbeeld credentials - VERVANG DEZE!\nadmin:$$2y$$05$$8eA6bz6E7J/ChsRFuD8njeW45yfJutYYb4HxwgUir3HP4EsggP/QNo0.\n</code></pre> <p>Warning</p> <p>Deze file laat je leeg, deze wordt automatisch aangevuld door Traefik. sudo chmod 755 acme.json</p> <p>Zorg ervoor dat de permissies correct zijn: </p><pre><code>touch acme.json\nchmod 600 acme.json\n</code></pre> <p>Warning</p> <p>Pas de gegevens aan voor jouw applicatie!</p> <pre><code>http:\n  routers:\n    &lt;APP&gt;-rtr:\n      rule: \"Host(`&lt;APP&gt;.{{env \"DOMAINNAME_1\"}}`)\"\n      entryPoints:\n        - websecure-external\n        - websecure-internal\n      middlewares:\n        - chain-no-auth\n      service: &lt;APP&gt;-svc\n      tls:\n        certResolver: dns-cloudflare\n        options: tls-opts@file\n\n  services:\n    &lt;APP&gt;-svc:\n      loadBalancer:\n        servers:\n          - url: \"http://&lt;ip:port&gt;\" # Bijvoorbeeld: http://192.168.1.100:8080\n</code></pre> <pre><code>http:\n  middlewares:\n    chain-basic-auth:\n      chain:\n        middlewares:\n          - middlewares-rate-limit\n          - middlewares-secure-headers\n          # - crowdsec-bouncer\n          - middlewares-basic-auth\n          # - middlewares-compress\n</code></pre> <pre><code>http:\n  middlewares:\n    chain-no-auth:\n      chain:\n        middlewares:\n          - middlewares-rate-limit\n          - middlewares-secure-headers\n          # - crowdsec-bouncer\n          # - middlewares-compress\n</code></pre> <pre><code>http:\n  middlewares:\n    middlewares-basic-auth:\n      basicAuth:\n        # users:\n        #   - \"user:$apsdfswWvC/6.$E3FtsfTntPC0wVJ7IUVtX1\"\n        usersFile: \"/run/secrets/basic_auth_credentials\" \n        realm: \"Traefik Basic Auth\"\n</code></pre> <pre><code>http:\n  middlewares:\n    middlewares-buffering:\n      buffering:\n        maxResponseBodyBytes: 2000000\n        maxRequestBodyBytes: 10485760  \n        memRequestBodyBytes: 2097152  \n        memResponseBodyBytes: 2097152\n        retryExpression: \"IsNetworkError() &amp;&amp; Attempts() &lt;= 2\"\n</code></pre> <pre><code>http:\n  middlewares:\n    crowdsec-bouncer:\n      forwardauth:\n        address: http://crowdsec-traefik-bouncer:8080/api/v1/forwardAuth\n        trustForwardHeader: true\n</code></pre> <pre><code>http:\n  middlewares:\n    default-headers:\n      headers:\n        browserXssFilter: true\n        contentTypeNosniff: true\n        forceSTSHeader: true\n        stsIncludeSubdomains: true\n        stsPreload: true\n        stsSeconds: 31536000\n        customFrameOptionsValue: \"SAMEORIGIN\"\n</code></pre> <pre><code>http:\n  middlewares:\n    middlewares-rate-limit:\n      rateLimit:\n        average: 100\n        burst: 200\n</code></pre> <pre><code>http:\n  middlewares:\n    middlewares-secure-headers:\n      headers:\n        accessControlAllowMethods:\n          - GET\n          - OPTIONS\n          - PUT\n        accessControlMaxAge: 100\n        hostsProxyHeaders:\n          - \"X-Forwarded-Host\"\n        stsSeconds: 63072000\n        stsIncludeSubdomains: true\n        stsPreload: true\n        forceSTSHeader: true # This is a good thing but it can be tricky. Enable after everything works.\n        customFrameOptionsValue: SAMEORIGIN # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options\n        contentTypeNosniff: true\n        browserXssFilter: true\n        referrerPolicy: \"same-origin\"\n        permissionsPolicy: \"camera=(), microphone=(), geolocation=(), payment=(), usb=()\"\n        customResponseHeaders:\n          X-Robots-Tag: \"none,noindex,nofollow,noarchive,nosnippet,notranslate,noimageindex\" # disable search engines from indexing home server\n          server: \"\" # hide server info from visitors\n        customRequestHeaders:\n          X-Forwarded-Proto: https\n</code></pre> <pre><code>http:\n  middlewares:\n    sslheader:\n      headers:\n        customRequestHeaders:\n          X-Forwarded-Proto: \"https\"\n</code></pre> <pre><code>tls:\n  options:\n    tls-opts:\n      minVersion: VersionTLS12\n      cipherSuites:\n        - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\n        - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n        - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\n        - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n        - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305\n        - TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\n        - TLS_AES_128_GCM_SHA256\n        - TLS_AES_256_GCM_SHA384\n        - TLS_CHACHA20_POLY1305_SHA256\n        - TLS_FALLBACK_SCSV # Client is doing version fallback. See RFC 7507\n      curvePreferences:\n        - CurveP521\n        - CurveP384\n      sniStrict: true\n</code></pre>"},{"location":"network/dns/traefik/#run","title":"Run","text":"<p>Als je alle bovenstaande stappen gedaan hebt voer je het volgende commado in de terminal in dezelfde map als docker compose. </p><pre><code>docker compose up -d\n</code></pre> <p>Warning</p> <p>Check de acme.json deze zou ingevuld moeten worden en daar zie je de certificaten.</p>"},{"location":"network/dns/traefik/#configureer-traefikyaml","title":"Configureer traefik.yaml","text":"<p>Zoals eerder gezegt is deze file dynamisch. copy past de code voor elke (sub)domein.</p> traefik.yml edit <pre><code>routers:\n            sub:\n            entryPoints:\n                - \"https\"\n            rule: \"Host(`sub.domain.be`)\"\n            middlewares:                      # Desable This if you having troubles \n                - default-headers               # Learn more about Middlewares\n                - https-redirectscheme          #\n            tls: {}\n            service: sub\n\n            sub2:\n            entryPoints:\n                - \"https\"\n            rule: \"Host(`sub2.domain.be`)\"\n            middlewares:                       \n                - default-headers               \n                - https-redirectscheme          \n            tls: {}\n            service: sub2\n\n\n        #endregion\n        #region services\n        services:\n            sub:\n            loadBalancer:\n                servers:\n                - url: \"http://172.30.0.50:5042\"\n                passHostHeader: true\n\n            sub2:\n            loadBalancer:\n                servers:\n                - url: \"http://172.30.0.51:5042\"\n                passHostHeader: true\n</code></pre>"},{"location":"network/dns/traefik/#advanced","title":"Advanced","text":"<p>U Kunt ook traefik zijn configuratie automatisch laten verlopen door middel van labels op je docker containers te zetten. De configuratie bij uw DNS provider zal nog steeds handmatig moeten gebeuren.</p> Labels <pre><code>    labels:\n    # if you are not using traefik, comment out labels\n    - \"traefik.enable=true\"\n    - \"traefik.http.routers.portainer.entrypoints=http\"\n    - \"traefik.http.routers.portainer.rule=Host(`pihole.domain.be`)\"\n    - \"traefik.http.middlewares.portainer-https-redirect.redirectscheme.scheme=https\"\n    - \"traefik.http.routers.portainer.middlewares=portainer-https-redirect\"\n    - \"traefik.http.routers.portainer-secure.entrypoints=https\"\n    - \"traefik.http.routers.portainer-secure.rule=Host(`pihole.domain.be`)\"\n    - \"traefik.http.routers.portainer-secure.tls=true\"\n    - \"traefik.http.routers.portainer-secure.service=portainer\"\n    - \"traefik.http.services.portainer.loadbalancer.server.port=9000\"\n    - \"traefik.docker.network=proxy\"\n</code></pre>"},{"location":"network/dns/unbound/","title":"Unbound","text":""},{"location":"network/protocols/smtp/","title":"SMTP","text":""},{"location":"network/protocols/smtp/#smtp","title":"SMTP","text":"<p>SMTP is a networking protocol for mail transfer.</p>"},{"location":"network/protocols/smtp/#troubleshooting","title":"Troubleshooting","text":""},{"location":"network/protocols/smtp/#tls","title":"TLS","text":"<ol> <li>Prepare encoded strings for your mail username and password</li> </ol> <pre><code>echo -ne \"mail@example.net\" | base64\n</code></pre> <ol> <li>Connect to mail server</li> </ol> <pre><code>openssl s_client -starttls smtp -connect smtp.example.com:587\n</code></pre> <ol> <li>Send HELO</li> </ol> <pre><code>EHLO\n</code></pre> <ol> <li>Authenticate</li> </ol> <pre><code>AUTH LOGIN\n&lt;your-encoded-username&gt;\n&lt;your-encoded-password&gt;\n</code></pre> <p>If that's successful the mail server should return <code>235 2.7.0 Authentication successful</code>.</p>"},{"location":"network/protocols/tcp/","title":"TCP","text":""},{"location":"network/protocols/tls/","title":"TLS","text":""},{"location":"network/protocols/tls/#tls","title":"TLS","text":""},{"location":"network/protocols/tls/#tls-handshake","title":"TLS Handshake","text":"<p>In a TLS/SSL handshake, clients and servers exchange SSL certificates, cipher suite requirements, and randomly generated data for creating session keys.</p> <p>TLS handshakes are a foundational part of how HTTPS works.</p> <p>SSL, or Secure Sockets Layer, was the original encryption protocol developed for HTTP. SSL was replaced by TLS, or Transport Layer Security, some time ago. SSL handshakes are now called TLS handshakes, although the \"SSL\" name is still in wide use.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \uf007 Client  \u2502                \u2502 \ueb50 Server  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502                            \u2502\n      \u2502                            \u2502 \n      \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  \u2500\u2500\u2510\n      \u2502 1. SYN                     \u2502    \u2502\n      \u2502                            \u2502    \u2502\n      \u2502                            \u2502    \u2502 TCP\n      \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502    \u2502\n      \u2502 3. ACK          2. SYN ACK \u2502  \u2500\u2500\u2518\n      \u2502                            \u2502\n      \u2502 -------------------------- \u2502\n      \u2502                            \u2502\n      \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  \u2500\u2500\u2510\n      \u2502 4. ClientHello             \u2502    \u2502\n      \u2502                            \u2502    \u2502\n      \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502    \u2502\n      \u2502             5. ServerHello \u2502    \u2502\n      \u2502                Certificate \u2502    \u2502\n      \u2502            ServerHelloDone \u2502    \u2502\n      \u2502                            \u2502    \u2502 TLS\n      \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502    \u2502\n      \u2502 6. ClientKeyExchange       \u2502    \u2502\n      \u2502    ChangeCipherSpec        \u2502    \u2502\n      \u2502    Finished                \u2502    \u2502\n      \u2502                            \u2502    \u2502\n      \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502    \u2502\n      \u2502        7. ChangeCipherSpec \u2502    \u2502\n      \u2502           Finished         \u2502  \u2500\u2500\u2518\n</code></pre>"},{"location":"network/protocols/udp/","title":"UDP","text":""},{"location":"network/protocols/udp/#udp","title":"UDP","text":"<p>TODO: WIP</p>"},{"location":"network/router/pfsense/","title":"PFSense","text":""},{"location":"network/router/unifi/","title":"Unifi","text":""},{"location":"network/switch/cisco/","title":"Cisco","text":""},{"location":"network/switch/cisco/#cisco","title":"Cisco","text":"<p>Een Cisco switch is een netwerkapparaat dat wordt geproduceerd door het bedrijf Cisco. Een switch wordt gebruikt om meerdere apparaten in een netwerk met elkaar te verbinden en gegevens tussen deze apparaten te verzenden. Cisco produceert verschillende soorten switches, waaronder unmanaged switches, smart switches en managed switches, die elk verschillende functies en mogelijkheden bieden.</p>"},{"location":"network/switch/cisco/#tp-link-ap-config","title":"TP-link AP config","text":"<p>Door een access point gaan verschillende VLANs. waardoor je ook in de config deze moet megeven. Je hebt 2 manieren ofwel definjeer je welke VLANs <code>switchport trunk allow vlan x,x</code> of je laat dit weg en dan laat hij alle vlans door. De native vlan is de vlan waar de Accepoint zijn ip vandaan haalt.</p> <pre><code>switchport trunk native vlan 10\nswitchport mode trunk\nspanning-tree portfast\n</code></pre>"},{"location":"network/switch/d_link/","title":"D-link","text":"<p>Een D-Link switch is een netwerkapparaat dat wordt geproduceerd door het bedrijf D-Link. Een switch wordt gebruikt om meerdere apparaten in een netwerk met elkaar te verbinden en gegevens tussen deze apparaten te verzenden. D-Link produceert verschillende soorten switches, waaronder unmanaged switches, smart switches en managed switches, die elk verschillende functies en mogelijkheden bieden.</p>"},{"location":"network/switch/d_link/#dgs-1100-08","title":"DGS-1100-08","text":""},{"location":"network/switch/d_link/#connection","title":"Connection","text":"<p>Sluit je toestel aan op de switch. Ga daarna naar je ipv4 instellingen. Stel dan de volgende waardes in. IP address: 10.90.90.80, Subnet: 255.0.0.0, Default Gateway: 10.90.90.90; DNS: 8.8.8.8,8.8.4.4.</p> <p>Hierna ga je naar je webbrowser en geef je als URL: 10.90.90.90. Het standaard wachtwoord is <code>admin</code>.</p>"},{"location":"network/switch/d_link/#configuren","title":"Configuren","text":""},{"location":"network/switch/d_link/#change-management-ip-en-vlan","title":"Change management IP en VLAN","text":"<p>Meld aan op de switch met bovenstaande stappen. Als dat gelukt is geef je de switch zelf een static ip in de range van je computer.</p> <p>Note</p> <p>Als je een met trunks werkt zal dit het ip zijn van je native vlan.</p> <p>Warning</p> <p>Dit is mij nog niet gelukt op een vlan ID (Management Vlan). Hier op mijn Cisco switch staan mijn native vlan op mijn management. Op de D-link heb ik mijn poorten op access/trunk poorten staan met native mijn computer network.</p>"},{"location":"network/switch/d_link/#8021q","title":"802.1Q","text":"<p>om meerdere VLANs over deze switch te sturen zal je tegen de switch moeten zetten dat deze bestaat. Standaard heeft hij Vlan1 (untagged) aangemaakt. In mijn case heb ik VLAN 10 (LAN), VLAN 20 (Servers). Eerst maak ik de vlans aan en zeg ik aan welke poorten deze gekoppeld moeten worden. Wat hier wel belangrijk is dat je duidelijke meegeeft per poort of dit Untagged, Tagged of Not Member is.</p> <p></p> <p>Note</p> <p>Zie er we wanneer die voor client of een server is. Als dit over client gaat zou ik de poort untagged voor lan nemen. En voor servers zou ik je server VLAN nemen.</p> <p></p>"},{"location":"network/tools/wireshark/","title":"Wireshark","text":""},{"location":"network/tools/wireshark/#wireshark","title":"Wireshark","text":""},{"location":"network/tools/wireshark/#capturen","title":"Capturen","text":""},{"location":"network/tools/wireshark/#local-dns-prefix-capturen","title":"Local DNS Prefix capturen","text":"<p>Hier uitleg geven over \"Als je dit in Wireshark zou capturen zal je zien dat hij achter <code>tower</code> alle prefixen gaat plakken en dat over het netwerk naar de local dns server sturen.\"</p>"},{"location":"network/vpn/cloudflare-tunnels/","title":"Cloudflare Tunnel","text":""},{"location":"network/vpn/cloudflare-tunnels/#cloudflare-tunnel","title":"Cloudflare Tunnel","text":""},{"location":"network/vpn/cloudflare-tunnels/#protect-your-web-servers-from-direct-attack","title":"Protect your web servers from direct attack","text":"<p>From the moment an application is deployed, developers and IT spend time locking it down \u2014 configuring ACLs, rotating IP addresses, and using clunky solutions like GRE tunnels.</p> <p>There\u2019s a simpler and more secure way to protect your applications and web servers from direct attacks: Cloudflare Tunnel.</p> <p>Ensure your server is safe, no matter where it\u2019s running: public cloud, private cloud, Kubernetes cluster, or even a Mac mini under your TV.</p>"},{"location":"network/vpn/cloudflare-tunnels/#i-do-everthing-in-the-cli","title":"I do everthing in the cli","text":"<p>install the cloudflare tunnel service. in my case i will do the install on een ubuntu machine.</p> <pre><code>wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb &amp;&amp; sudo dpkg -i cloudflared-linux-amd64.deb\n</code></pre> <p>When you run the flowing command you get a url. login to cloudflare</p> <pre><code>cloudflared tunnel login\n</code></pre> <p>Tip</p> <p>When cloudflare is connected you get a cert.pem. Make a note of the location.</p> <p>create the tunnel by name fill the name that you want for the tunnel.</p> <pre><code>cloudflared tunnel create &lt;NAME&gt;\n</code></pre> <p>Tip</p> <p>Take a note where your tunnel credentials are saved.</p> <p>create a\u00a0configuration file\u00a0in the\u00a0<code>.cloudflared</code>\u00a0directory</p> <pre><code>nano /home/$USER/.cloudflared/config.yaml\n</code></pre> <p>Set the following lines.</p> <pre><code>tunnel: Your-Tunnel-Id\ncredentials-file: /home/$USER/.cloudflared/1d4537b6-67b9-4c75-a022-ce805acd5c0a.json\n\n1d4537b6-67b9-4c75-a022-ce805acd5c0a.json # Get the json file from previous step.\n</code></pre> <p>add your first site example.com</p> <pre><code>cloudflared tunnel route dns &lt;name of the tunnel&gt; &lt;example.com&gt;\n</code></pre> <p>create the ingress. create config.yml file in you .cloudflared directory</p> <pre><code>ingress:\n  - hostname: example.com\n    service: http://internalip:80\n  - hostname: sub.example.com\n    service: http://internalip:88\n  - service: http_status:404 # this is required as a 'catch-all'\n</code></pre> <p>start the tunnel</p> <pre><code>cloudflared tunnel run &lt;name of your tunnel&gt;\n</code></pre> <p>Make a service to run automatic</p> <pre><code>cloudflared service install\n</code></pre> <p>start en enable the service</p> <pre><code>systemctl enable --now cloudflared\n</code></pre>"},{"location":"network/vpn/s2s/","title":"Site to Site (S2S)","text":""},{"location":"network/vpn/s2s/#site-to-site-s2s","title":"Site to Site (S2S)","text":"<p>Een Site to Site maakt het heel gemakkelijk zoals in een bedrijf om 2 locaties veilig met elkaar te verbinden alsof het 1 locatie (en dus netwerk) is. Daarom hebben wij er voor gekozen om onze 2 locaties met elkaar te verbinden. Zo kunnen we onze Docker services gemakkelijk delen zonder over het internet te gaan.</p> <p>Onze huidige configuratie is opgemaakt met Pfsense en Unifi.</p> <p>Laten we eerst even oplijsten wat onze vereisten zijn om een S2S op te zetten.</p> <p>Note</p> <p>Zie wel dat je een bridge modem heb zodat jouw firewall een WAN IP heeft zodat jij de modem bent.</p> <ul> <li>Phase1</li> <li>Version: IKEv\u00bd</li> <li>Remote IP: WAN IP van de andere locatie</li> <li>Authenticatie: PSK/Certificaat</li> <li>Encryption: AES/3DES/...</li> <li>Life time: 28800</li> <li>Dead peer Detection: Optioneel kijk of de andere kant nog op is.</li> <li>Phase2</li> <li>Local network: host/range/network</li> <li>Remote netwerk: Lokale Subnet aan de remote kant (Mag niet gelijk zijn aan dat van jou)</li> <li>Protocol: ESP/AH</li> <li>Encryption: AES/3DES/...</li> <li>Hash: MD5/sha...</li> <li>PFS: Alles hoger dan 14</li> <li>Life time: 3600</li> </ul>"},{"location":"network/vpn/s2s/#instellen","title":"Instellen","text":""},{"location":"network/vpn/s2s/#pfsense","title":"PfSense","text":"<p>Note</p> <p>Zie wel dat je bij de encryptie ook de <code>AESxxx-GCM</code> opzet. Je hebt geen keus om dit bij Unifi in te stellen.</p> <ol> <li> <p>VPN intellingen</p> <ul> <li>VPN \u2192 IPSec \u2192 Add P1 (Phase 1)</li> <li>VPN \u2192 IPSec \u2192 Add P2 (Phase 2)</li> </ul> </li> <li> <p>Kijk vervolgend in de logs of de VPN online is gekomen.</p> <ul> <li>Status \u2192 System Logs \u2192 IPSec</li> </ul> </li> <li> <p>Als de VPN onlineis  ga je nog rules moeten opzetten.</p> <ul> <li>Firewall \u2192 Rules \u2192 IPSec<ul> <li>hier stel je de routing net als dat je dat doet bij andere VLANs</li> </ul> </li> </ul> </li> </ol> <p>Note</p> <p>Hou rekening met je andere rules als je in een vlan/subnet aanduid dat die niet aan alles kan kan die daar ook geblokeerd worden. Als het dan nog niet werkt kan je terug in de logs gaan kijken maar bij Firewall \u2192 Normal view. Hier kan je dan op <code>+</code> klikken en gaat die voor dat IP zelf een rule aanmaken. Vervolgend kan je terug naar rules gaan. Deze rule zoeken en aanspassen naar het hele subnet b.v.</p>"},{"location":"network/vpn/s2s/#unifi","title":"Unifi","text":"<ol> <li>Eerst gaan we de VPN instellen.<ul> <li>Settings \u2192 Teleport &amp; VPN \u2192 Site-to-Site-VPN \u2192 Create Site-to-Site VPN<ul> <li>Enable Route-Based VPN</li> </ul> </li> </ul> </li> <li> <p>nu gaan we de routing instellen</p> <ul> <li>Setting \u2192 Firewall &amp; Security \u2192 LAN \u2192 Create New Rule</li> </ul> </li> </ol> <p>Note</p> <p>Er vanuitgaand dat jouw Firewall correct is ingesteld.</p>"},{"location":"network/vpn/tailscale/","title":"Tailscale","text":""},{"location":"network/vpn/tailscale/#tailscale","title":"Tailscale","text":"<p>Tailscale is een VPN-service die de apparaten en applicaties die u bezit overal ter wereld toegankelijk maakt, veilig en moeiteloos. Het maakt gebruik van versleutelde peer-to-peer verbindingen met behulp van het open source WireGuard-protocol, wat betekent dat alleen apparaten op uw priv\u00e9netwerk met elkaar kunnen communiceren. Tailscale kan zowel met Docker als met Kubernetes werken om de implementatie en het beheer van gecontaineriseerde applicaties en services gemakkelijker en effici\u00ebnter te maken2. Tailscale heeft een gratis en open-source CE-editie en een commerci\u00eble Business-editie.</p> <p></p>"},{"location":"network/vpn/vpn/","title":"VPN","text":""},{"location":"network/vpn/wireguard/","title":"WireGuard","text":""},{"location":"network/vpn/wireguard/#wireguard","title":"WireGuard","text":"<p>WireGuard\u00a0is an extremely simple yet fast and modern VPN Protocol that utilizes\u00a0state-of-the-art. It aims to be\u00a0faster,\u00a0simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances.</p>"},{"location":"network/vpn/wireguard/#create-wireguard-keys-private-publickey","title":"Create Wireguard keys (private &amp; publickey)","text":"<pre><code>wg genkey | tee privatekey | wg pubkey &gt; publickey\n</code></pre>"},{"location":"network/vpn/wireguard/#example-of-server-config","title":"Example of server config","text":"<p>for example: </p><pre><code>nano /etc/wireguard/wg0.conf\n</code></pre> <p>Example server config: </p><pre><code>[Interface]\nAddress = 192.168.8.1/0 #ip of the wireguard server\nSaveConfig = true\nListenPort = 51820 # default port you can change it\nFwMark = 0xca6c\nPrivateKey = #paste here your privatekey\n\nPostUp = iptables -A FORWARD -i wg0 -j ACCEPT\nPostUp = iptables -t nat -A POSTROUTING -o ens2 -j MASQUERADE\nPostDown = iptables -A FORWARD -i wg0 -j ACCEPT\nPostDown= iptables -t nat -A POSTROUTING -o ens2 -j MASQUERADE\n\n# change here your peers conf\n[Peer]\nPublicKey = #paste here your pub key of your client\nAllowedIPs = 192.168.8.3/32 # change ip in your range\nPersistentKeepalive = 25\n\n[Peer]\nPublicKey = #paste here your pub key of your client\nAllowedIPs = 192.168.8.2/32 # change ip in your range\nPersistentKeepalive = 25\n</code></pre>"},{"location":"network/vpn/wireguard/#example-of-the-client-config","title":"Example of the client config","text":"<pre><code>[Interface]\nAddress = 192.168.8.2/32 # change this to the ip that you want for your client\nMTU = 1420\nSaveConfig = true\nListenPort = 47991\nFwMark = 0xca6c\nPrivateKey = # set here the privatekey of your client.\n\n[Peer]\nPublicKey = # paste here the public key of your wireguard server\nAllowedIPs = 0.0.0.0/0\nEndpoint = your-external-ip:51820\nPersistentKeepalive = 15\n</code></pre>"},{"location":"network/vpn/wireguard/#troubleshooting","title":"Troubleshooting","text":"<p>With this command you can enable the debug logging in WireGuard:</p> <pre><code>echo 'module wireguard +p' | sudo tee /sys/kernel/debug/dynamic_debug/control\n</code></pre> <p>And the same command with -p can disable it again:</p> <pre><code>echo 'module wireguard -p' | sudo tee /sys/kernel/debug/dynamic_debug/control\n</code></pre>"},{"location":"programming/markdown/","title":"Markdown","text":""},{"location":"programming/markdown/#markdown","title":"Markdown","text":"<p>Markdown is een tekst-naar-HTML-conversietool voor webschrijvers. Met Markdown kunt u schrijven met behulp van een gemakkelijk te lezen, gemakkelijk te schrijven platte tekstindeling en deze vervolgens converteren naar structureel geldige XHTML (of HTML).</p> <p>Documentation: Markdown Docs RFC: RFC 7763 GitHub Documentation: Writing Markdown on GitHub</p>"},{"location":"programming/markdown/#cheat-sheet","title":"Cheat-Sheet","text":""},{"location":"programming/markdown/#headings","title":"Headings","text":"<pre><code># Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n##### Heading 5\n###### Heading 6\n</code></pre> <p>Here is a heading: <code># Heading</code>, don't do this: <code>#Heading</code></p>"},{"location":"programming/markdown/#emphasis","title":"Emphasis","text":"<pre><code>Emphasis, aka italics, with *asterisks* or _underscores_.\n\nStrong emphasis, aka bold, with **asterisks** or __underscores__.\n\nCombined emphasis with **asterisks and _underscores_**.\n\nStrikethrough uses two tildes. ~~Scratch this.~~\n</code></pre>"},{"location":"programming/markdown/#line-breaks","title":"Line Breaks","text":"<pre><code>First line with two spaces after.\nAnd the next line.\n</code></pre>"},{"location":"programming/markdown/#lists","title":"Lists","text":""},{"location":"programming/markdown/#ordered-lists","title":"Ordered Lists","text":"<pre><code>1. First item\n2. Second item\n3. Third item\n</code></pre>"},{"location":"programming/markdown/#unordered-lists","title":"Unordered Lists","text":"<pre><code>- First item\n- Second item\n- Third item\n</code></pre>"},{"location":"programming/markdown/#links","title":"Links","text":"<pre><code>Link with text: [link-text](https://www.google.com)\n</code></pre>"},{"location":"programming/markdown/#images","title":"Images","text":"<pre><code>Image with alt text: ![alt-text](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067)\n\nImage without alt text: ![](https://camo.githubusercontent.com/4d89cd791580bfb19080f8b0844ba7e1235aa4becc3f43dfd708a769e257d8de/68747470733a2f2f636e642d70726f642d312e73332e75732d776573742d3030342e6261636b626c617a6562322e636f6d2f6e65772d62616e6e6572342d7363616c65642d666f722d6769746875622e6a7067)\n</code></pre>"},{"location":"programming/markdown/#code-blocks","title":"Code Blocks","text":""},{"location":"programming/markdown/#inline-code-block","title":"Inline Code Block","text":"<pre><code>Inline `code` has `back-ticks around` it.\n</code></pre>"},{"location":"programming/markdown/#blocks-of-code","title":"Blocks of Code","text":"<pre>\n<pre><code>var s = \"JavaScript syntax highlighting\";\nalert(s);\n</code></pre>\n\n<pre><code>s = \"Python syntax highlighting\"\nprint s\n</code></pre>\n\n<pre><code>No language indicated, so no syntax highlighting.\nBut let's throw in a &lt;b&gt;tag&lt;/b&gt;.\n</code></pre>\n</pre>"},{"location":"programming/markdown/#tables","title":"Tables","text":"<p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily.</p> <pre><code>| Heading 1 | Heading 2 | Heading 3 |\n|---|---|---|\n| col1 | col2 | col3 |\n| col1 | col2 | col3\u00a0|\n</code></pre>"},{"location":"programming/markdown/#task-list","title":"Task list","text":"<p>To create a task list start line with square brackets with an empty space. Ex: [  ] and add text for task. To check the task replace the space between the bracket with \"x\".</p> <pre><code>[x] Write the post\n[ ] Update the website\n[ ] Contact the user\n</code></pre>"},{"location":"programming/markdown/#reference","title":"Reference","text":"<p>Link: markdown guide</p>"},{"location":"programming/programming/","title":"Programming","text":""},{"location":"programming/python/","title":"Python","text":""},{"location":"programming/yaml/","title":"YAML","text":""},{"location":"programming/gatsby/gatsby/","title":"Gatsby Setup and Usage Guide","text":""},{"location":"programming/gatsby/gatsby/#gatsby-setup-and-usage-guide","title":"Gatsby Setup and Usage Guide","text":"<p>This guide provides instructions on setting up and using Gatsby, a powerful tool for building websites. Follow the steps below to get started.</p>"},{"location":"programming/gatsby/gatsby/#setting-up-gatsby","title":"Setting up Gatsby","text":"<ol> <li>Run the following command to set up Gatsby:</li> </ol> <pre><code>$ Gatsby build\n</code></pre> <ol> <li> <p>To stop the server, press <code>Control</code>.</p> </li> <li> <p>The <code>Gatsby build</code> command generates a <code>public</code> folder that contains all the optimized assets and files for the project.</p> </li> </ol>"},{"location":"programming/gatsby/gatsby/#working-with-static-assets","title":"Working with Static Assets","text":"<p>Gatsby converts the project into static files for efficient delivery. However, it is recommended to avoid directly adding assets to the <code>static</code> folder to benefit from Gatsby's optimizations. Instead, follow the proper procedure outlined in the documentation.</p>"},{"location":"programming/gatsby/gatsby/#development-server","title":"Development Server","text":"<p>To start the development server, you have two options:</p> <ul> <li>Run the command:</li> </ul> <pre><code>$ Gatsby develop\n</code></pre> <ul> <li>Alternatively, use the npm start script:</li> </ul> <pre><code>$ npm start\n</code></pre> <p>The server will be accessible at <code>localhost:8000</code>, where you can preview your project during development.</p>"},{"location":"programming/gatsby/gatsby/#previewing-the-production-ready-project","title":"Previewing the Production-Ready Project","text":"<p>To serve the production-ready project locally for preview:</p> <ol> <li> <p>Ensure you have previously run <code>Gatsby build</code> to generate the <code>public</code> folder.</p> </li> <li> <p>Execute the following command:</p> </li> </ol> <pre><code>$ Gatsby serve\n</code></pre> <p>You can now access the project at <code>localhost:9000</code>.</p>"},{"location":"programming/gatsby/gatsby/#clearing-cache-and-troubleshooting","title":"Clearing Cache and Troubleshooting","text":"<ol> <li>To clear the cache and ensure changes take effect, use the following command:</li> </ol> <pre><code>$ Gatsby clean\n</code></pre> <ol> <li> <p>The <code>Gatsby clean</code> command deletes the cache and <code>public</code> folder. This is particularly useful when working with images and encountering caching issues.</p> </li> <li> <p>If changes to your code are not reflected in the browser automatically, try manually refreshing the page. Although Gatsby uses hot reloading, some scenarios may require a manual refresh.</p> </li> <li> <p>Gatsby version 3 includes an error model that helps identify code errors. If an error occurs, you will see a helpful model pointing out the specific issue.</p> </li> </ol>"},{"location":"programming/gatsby/gatsby/#source-directory","title":"Source Directory","text":"<p>Most of the project work should be performed in the <code>source</code> directory.</p> <p>Please note that this is a condensed summary of the key points covered in the transcript. For more detailed instructions and explanations, refer to the official Gatsby documentation.</p>"},{"location":"programming/github/dependabot/","title":"Dependabot","text":""},{"location":"programming/github/gh/","title":"gh","text":""},{"location":"programming/github/gh/#gh","title":"gh","text":"<p>Zalig, met simpel commando kan ik alle private repo's uit organization verwijderen \ud83d\ude04</p> <pre><code>gh repo list Cowadar --visibility=private | awk '{print $1}' | xargs -n 1 bash -c 'gh repo delete $0 --confirm'\n</code></pre>"},{"location":"programming/github/git/","title":"Git","text":""},{"location":"programming/github/git/#git","title":"Git","text":"<p>Git is een snel, schaalbaar, gedistribueerd versiebeheersysteem met een ongewoon rijke commandoset die zowel hoog-niveau operaties als volledige toegang tot de interne werking biedt. Git commando is het hoofdcommando dat wordt gebruikt om andere git subcommando\u2019s aan te roepen. De algemene syntax voor het commando is: <code>git &lt;opties&gt; &lt;subcommando&gt; [&lt;argumenten&gt;]</code>. Enkele veelgebruikte subcommando\u2019s zijn:</p> <ul> <li>config om de gebruiker te configureren of globale instellingen te wijzigen.</li> <li>init om een lokale repository te maken.</li> <li><code>clone</code> om een kopie te maken van een bestaande repository van een URL.</li> <li><code>add</code> om bestanden toe te voegen aan de staging area.</li> <li><code>commit</code> om een snapshot te maken van de wijzigingen en deze op te slaan in de git directory.</li> <li><code>status</code> om de lijst van gewijzigde bestanden en de bestanden die nog moeten worden gestaged of gecommit te tonen.</li> <li><code>push</code> om lokale commits naar de externe repository te sturen.</li> <li><code>pull</code> om wijzigingen van de externe repository op te halen en samen te voegen met de lokale branch.</li> <li><code>branch</code> om branches te lijsten, maken, hernoemen of verwijderen.</li> <li><code>checkout</code> om branches aan te maken en ertussen te wisselen of bestanden uit te checken.</li> <li><code>merge</code> om twee of meer branches samen te voegen tot \u00e9\u00e9n branch.</li> <li><code>log</code> om de geschiedenis van commits te tonen.</li> </ul>"},{"location":"programming/github/git/#git-config","title":"Git config","text":"<p><code>Git config</code> is een subcommando dat wordt gebruikt om git configuratie waarden in te stellen op een globaal of lokaal projectniveau. Deze configuratieniveaus komen overeen met .gitconfig tekstbestanden. Het uitvoeren van git config zal een configuratietekstbestand wijzigen. Je kunt met dit commando je persoonlijke werkvoorkeuren instellen, zoals je e-mail, gebruikersnaam, bestandsformaat, kleuren, enzovoort.</p> <p>De algemene syntax voor het commando is: <code>git config &lt;opties&gt; &lt;naam&gt; [&lt;waarde&gt;]</code>. Enkele veelgebruikte opties zijn:</p> <ul> <li><code>global</code> om een waarde in te stellen voor alle lokale repositories. De waarde wordt opgeslagen in het bestand ~/.gitconfig (of ~/.config/git/config).</li> <li><code>local</code> om een waarde in te stellen voor de huidige repository. De waarde wordt opgeslagen in het bestand .git/config. Dit is het standaardniveau als er geen optie wordt gegeven.</li> <li><code>system</code> om een waarde in te stellen voor alle gebruikers op het systeem en al hun repositories. De waarde wordt opgeslagen in het bestand [path]/etc/gitconfig. Je moet de optie --system expliciet geven om van dit niveau te lezen of te schrijven.</li> <li><code>file &lt;bestand&gt;</code> om een waarde in te stellen in een specifiek bestand dat je opgeeft.</li> <li><code>add</code> om een nieuwe regel toe te voegen aan een optie die meerdere regels kan hebben.</li> <li><code>replace-all</code> om alle regels die overeenkomen met de naam (en eventueel de waarde-patroon) te vervangen door een nieuwe regel.</li> <li><code>get</code> om de waarde van een bepaalde naam te tonen.</li> <li><code>get-all</code> om alle waarden van een bepaalde naam te tonen.</li> <li><code>get-regexp</code> om alle namen en waarden die overeenkomen met een reguliere expressie te tonen.</li> <li><code>unset</code> om een naam (en eventueel de waarde-patroon) te verwijderen.</li> <li><code>unset-all</code> om alle namen (en eventueel de waarde-patronen) die overeenkomen met de reguliere expressie te verwijderen.</li> <li><code>rename-section</code> om een sectie te hernoemen naar een nieuwe naam.</li> <li><code>remove-section</code> om een sectie en al zijn waarden te verwijderen.</li> <li><code>l</code> of <code>--list</code> om alle namen en waarden van de configuratiebestanden te tonen.</li> <li><code>-e</code> of <code>edit</code> om het configuratiebestand met je editor te openen en aan te passen.</li> </ul>"},{"location":"programming/github/git/#git-init","title":"Git init","text":"<p><code>Git init</code> is een subcommando dat wordt gebruikt om een nieuwe git repository te maken. Het kan worden gebruikt om een bestaand, niet-versiebeheerd project om te zetten naar een git repository of om een nieuwe, lege repository te initialiseren. De meeste andere git commando\u2019s zijn niet beschikbaar buiten een ge\u00efnitialiseerde repository, dus dit is meestal het eerste commando dat je uitvoert in een nieuw project.</p> <p>De algemene syntax voor het commando is: <code>git init [&lt;opties&gt;] [&lt;directory&gt;]</code>. Enkele veelgebruikte opties zijn:</p> <ul> <li><code>-bare</code> om een kale repository te maken. Dit is een repository die alleen wordt gebruikt als een externe repository en die geen actieve ontwikkeling bevat. De repository bevat alleen de .git directory en geen werkdirectory.</li> <li><code>-template=&lt;template-directory&gt;</code> om een directory op te geven waaruit sjablonen worden gebruikt. Dit zijn bestanden die worden gekopieerd naar de .git directory van de nieuwe repository, zoals hooks of beschrijvingen.</li> <li><code>-separate-git-dir=&lt;git-dir&gt;</code> om een tekstbestand te maken in plaats van een directory voor de .git directory van de repository. Dit bestand bevat het pad naar de eigenlijke repository en fungeert als een bestandssysteemonafhankelijke git symbolische link naar de repository.</li> <li><code>-b &lt;branch-name&gt;</code> of <code>--initial-branch=&lt;branch-name&gt;</code> om de naam op te geven voor de initi\u00eble branch in de nieuwe repository. Als dit niet wordt opgegeven, wordt de standaardnaam gebruikt (momenteel master, maar dit kan in de toekomst veranderen; de naam kan worden aangepast via de init.defaultBranch configuratievariabele).</li> <li><code>-shared [= (false|true|umask|group|all|world|everybody|&lt;perm&gt;)]</code> om aan te geven dat de git repository moet worden gedeeld tussen meerdere gebruikers. Dit maakt het mogelijk dat gebruikers die tot dezelfde groep behoren naar die repository kunnen pushen. Wanneer dit wordt opgegeven, wordt de configuratievariabele \u201ccore.sharedRepository\u201d ingesteld zodat bestanden en directories onder $GIT_DIR worden aangemaakt met de gevraagde permissies.</li> </ul>"},{"location":"programming/github/git/#usefull-links","title":"Usefull links","text":"<ul> <li>OpenCommit: Auto-generate meaningful commits in 1 second</li> <li>Gitmoji: Gitmoji is an initiative to standardize and explain the use of emojis on GitHub commit messages.</li> </ul>"},{"location":"programming/github/git_branch/","title":"GitHub Brancheregels (Bescherm je Git-branches) - YouTube","text":""},{"location":"programming/github/git_branch/#github-brancheregels-bescherm-je-git-branches-youtube","title":"GitHub Brancheregels (Bescherm je Git-branches) - YouTube","text":"<p>In deze video bespreken we branchebescherming en het belang ervan bij het handhaven van codekwaliteit en samenwerking binnen een repository. De spreker benadrukt de uitdagingen van het beheren van meerdere beoordelingen, CI-controles en andere vereisten handmatig. Ze stellen voor om de brancheregelfunctie van GitHub te gebruiken om deze vereisten geautomatiseerd af te handelen.</p>"},{"location":"programming/github/git_branch/#configuratiestappen","title":"Configuratiestappen","text":"<ol> <li>Ga naar de Instellingen van de repository.</li> <li>Selecteer het tabblad Branches.</li> <li>Configureer brancheregels voor een specifieke branch of gebruik wildcards voor meerdere branches.</li> <li>Specificeer de gewenste regels en opties voor branchebescherming:</li> </ol>"},{"location":"programming/github/git_branch/#configuring-protection-rules","title":"Configuring Protection Rules","text":"<p>After selecting the desired branch, a range of options is presented for configuration. The speaker suggests the following practices and encourages viewers to share their preferences in the comments:</p> <ol> <li> <p>Require a pull request before merging \u2705: This option ensures that commits made to unprotected branches, such as feature- or bug-specific branches, go through a pull request process before merging into the main branch. The speaker recommends enabling this option and discusses the importance of having multiple approvals for significant changes.</p> </li> <li> <p>Require approvals \u2705 (1): Users can specify the minimum number of approvals required for merging a pull request. Depending on the situation, it can be set to one or more, striking a balance between efficiency and thoroughness.</p> </li> <li> <p>Dismiss Stale Approvals \u2705: This crucial setting automatically dismisses previous approvals when new commits are added to a pull request. By enabling this option, contributors cannot merge additional commits without the newly added code being reviewed.</p> </li> <li> <p>Check Status of GitHub Actions: It is advised to ensure that all status checks, including GitHub Actions, pass successfully before merging. Failing checks indicate unresolved issues that need to be fixed before merging.</p> </li> <li> <p>Keep Branches Up to Date: The speaker emphasizes the importance of merging changes from the target branch (e.g., main) into the pull request branch before merging. This practice ensures that the changes being merged are compatible with the latest codebase.</p> </li> <li> <p>Resolve Conversations: Inline comments and discussions in pull requests are highly encouraged for collaboration and knowledge transfer. It is essential to resolve these conversations by addressing pending issues or marking them as resolved.</p> </li> <li> <p>Require Signed Commits: While the speaker acknowledges the benefits of signed commits for verification, they note that it poses a high barrier to entry for contributors. Consequently, enabling this option might not be practical for most projects.</p> </li> <li> <p>Require Linear History: The preference for a linear commit history varies among users. The speaker leaves this option open for debate and encourages viewers to share their opinions.</p> </li> <li> <p>Require Deployments to Succeed: If branches are deployed to production-like environments, enabling this option ensures that deployments succeed before allowing merges. However, the speaker suggests leaving this option unchecked in most cases, especially when testing can be adequately performed before merging.</p> </li> <li> <p>Include Administrators: It is highly recommended to enforce branch protection rules for administrators as well. Although there may be rare occasions where bypassing rules is necessary, it should not become the norm.</p> </li> <li> <p>Restrict Force Pushes: Force pushing, which rewrites branch history, should generally be prohibited when collaborating with others. It is crucial to avoid conflicts caused by rewriting history.</p> </li> <li> <p>Allow Deletions: Once branches are merged, the speaker suggests deleting feature and bug fix branches to keep the branch list clean. This practice helps maintain a low number of active branches while emphasizing high-quality releases.</p> </li> </ol>"},{"location":"programming/github/git_cheatsheet/","title":"Git cheatsheet","text":""},{"location":"programming/github/git_cheatsheet/#git-cheatsheet","title":"Git cheatsheet","text":""},{"location":"programming/github/git_cheatsheet/#git-config","title":"Git config","text":""},{"location":"programming/github/git_cheatsheet/#gebruiker-definieren","title":"Gebruiker defini\u00ebren","text":""},{"location":"programming/github/git_cheatsheet/#methode-1","title":"Methode 1","text":"<pre><code>git config --global user.email \"email@mail.com\"\ngit config --global user.name \"username\"\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#methode-2","title":"Methode 2","text":"<p>Global config aanpassen via</p> <pre><code>git config --global --edit\n</code></pre> <p>Dan ziet je config er ongeveer zo uit: </p><pre><code>$ cat ~/.gitconfig\n[user]\n    name = Bedar Idem\n    email = &lt;user&gt;@&lt;domain&gt;\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#file-permissions-problemen-oplossen","title":"File permissions problemen oplossen","text":"<pre><code>git config core.filemode false\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#git-pull","title":"Git pull","text":""},{"location":"programming/github/git_cheatsheet/#git-pull-in-subfolders","title":"Git pull in subfolders","text":"<p>Indien je in meerdere onderliggende folders git repo's hebt zitten, kan je met dit commando alle git repos laten pullen.</p> <p>Dankzij parallel zal dit niet tegelijkertijd uitgevoerd worden, maar op meerdere tasks in parallel.</p> <pre><code>find . -maxdepth 8 -name '.git' -prune -type d -printf '%h\\n' | parallel --eta 'echo {} &amp;&amp; git -C {} pull'\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#git-alias","title":"Git alias","text":"<p>Als je dit in je terminal ingeeft, kan je commando's sneller schrijven met korte aliassen.</p> <pre><code>function gc () {\n git commit -m \"$*\"\n}\n\nalias ga='git add'\nalias gp='git push'\nalias gl='git log'\nalias gs='git status'\nalias gd='git diff'\nalias gdc='git diff --cached'\nalias gb='git branch'\nalias gra='git remote add'\nalias grr='git remote rm'\nalias gpu='git pull'\nalias gcl='git clone'\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#git-fetch","title":"Git Fetch","text":"<p>Git fetch is een commando dat commits, bestanden, branches en tags ophaalt van een externe repository naar je lokale repository. De algemene syntax voor het commando is: <code>git fetch &lt;opties&gt; &lt;externe naam&gt; &lt;branch naam&gt;</code> Git isoleert de opgehaalde inhoud van de lokale code. Daarom biedt de fetch een veilige manier om de informatie te bekijken voordat je deze commit naar je lokale branch</p>"},{"location":"programming/github/git_cheatsheet/#fetch-alle-externe-branches","title":"Fetch alle externe branches","text":"<pre><code>git fetch --all\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#fetch-enkel-1-branch","title":"Fetch enkel 1 branch","text":"<pre><code>git fetch origin &lt;local-branch-name&gt;:&lt;remote-branch-name&gt;\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#git-branch","title":"Git branch","text":"<p>Git branch is een commando dat branches lijst, maakt, hernoemt of verwijdert. Een branch is een onafhankelijke lijn van ontwikkeling. Branches dienen als een abstractie voor het bewerken/stagen/commiten proces. Je kunt ze beschouwen als een manier om een nieuwe werkmap, staging area en projectgeschiedenis aan te vragen. Nieuwe commits worden vastgelegd in de geschiedenis van de huidige branch, wat resulteert in een splitsing in de geschiedenis van het project.</p> <p>De algemene syntax voor het commando is: <code>git branch &lt;opties&gt; &lt;branch naam&gt;</code>. Enkele veelgebruikte opties zijn:</p> <ul> <li><code>-d</code> om een branch te verwijderen. Dit is een \u201cveilige\u201d operatie omdat Git je verhindert om de branch te verwijderen als deze niet-samengevoegde wijzigingen heeft.</li> <li><code>-D</code> om een branch geforceerd te verwijderen, zelfs als deze niet-samengevoegde wijzigingen heeft. Dit is het commando om te gebruiken als je alle commits die verband houden met een bepaalde ontwikkelingslijn permanent wilt weggooien.</li> <li><code>-m</code> om de huidige branch te hernoemen.</li> <li><code>-a</code> om zowel lokale als externe branches te tonen. Het git branch commando laat je niet toe om tussen branches te wisselen of een gesplitste geschiedenis weer samen te voegen. Daarom is git branch nauw ge\u00efntegreerd met de git checkout en git merge commando\u2019s</li> </ul>"},{"location":"programming/github/git_cheatsheet/#branch-verwijderen","title":"Branch verwijderen","text":"<pre><code>git branch -D branch-name\n</code></pre>"},{"location":"programming/github/git_cheatsheet/#laat-alle-locale-branches-zien","title":"Laat alle locale branches zien","text":"<pre><code>git branch -a\n</code></pre>"},{"location":"programming/github/github/","title":"Github","text":""},{"location":"programming/github/github/#github","title":"Github","text":"<ul> <li>Website: github.com</li> <li>Documentatie: docs.github.com</li> </ul> <p>GitHub is een platform waar meer dan 100 miljoen ontwikkelaars samen software bouwen. Je kunt bijdragen aan de open source gemeenschap, je Git repositories beheren, code reviewen als een pro, bugs en features bijhouden, je CI/CD en DevOps workflows ondersteunen en je code beveiligen voordat je die commit. GitHub biedt ook verschillende functies om je te helpen met je projecten, zoals GitHub Copilot, GitHub Actions, GitHub Mobile, GitHub Discussions, pull requests, GitHub Sponsors, secret scanning, Dependabot en code scanning.</p> <ul> <li>GitHub Copilot is je AI-pair-programmeur die je helpt om taken 55% sneller te voltooien door natuurlijke taalprompts om te zetten in code-suggesties.</li> <li>GitHub Actions automatiseert je build-, test- en deployment-workflow met eenvoudige en veilige CI/CD.</li> <li>GitHub Mobile past je projecten in je zak, zodat je nooit iets mist terwijl je onderweg bent.</li> <li>GitHub Discussions cre\u00ebert ruimte om vragen te stellen en open gesprekken te voeren.</li> <li>Pull requests maken real-time communicatie en samenwerking over codeveranderingen mogelijk.</li> <li>GitHub Sponsors laat je je favoriete open source onderhouders en projecten ondersteunen.</li> <li>Secret scanning zoekt automatisch naar partnerpatronen en voorkomt frauduleus gebruik van per ongeluk gecommitteerde geheimen.</li> <li>Dependabot maakt het gemakkelijk om kwetsbare afhankelijkheden in je supply chain te vinden en op te lossen.</li> <li>Code scanning is GitHub\u2019s statische code-analysetool die je helpt om problemen in je code te verhelpen.</li> </ul>"},{"location":"programming/github/github_actions/","title":"GitHub Actions","text":""},{"location":"programming/github/github_actions/#github-actions","title":"GitHub Actions","text":"<p>Automatiseer, pas aan en voer uw softwareontwikkelingsworkflows uit in uw repository met GitHub Actions. U kunt acties ontdekken, maken en delen om elke taak uit te voeren die u wilt, inclusief CI/CD, en acties combineren in een volledig aangepaste workflow.</p>"},{"location":"programming/github/github_actions/#workflows","title":"Workflows","text":""},{"location":"programming/github/github_actions/#events","title":"Events","text":""},{"location":"programming/github/github_actions/#jobs","title":"Jobs","text":""},{"location":"programming/github/github_actions/#actions","title":"Actions","text":""},{"location":"programming/github/github_actions/#runners","title":"Runners","text":"<p>Een runner is een server die uw workflows uitvoert wanneer ze worden geactiveerd. Elke runner kan \u00e9\u00e9n taak tegelijk uitvoeren. GitHub biedt Ubuntu Linux, Microsoft Windows en macOS runners om uw workflows uit te voeren; elke workflow-uitvoering wordt uitgevoerd in een nieuwe, nieuw ingerichte virtuele machine.</p>"},{"location":"programming/github/github_codescanning/","title":"Github Codescanning","text":""},{"location":"programming/github/github_copilot/","title":"Github Copilot","text":""},{"location":"programming/github/github_discussions/","title":"Github Discussions","text":""},{"location":"programming/github/github_mobile/","title":"Github Mobile","text":""},{"location":"programming/github/github_secretscanning/","title":"Github Secretscanning","text":""},{"location":"programming/github/github_sponsors/","title":"Github Sponsors","text":""},{"location":"programming/github/pull_requests/","title":"Pull Requests","text":""},{"location":"programming/github/submodules/","title":"Working with submodules","text":""},{"location":"programming/github/submodules/#working-with-submodules","title":"Working with submodules","text":"<p>Eventually, any interesting software project will come to depend on another project, library, or framework. Git provides submodules to help with this. Submodules allow you to include or embed one or more repositories as a sub-folder inside another repository.</p> <p>For many projects, submodules aren\u2019t the best answer (more on this below), and even at their best, working with submodules can be tricky, but let\u2019s start by looking at a straight-forward example.</p>"},{"location":"programming/github/submodules/#adding-a-submodule","title":"Adding a Submodule","text":"<p>Let\u2019s say you\u2019re working on a project called Slingshot. You\u2019ve got code for <code>y-shaped stick</code> and a <code>rubber-band</code>.</p> <p></p> <p>At the same time, in another repository, you\u2019ve got another project called Rock\u2014it\u2019s just a generic <code>rock</code> library, but you think it\u2019d be perfect for Slingshot.</p> <p>You can add <code>rock</code> as a submodule of <code>slingshot</code>. In the <code>slingshot</code> repository:</p> <pre><code>git submodule add https://github.com/&lt;user&gt;/rock rock\n</code></pre> <p>At this point, you\u2019ll have a <code>rock</code> folder inside <code>slingshot</code>, but if you were to peek inside that folder, depending on your version of Git, you might see \u2026 nothing.</p> <p>Newer versions of Git will do this automatically, but older versions will require you to explicitly tell Git to download the contents of <code>rock</code>:</p> <pre><code>git submodule update --init --recursive\n</code></pre> <p>If everything looks good, you can commit this change and you\u2019ll have a <code>rock</code> folder in the <code>slingshot</code> repository with all the content from the <code>rock</code> repository.</p> <p>On GitHub, the <code>rock</code> folder icon will have a little indicator showing that it is a submodule:</p> <p></p> <p>And clicking on the <code>rock</code> folder will take you over to the <code>rock</code> repository.</p> <p>That\u2019s it! You\u2019ve embedded the <code>rock</code> repository inside the <code>slingshot</code> repository. You can interact with all the content from <code>rock</code> as if it were a folder inside <code>slingshot</code> (because it is).</p> <p>On the command-line, Git commands issued from <code>slingshot</code> (or any of the other folders, <code>rubber-band</code> and <code>y-shaped-stick</code>) will operate on the \u201cparent repository\u201d, <code>slingshot</code>, but commands you issue from the <code>rock</code> folder will operate on just the <code>rock</code> repository:</p> <pre><code>cd ~/projects/slingshot\ngit log # log shows commits from Project Slingshot\ncd ~/projects/slingshot/rubber-band\ngit log # still commits from Project Slingshot\ncd ~/projects/slingshot/rock\ngit log # commits from Rock\n</code></pre>"},{"location":"programming/github/submodules/#joining-a-project-using-submodules","title":"Joining a project using submodules","text":"<p>Now, say you\u2019re a new collaborator joining Project Slingshot. You\u2019d start by running <code>git clone</code> to download the contents of the <code>slingshot</code> repository. At this point, if you were to peek inside the <code>rock</code> folder, you\u2019d see \u2026 nothing.</p> <p>Again, Git expects us to explicitly ask it to download the submodule\u2019s content. You can use <code>git submodule update --init --recursive</code> here as well, but if you\u2019re cloning <code>slingshot</code> for the first time, you can use a modified <code>clone</code> command to ensure you download everything, including any submodules:</p> <pre><code>git clone --recursive &lt;project url&gt;\n</code></pre>"},{"location":"programming/github/submodules/#switching-to-submodules","title":"Switching to submodules","text":"<p>It can be a little tricky to take an existing subfolder and turn it into an external dependency. Let\u2019s look at an example.</p> <p>You\u2019re about to start a new project\u2014a magic roll-back can\u2013which also needs a <code>rubber-band</code>. Let\u2019s take the <code>rubber-band</code> you built for <code>slingshot</code>, split it out into a stand-alone repository, and then embed it into both projects via submodules.</p> <p>You can take everything from the Project Slingshot\u2019s <code>rubber-band</code> folder and extract it into a new repository and even maintain the commit history.</p> <p>Let\u2019s begin by extracting the contents of the <code>rubber-band</code> folder out of <code>slingshot</code>. You can use <code>git filter-branch</code> to do this, leaving you with just the commits related to <code>rubber-band</code>. The <code>git filter-branch</code> command will rewrite our repository\u2019s history, making it look as if the <code>rubber-band</code> folder had been it\u2019s own repository all along. For more information on <code>git filter-branch</code>, see this article.</p> <p>The first step is to make a copy of <code>slingshot</code> to work on\u2014the end-goal is for <code>rubber-band</code> to stand as its own repository, so leave <code>slingshot</code> as is. You can use <code>cp</code> with <code>-r</code> to recursively copy the entire <code>slingshot</code> folder to a new folder <code>rubber-band</code>.</p> <pre><code>cd ..\ncp -r slingshot rubber-band\n</code></pre> <p>It looks like <code>rubber-band</code> is just another <code>slingshot</code>, but now, from the <code>rubber-band</code> repository, run <code>git filter-branch</code>:</p> <pre><code>cd rubber-band\npwd # (double check before proceeding!)\ngit filter-branch --subdirectory-filter rubber-band -- --all\n</code></pre> <p>At this point, you\u2019ll have a folder <code>rubber-band</code>, which is a repository that sort of resembles Project Slingshot, but it only has the files and commit history from the <code>rubber-band</code> folder.</p> <p>Since you copied this from <code>slingshot</code>, the new repository will still have any remote tracking branches you setup when it was <code>slingshot</code>. You don\u2019t want to push <code>rubber-band</code> back onto <code>slingshot</code>. You want to push this to a new repository.</p> <p>Create a new repository for <code>rubber-band</code> on GitHub, then update the remote for <code>rubber-band</code>. Assuming you were calling the remote <code>origin</code>, you could:</p> <pre><code>git remote set-url origin https://github.com/&lt;user&gt;/rubber-band\n</code></pre> <p>Then you can publish the new \u201cgeneric rubber-band module\u201d with <code>git push</code>.</p> <p>Now that you\u2019ve separated <code>rubber-band</code> into its own repository, you need to delete the old <code>rubber-band</code> folder from the <code>slingshot</code> repository:</p> <pre><code>git rm -r rubber-band\ngit commit -m \"Remove rubber-band (preparing for submodule)\"\n</code></pre> <p>Then update <code>slingshot</code> to use <code>rubber-band</code> as a submodule:</p> <pre><code>git submodule add https://github.com/&lt;user&gt;/rubber-band rubber-band\ngit commit -m \"rubber-band submodule\"\n</code></pre> <p>Like we saw before when we were adding <code>rock</code>, we now have a repository-in-a-repository. Three repositories, in fact: the \u201cparent\u201d repository <code>slingshot</code>, plus the two \u201csub\u201d repositories, <code>rock</code> and <code>rubber-band</code>.</p> <p>In addition, if we dive back into <code>slingshot</code>\u2018s history, we\u2019ll see the commits we originally made into <code>rubber-band</code> back when it was a folder\u2014deleting the folder didn\u2019t erase any of the history. This can sometimes be a little confusing\u2014since the <code>rubber-band</code> \u201cchild\u201d repository has a copied-and-modified version of those old <code>slingshot</code> commits, it can sometimes feel like you\u2019re having d\u00e9ja vu.</p> <p>Unfortunately, any collaborator who pulls <code>slingshot</code> at this point will have an empty <code>rubber-band</code> folder. You might want to remind your collaborators to run this command to ensure they have all the submodule\u2019s content:</p> <pre><code>git submodule update --init --recursive\n</code></pre> <p>You\u2019ll also want to add the <code>rubber-band</code> submodule to <code>magic roll-back can</code>. Luckily, all you need to do that is to follow the same procedure you used earlier when you added <code>rock</code> to <code>slingshot</code>, in \u201cAdding a submodule.\u201d</p> <pre><code>cd ~/projects/roll-back-can\ngit submodule add https://github.com/&lt;user&gt;/rubber-band rubber-band\ngit commit -m \"rubber-band submodule\"\ngit submodule update --init --recursive\n</code></pre>"},{"location":"programming/github/submodules/#advice-on-using-submodules-or-not","title":"Advice on using submodules (or not)","text":"<ul> <li>Before you add a repository as a submodule, first check to see if you have a better alternative available. Git submodules work well enough for simple cases, but these days there are often better tools available for managing dependencies than what Git submodules can offer. Modern languages like Go have friendly, Git-aware dependency management systems built-in from the start. Others, like Ruby\u2019s rubygems, Node.js\u2019 npm, or Cocoa\u2019s CocoaPods and Carthage, have been added by the programming community. Even front-end developers have tools like Bower to manage libraries and frameworks for client-side JavaScript and CSS.</li> <li>Remember that Git doesn\u2019t download submodule contents by default. If you\u2019re adding a submodule to an existing project, make sure anyone that works on the project knows they need to run commands like <code>git submodule update</code> and <code>git clone --recursive</code> to ensure they get everything\u2014this includes any automated deployment or testing service that might be involved in the project! We recommend you use something like our \u201cScripts to Rule Them All\u201d to ensure that all collaborators and services have access to the same repository content everywhere.</li> <li>Submodules require you to carefully balance consistency and convenience. The setup used here strongly prefers consistency, at the cost of a little convenience. It\u2019s generally best to have a project\u2019s submodules locked to a specific SHA, so all collaborators receive the same content. But this setup also makes it difficult for developers in the \u201cparent\u201d repository to contribute changes back to the submodule repository.</li> <li>Remember that collaborators won\u2019t automatically see updates to submodules\u2014if you update a submodule, you may need to remind your colleagues to run <code>git submodule update</code> or they will likely see odd behavior.</li> <li>Managing dynamic, rapidly evolving or heavily co-dependent repositories with submodules can quickly become frustrating. This post was focused on simple, relatively static parent-child repository relationships. A future follow-up post will detail some strategies to help manage more complex submodule workflows.</li> </ul>"},{"location":"programming/github/submodules/#git-submodule-guide-basic-commands-to-get-started","title":"Git Submodule Guide &amp; Basic Commands to Get Started","text":"<p>Warning</p> <p>update this!</p> <p>Introduction</p> <p>When developing an application using Git, it is practical to integrate code available in other repositories. Reusing the code shortens development time and conserves resources.</p> <p>Copying repository contents directly into the project is an adequate solution in some scenarios. However, merging customizations with future upstream changes can be challenging. Submodules are a Git feature designed to address this issue.</p> <p>This guide will show you how to work with Git submodules and provide a list of the most frequently used commands and their options.</p> <p></p> <p>Prerequisites</p> <ul> <li>Git installed (refer to our installation tutorials for\u00a0Windows,\u00a0macOS,\u00a0CentOS 7,\u00a0CentOS 8, and\u00a0Ubuntu).</li> <li>GitHub account or access to another Git repository hosting service.</li> </ul>"},{"location":"programming/github/submodules/#what-is-git-submodule","title":"What is Git Submodule?","text":"<p>A Git submodule is a feature that allows the integration of multiple independent repositories into a single project. A submodule acts as a subdirectory within the main project directory, but the code it contains does not have to be copied directly into the project.</p> <p>Instead, Git creates a reference to the submodule's repository and places it inside the main project's repository. The image below shows a submodule in a repository hosted on GitHub.</p> <p></p>"},{"location":"programming/github/submodules/#why-use-git-submodules","title":"Why Use Git Submodules?","text":"<p>Git submodules are helpful when working with complex projects. For example, developers of microservice-based apps can design and update each microservice separately to preserve independent change histories.</p> <p>Another benefit is that multiple projects can share the code maintained in a single repository. This way, developers ensure consistency between various products using the same feature.</p> <p>The Git command-line interface has a dedicated subcommand for manipulating submodules. Use <code>git submodule</code> to create, update, and manage submodules.</p> <p>The sections below list the most common <code>git submodule</code> commands and their options.</p>"},{"location":"programming/github/submodules/#git-submodule-add","title":"git submodule add","text":"<p>Add a submodule to your main repository using the git submodule add command.</p> <p>To do so:</p> <p>1. Go to the main directory of your project:</p> <pre><code>cd [main-project-directory]\n</code></pre> <p>2. Provide the URL of the submodule's origin repository to the <code>add</code> command:</p> <pre><code>git submodule add [submodule-repository-url]\n</code></pre> <p>The output shows Git cloning the repository into the project's subdirectory.</p> <p></p> <p>To specify the path and name of the directory containing the submodule, add the <code>path</code> argument to the command:</p> <pre><code>git submodule add [submodule-repository-url] [path]\n</code></pre> <p>The following example clones the repository <code>new-submodule</code> into the <code>submodules/example</code> path:</p> <pre><code>git submodule add https://github.com/marko-pnap/new-submodule.git submodules/example\n</code></pre> <p>If you do not specify a path, Git defaults to the repository name.</p> <p>Note: Use the <code>-b</code> option to specify a non-default branch for the submodule.</p>"},{"location":"programming/github/submodules/#git-submodule-init","title":"git submodule init","text":"<p>When cloning the repositories that contain submodules, you must initialize the submodules with the <code>&lt;a href=\"https://phoenixnap.com/kb/git-submodule-init\" target=\"_blank\" rel=\"noreferrer noopener\"&gt;git submodule init&lt;/a&gt;</code> command:</p> <pre><code>git submodule init\n</code></pre> <p>The command registers the paths to submodules within the project tree.</p> <p></p> <p>To initialize a specific submodule, add its path to the command:</p> <pre><code>git submodule init [path]\n</code></pre>"},{"location":"programming/github/submodules/#git-submodule-update","title":"git submodule update","text":"<p>Update the state of the submodules in the project with the following command:</p> <pre><code>git submodule update\n</code></pre> <p>The command clones the missing submodules, fetches any new remote commits, and updates the directory tree.</p> <p></p> <p>Adding the <code>--init</code> flag to the command eliminates the need to run <code>git submodule init</code>. The <code>--recursive</code> option tells Git to check the submodules for nested submodules and update them as well.</p>"},{"location":"programming/github/submodules/#git-submodule-status","title":"git submodule status","text":"<p>Check the status of the submodules by typing:</p> <pre><code>git submodule status\n</code></pre> <p>The command prints out the SHA-1 and the path of each submodule.</p> <p></p> <p>The SHA-1 string can have three different prefixes.</p> <ul> <li>The - prefix marks an uninitialized submodule.</li> <li>The <code>+</code> sign shows that the checked-out submodule commit differs from the state of the original submodule repository.</li> <li>The <code>U</code> prefix alerts to merge conflicts.</li> </ul> <p>Note: No prefix means that the submodule is initialized, synchronized with the origin, and has no conflicts.</p> <p>Use the <code>--recursive</code> option to include nested submodules in the status report.</p>"},{"location":"programming/github/submodules/#git-submodule-foreach","title":"git submodule foreach","text":"<p>The <code>git submodule foreach</code> command allows executing a command on each submodule. Use the following syntax:</p> <pre><code>git submodule foreach '[command]'\n</code></pre> <p>For example, to perform the fetch action on each submodule, type:</p> <pre><code>git submodule foreach 'git fetch'\n</code></pre> <p>The example output shows Git checking submodules and fetching new data for the test-submodule.</p> <p></p>"},{"location":"programming/github/submodules/#git-submodule-deinit","title":"git submodule deinit","text":"<p>Unregister a submodule by typing the following command:</p> <pre><code>git submodule deinit [path]\n</code></pre> <p>Git removes the content of the submodule directory and deletes the section of the <code>.git/config</code> file relevant to the submodule.</p> <p></p> <p>De-initialize a submodule containing local modifications by adding the <code>--force</code> option:</p> <pre><code>git submodule deinit [path] --force\n</code></pre>"},{"location":"programming/github/submodules/#working-with-git-submodules","title":"Working with Git Submodules","text":"<p>In projects that utilize submodules, the workflow must include submodule management. The sections below deal with the most common submodule operations, such as:</p> <ul> <li>Creating submodules from subdirectories.</li> <li>Pulling changes from submodule and project remotes.</li> <li>Merging and publishing submodule changes.</li> <li>Using aliases.</li> </ul>"},{"location":"programming/github/submodules/#joining-a-project-using-submodules_1","title":"Joining a Project Using Submodules","text":"<p>If a project contains submodules, follow the steps below to obtain a full local copy:</p> <p>1. Clone the repository:</p> <pre><code>git clone [repository]\n</code></pre> <p>The output of the <code>git clone</code> command confirms the successful cloning.</p> <p></p> <p>The directory with the cloned repository contains all the files and subdirectories of the original repository. However, the submodule directories are created empty and uninitialized.</p> <p>2. Initialize the submodules and clone their contents by typing:</p> <pre><code>git submodule update --init --recursive\n</code></pre> <p>Git registers the submodules, clones the related files, and checks out the path of each submodule.</p> <p></p> <p>Alternatively, perform all the above actions using a single command by adding the <code>--recursive</code> flag to <code>git clone</code>.</p> <pre><code>git clone --recursive [repository-url]\n</code></pre>"},{"location":"programming/github/submodules/#switching-from-subdirectories-to-submodules","title":"Switching From Subdirectories to Submodules","text":"<p>If you start using submodules in a project that is already in progress, subdirectories containing the relevant code need to be turned into submodules. The simplest way to perform this switch is using the procedure below.</p> <p>1. Recursively copy the contents of the entire project directory to a new location:</p> <pre><code>cp -r [existing-directory] [new-directory]\n</code></pre> <p>2. Go to the new directory and execute the <code>git filter-branch</code> command. Use the <code>--subdirectory-filter</code> option and provide the name of the subdirectory containing files for the new submodule.</p> <pre><code>git filter-branch --subdirectory-filter [subdirectory] -- --all\n</code></pre> <p>The example below uses <code>git filter-branch</code> to remove everything except the contents of the test-dir directory.</p> <p></p> <p>3. Create an empty repository to store the new submodule and copy the URL. If you use GitHub, read how to create a new repository on GitHub.</p> <p>4. On the local system, set the new remote origin for the submodule repository:</p> <pre><code>git remote set-url origin [submodule-repository-url]\n</code></pre> <p>5. Push the changes to remote.</p> <pre><code>git push\n</code></pre> <p>The contents of the submodule directory are uploaded to the repository you created.</p> <p></p> <p>6. Return to the main project's directory and remove the subdirectory containing the code that now belongs to the new submodule.</p> <pre><code>git rm -r [subdirectory]\n</code></pre> <p>7. Commit the changes with:</p> <pre><code>git commit -m \"[message]\"\n</code></pre> <p>8. Push the changes to remote.</p> <pre><code>git push\n</code></pre> <p>9. Use the <code>git submodule add</code> command to add the submodule to the project.</p> <pre><code>git submodule add [new-repository]\n</code></pre>"},{"location":"programming/github/submodules/#pulling-changes-from-the-submodule-remote","title":"Pulling Changes From the Submodule Remote","text":"<p>A frequent usage scenario for submodules is utilizing their code without changing it locally. In this case, updating submodules with new content from their remote origin is performed with the following command:</p> <pre><code>git submodule update --recursive --remote\n</code></pre> <p>The output shows the submodule's remote origin and confirms the successful update.</p> <p></p>"},{"location":"programming/github/submodules/#pulling-changes-from-the-project-remote","title":"Pulling Changes from the Project Remote","text":"<p>If a submodule is changed as a part of the superproject's commit, pull the changes by following the procedure below:</p> <p>1. Execute <code>git pull</code>:</p> <pre><code>git pull [remote-repository] [branch-name]\n</code></pre> <p>2. Update the submodules.</p> <pre><code>git submodule update --init --recursive\n</code></pre> <p>The <code>--init</code> flag in the command above is important in case new submodules have been created in the remote commit.</p>"},{"location":"programming/github/submodules/#publishing-submodule-changes","title":"Publishing Submodule Changes","text":"<p>Changes made on a submodule locally are published similarly to any other repository changes in Git. The only difference is that the command execution takes place in the submodule directory.</p> <p>To publish the changes:</p> <p>1. Go to the directory containing the submodule.</p> <pre><code>cd [submodule-path]\n</code></pre> <p>2. Use <code>git add</code> to choose which files to commit.</p> <pre><code>git add [filename]\n</code></pre> <p>3. Commit the changes.</p> <pre><code>git commit -m \"[message]\"\n</code></pre> <p>4. Push the changes to remote.</p> <pre><code>git push\n</code></pre>"},{"location":"programming/github/submodules/#merging-submodule-changes","title":"Merging Submodule Changes","text":"<p>To merge upstream changes to submodules with the local versions, type:</p> <pre><code>git submodule update --remote --merge\n</code></pre> <p></p> <p>To merge the main project's gitlink changes into the submodules, type:</p> <pre><code>git submodule update --merge\n</code></pre>"},{"location":"programming/github/submodules/#using-aliases","title":"Using Aliases","text":"<p>Most of the commands related to submodule management in Git are long. To simplify frequently performed actions, create aliases for the commonly used commands.</p> <p>The syntax for creating an alias is as follows:</p> <pre><code>git config --global alias.[new-alias] '[original-command]'\n</code></pre> <p>For example, to create the <code>sub-update</code> alias which replaces the <code>submodule update --recursive --remote</code> command, type:</p> <pre><code>git config --global alias.sub-update 'submodule update --recursive --remote'\n</code></pre> <p>Test the new command alias on your system:</p> <pre><code>git sub-update\n</code></pre> <p>The output of the alias is the same as the output of the original command.</p> <p></p>"},{"location":"programming/github/submodules/#submodules-and-branch-switching","title":"Submodules and Branch Switching","text":"<p>Switching to a new submodule branch in Git is performed using the git checkout command. Execute it from the submodule directory, adding the name of the branch you want to switch to:</p> <pre><code>git checkout [branch]\n</code></pre> <p>The output confirms that the new branch is checked out.</p> <p></p> <p>If you are checking out a new branch for the entire project, add the <code>--recurse-submodules</code> flag to properly transfer the state of submodules.</p> <p>Note: With older Git versions that do not support the <code>--recurse-submodules</code> option, use the <code>git submodule update --init --recursive</code> command to restore the state of submodules after the checkout.</p> <p>Conclusion</p> <p>This guide aimed to provide a simple overview of Git submodules, focusing on the most frequently used commands and workflows.</p> <p>If you need a comprehensive general introduction to Git, read our beginner's guide to Git.</p>"},{"location":"tools/ansible/","title":"Ansible","text":""},{"location":"tools/ansible/#ansible","title":"Ansible","text":""},{"location":"tools/ansible/#wat-is-ansible","title":"Wat is Ansible","text":"<p>Ansible is een open-source automatiseringstool waarmee je IT-taken zoals configuratiebeheer, software-implementatie en applicatie-orkestratie eenvoudig kunt uitvoeren. Het werkt agentloos, wat betekent dat je geen extra software hoeft te installeren op de beheerde systemen. Ansible gebruikt YAML-bestanden (playbooks) om instructies te defini\u00ebren en maakt verbinding via SSH om taken uit te voeren. Het is populair vanwege de eenvoudige syntaxis, schaalbaarheid en effici\u00ebntie in het beheren van zowel kleine als grote IT-omgevingen.</p>"},{"location":"tools/ansible/#benodigdheden-voor-het-uitvoeren-van-een-ansible-script-easy","title":"Benodigdheden voor het uitvoeren van een Ansible-script (easy)","text":"<p>Om een Ansible-script te laten draaien, zijn er een aantal essenti\u00eble onderdelen:</p> <pre><code>ansible\n\u00a0 \u251c\u2500\u2500 inventory.txt\n\u00a0 \u2514\u2500\u2500 playbook.yml\n</code></pre> <p>Note</p> <p>De config file van Ansible staat op \"/etc/ansible/ansible.cfg\". Deze word overschreven als je deze in de root folder van je ansible playbook zet.</p>"},{"location":"tools/ansible/#inventory-bestand","title":"Inventory-bestand","text":"<p>Het inventory-bestand bevat een lijst van servers waarop Ansible taken moet uitvoeren. Een eenvoudig voorbeeld:</p> <p>Note</p> <p>Je kan heel makkelijk servers groeperen door deze op te lijsten zoals hieronder bij [webservers]. Hier heb kan je ook nog  [webservers:vars] aan toevoegen en dan gaan alle [webservers] deze variabele gebruiken. Als je dan in je Playbook deze aanspreekt onders \"hosts:\" zullen enkel deze servers aangesproken worden.</p> <p></p><pre><code>[webservers]\nserver1.example.com\nserver2.example.com\n\n[databases]\ndb1.example.com\n</code></pre> Je kunt ook variabelen specificeren per groep of per host."},{"location":"tools/ansible/#playbook-bestand","title":"Playbook-bestand","text":"<p>Een Ansible playbook is een YAML-bestand dat een serie taken beschrijft die uitgevoerd moeten worden op een of meer remote machines. Het wordt gebruikt om geautomatiseerde configuraties, implementaties of beheertaken uit te voeren op servers of andere systemen. Playbooks in Ansible zijn zeer flexibel en kunnen worden gebruikt om allerlei systemen in te stellen, van het installeren van software tot het configureren van netwerkinstellingen of het beheren van beveiligingsinstellingen.</p> <p>Note</p> <p>Een playbook bestaat meestal uit de volgende elementen: - Hosts: Dit is een reeks taken die uitgevoerd moeten worden op een specifieke groep hosts. - Tasks: Dit zijn de specifieke acties die moeten worden uitgevoerd (zoals het installeren van software, het kopi\u00ebren van bestanden, enz.). - Modules: Ansible maakt gebruik van modules die de uitvoering van een taak mogelijk maken, zoals de apt-module voor het installeren van pakketten op Debian-gebaseerde systemen. - Variables: Dit maakt het mogelijk om dynamische configuraties te gebruiken.</p> <p></p><pre><code>---\n- name: Installeer Apache\n  hosts: webservers\n  become: yes\n  tasks:\n    - name: Update pakkettenlijst\n      apt:\n        update_cache: yes\n    - name: Installeer Apache\n      apt:\n        name: apache2\n        state: present\n</code></pre> Ansible uitvoeren <p>Als het inventory- en playbook-bestand klaar zijn, kun je het script uitvoeren met:</p> <pre><code>ansible-playbook -i inventory playbook.yml\n</code></pre>"},{"location":"tools/ansible/#benodigdheden-voor-het-uitvoeren-van-een-ansible-script-advanced","title":"Benodigdheden voor het uitvoeren van een Ansible-script (advanced)","text":"<p>Als je het bovenste onder de knie hebt kunnen we je ansible script wat geavanceerd maken. </p><pre><code>ansible\n\u00a0\u00a0 \u251c\u2500\u2500 ansible.cfg\n\u00a0\u00a0 \u251c\u2500\u2500 files\n\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sudoers_USER\n\u00a0\u00a0 \u251c\u2500\u2500 inventory.txt\n\u00a0\u00a0 \u251c\u2500\u2500 roles\n\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 playbook1\n\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 tasks\n\u00a0\u00a0 \u2502\u00a0\u00a0         \u2514\u2500\u2500 main.yml\n\u00a0\u00a0 \u2514\u2500\u2500 first_playbook.yml\n</code></pre>"},{"location":"tools/ansible/#uitleg-van-de-bestanden-en-mappen","title":"Uitleg van de bestanden en mappen:","text":"<ul> <li>files/: Bevat bestanden die nodig zijn voor de configuratie of implementatie.</li> <li>roles/: Hierin kunnen Ansible-rollen worden opgeslagen, die taken groeperen per functie.</li> <li>ansible.cfg: De configuratie van Ansible, waarin instellingen zoals de locatie van het inventory-bestand en logbestanden staan.</li> <li>inventory.md: Bevat een lijst van de servers en hun groepen die door Ansible worden beheerd.</li> <li>first_playbook.yml: Een test-playbook om de basisfunctionaliteit van Ansible te controleren.</li> </ul> Configuratie bestanden <p>Warning</p> <p>Dit is een voorbeeld!!</p> ansible.cfgsudoers_USERinventory.mdmain.yamlfirst_playbook.yamlreadme.md <pre><code>    [defaults]\n    interpreter_python=auto_silent\n    host_key_checking=false\n\n    INVENTORY = inventory.txt\n</code></pre> <pre><code>    USER ALL=(ALL) NOPASSWD: ALL\n</code></pre> <pre><code>    [docker]\n    10.18.0.20 #network\n    10.18.0.21 #Media\n    10.18.0.25 #test docker\n\n    [docker:vars]\n    ansible_connection=ssh  \n    ansible_user=USER   \n    ansible_ssh_private_key_file=~/.ssh/id_ansible\n</code></pre> <pre><code>    ---\n    - name: install sudo package\n    become: true\n    apt:\n        name: sudo \n        update_cache: yes\n        cache_valid_time: 3600\n        state: latest\n\n    - name: create USER user\n    user: \n        name: USER\n        shell: '/bin/bash'\n\n    - name: add USER to sudoers\n    become: true\n    copy:\n        src: sudoers_USER\n        dest: /etc/sudoers.d/USER\n        owner: root\n        group: root\n        mode: 0440\n\n    - name: Copy SSH public key to remote host\n    ansible.builtin.authorized_key:\n        user: cowarol\n        key: \"{{ lookup('file', '~/.ssh/id_ansible.pub') }}\"\n        state: present\n\n    - name: Copy SSH keys\n    become: true\n    ansible.builtin.copy:\n        src: \"/home/USER/.ssh/{{ item.file }}\"\n        dest: \"/home/USER/.ssh/{{ item.file }}\"\n        owner: cowarol\n        group: cowarol\n        mode: \"{{ item.mode }}\"\n    loop:\n        - { file: 'id_ed25519', mode: '0600' }\n        - { file: 'id_ed25519.pub', mode: '0644' }\n\n\n    - name: Ensure SSH agent is running\n    ansible.builtin.shell: eval $(ssh-agent)\n    changed_when: false\n\n    - name: Test GitHub SSH connectivity\n    ansible.builtin.command: ssh -T git@github.com\n    register: ssh_test\n    failed_when: \n        - ssh_test.rc != 1\n        - '\"successfully authenticated\" not in ssh_test.stderr'\n    changed_when: false\n</code></pre> <pre><code>    ---\n    - name: docker Playbook\n    hosts: docker\n    gather_facts: true\n    become: false\n    roles:\n        - install_ssh-ansible\n</code></pre>"},{"location":"tools/ansible/#ansible_1","title":"Ansible","text":""},{"location":"tools/ansible/#installeer-ansible","title":"Installeer Ansible","text":"<p>Voor je begint zijn er een aandere stappen die je moet doorlopen. Waaronder het installeren van Ansible </p><pre><code>sudo add-apt-repository --yes --update ppa:ansible/ansible\nsudo apt install ansible -y\nansible --version\n</code></pre>"},{"location":"tools/ansible/#voor-de-het-target-toestel-installeer-je-python","title":"Voor de het target toestel installeer je python","text":"<p>Als python aan de andere kant niet is geinstalleerd zal ansible ook niet werken. </p><pre><code>sudo apt install python3\nsudo apt install python3-pip\n</code></pre>"},{"location":"tools/ansible/#test-de-connectie","title":"Test de connectie","text":"<p>Voor we verder gaan willen we weten of de connectie wel werkt. Dat doe je door volgende commando uit te voeren.</p> <p>[!NOTE] sshpass is nodig voor directe ansible commando</p> <pre><code>sudo apt-get install sshpass\nansible all -i \"IP,\" -m ping -u USER -k\n</code></pre>"},{"location":"tools/ansible/#installeer-ssh-keys","title":"installeer ssh keys","text":"<p>Je kan ansible laten werken zonder ssh keys. Met ssh keys is dit gemakkelijker en gebruiks vriendelijker.</p>"},{"location":"tools/ansible/#installeer-een-ssh-key-voor-ansible","title":"Installeer een ssh key voor ansible","text":"<p>Dit doen we om een ssh key voor ansible te reserveren. </p><pre><code>ssh-keygen -t ed25519 -C \"jouw_email@voorbeeld.com\"\n</code></pre> Zet zeker volgende path. \"~/.ssh/id_ansible\" <pre><code>eval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ansible\ncat ~/.ssh/id_ansible.pub\n</code></pre> <p>[!NOTE] Als je in verdere stappen problemen krijgt met het remote connectie maken voer dan volgende commandie uit</p> <pre><code>ssh-copy-id -i ~/.ssh/id_ansible.pub username@remote-host\n</code></pre>"},{"location":"tools/ansible/#github-ssh-key","title":"Github ssh key","text":"<p>Als je met github werkt raad ik aan een key aan te maken en de public in github te steken Deze key word ook meegegeven aan alle servers waar je ansible op uitvoert.</p> <pre><code>ssh-keygen -t ed25519 -C \"jouw_email@voorbeeld.com\"\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519\ncat ~/.ssh/id_ed25519.pub\n</code></pre>"},{"location":"tools/ansible/#github-test","title":"Github test","text":"<p>Test even of de connectie met Github werkt voor je verdergaat. Als dit failt zullen alle toestellen waar je deze key opzet ook failen. </p><pre><code>ssh -T git@github.com\n</code></pre>"},{"location":"tools/ansible/#test-het-script","title":"Test het script","text":"<p>Eerst en vooral zul je dit commano moeten losslaten omdat je nog geen connectie hebt met de nodes. Dit Commandoe vraagt achter het gebruikers wachtwoord en het root wachwoord</p> <p>[!warning] Voor je verdergaat ga je naar de inventory.md file en pas je jouw waardes aan. De test_playbook spreekt de [docker] aan. </p><pre><code>ansible-playbook  first_playbook.yml -u USER -k -K\n</code></pre> Als Voorig scipt succesvol is uitgevoerd zou je vanaf nu je script kunnen starten met <pre><code>ansible-playbook  first_playbook.yml\n</code></pre>"},{"location":"tools/bitwarden/","title":"Bitwarden","text":""},{"location":"tools/bitwarden/#bitwarden","title":"Bitwarden","text":"<p>TODO: WIP</p>"},{"location":"tools/chocolatey/","title":"Chocolatey","text":""},{"location":"tools/git/","title":"Git","text":""},{"location":"tools/git/#git","title":"Git","text":"<p>Git is an open source version control system, which supports your development tasks, especially in distributed code projects.</p>"},{"location":"tools/git/#installation","title":"Installation","text":"<p>Git can be easily installed on Linux systems with the available package managers. E.g. for Debian based systems by <code>apt install git</code>.</p> <p>For other systems, see the download page of Git here.</p>"},{"location":"tools/git/#configuration","title":"Configuration","text":"<p>Git can be configured by the CLI using the <code>git config</code> command. For first configuration it is necessary to configure at least the parameters <code>user.name</code> and <code>user.email</code>. This can be done by the following commands:</p> <pre><code>git config --global user.name \"MyFancyUser\"\n</code></pre> <pre><code>git config --global user.email \"developer@mydomain.com\"\n</code></pre>"},{"location":"tools/git/#using-git","title":"Using Git","text":"<p>The following commands can be helpful for working with <code>git</code>.</p> git command Comment <code>git init</code> Initialize a directory as git managed repository <code>git clone &lt;repo_url&gt;</code> Clone a remote repository to your local client <code>git status</code> Shows uncommited changes, new files etc. <code>git add &lt;wildcard_or_filename&gt;</code> Stage an updated / new file to the next commit <code>git rm &lt;wildcard_or_filename&gt;</code> Remove a file and stage the removal for the next commit <code>git commit -m \"&lt;commit message\"&gt;</code> Commit staged changes under a new commit <code>git commit</code> Will open an editor to write more descriptive commit messages. See here for a guide on good commit messages <code>git checkout &lt;branch_name&gt;</code> Switch to another branch <code>git branch</code> Shows a list of existing branches <code>git branch &lt;branch_name&gt;</code> Creates a new branch (from the currently checked out branch) <code>git merge &lt;branch_name&gt;</code> Merge changes from <code>branch_name</code> to the currently checked out branch <code>git push</code> Push commited changes to the remote repository <code>git pull</code> Pull current state from the remote repository to your local repo"},{"location":"tools/git/#working-with-git-flow","title":"Working with git-flow","text":"<p>Git-flow assists you by combining multiple steps of <code>git</code> commands to one <code>git-flow</code> command which will do a workflow of steps. Although <code>git-flow</code> makes live easier in some cases, it makes it also more complex sometimes and you need to execute some steps before or after using a <code>git-flow</code> command as regular <code>git</code> command. (See below)</p> <p>As an example, here is the comparison between the regular <code>git</code> commands and the appropriate <code>git-flow</code> command for creating a release.</p> git-flow command git command <code>git-flow feature start &lt;feature_name&gt;</code> <code>git checkout -b feature/&lt;feature_name&gt; develop</code> <code>git-flow feature finish &lt;feature_name&gt; [--squash]</code> <code>git checkout develop</code> <code>git merge [--squash] --no-ff feature/&lt;feature_name&gt;</code> <code>git branch -d feature/&lt;feature_name&gt;</code> <p>Another <code>git-flow</code> cheat sheet can be found here.</p>"},{"location":"tools/git/#using-git-crypt","title":"Using git-crypt","text":"<p>Having secret or sensitive information in your git repository is never a good choice. But sometimes it's necessary. Never push unencrypted data to your remote repository.</p> <p>Git-crypt is a transparent encryption tool that works seamless with your Git repository. All sensitive information is encrypted before pushed to the remote repository. Once you've unlocked the repository locally, all data will be decrypted automatically when pulling from the remote repo. This makes development with encrypted data effortless.</p> <p>To install git-crypt, you can use your package manager of choice (e.g. <code>apt</code>):</p> <pre><code>sudo apt install git-crypt\n</code></pre> <p>To initialize a new repository with git-crypt, you can use <code>git-crypt init</code> when located in the repository directory. An already encrypted git repository can be unlocked by <code>git-crypt unlock</code>. This requires you to have either the repository encryption key in your GPG keychain, or that your private GPG key has been added to the allowed keys in the repository. For more details, see the links below.</p> <p>For more information, check out the official Github repository here. A tutorial on git-crypt can be found here.</p>"},{"location":"tools/gparted/","title":"Gparted","text":""},{"location":"tools/gparted/#gparted","title":"Gparted","text":"<p>Gparted is een programma dat je kunt gebruiken om je schijfpartities te beheren. Een schijfpartitie is een deel van je harde schijf waarop je bestanden en besturingssystemen kunt opslaan. Met Gparted kun je verschillende acties uitvoeren met je partities, zoals:</p> <ul> <li>Een partitietabel maken op een schijfapparaat. Een partitietabel is een structuur die informatie bevat over de grootte, het type en de locatie van de partities op een schijf.</li> <li>Partitievlaggen in- en uitschakelen, zoals boot en hidden. Partitievlaggen zijn kenmerken die bepalen hoe een partitie wordt behandeld door het besturingssysteem of de bootloader.</li> <li>Partities maken, verwijderen, vergroten, verkleinen, verplaatsen, controleren, labelen, kopi\u00ebren en plakken. Dit stelt je in staat om de indeling van je schijf aan te passen aan je behoeften en om ruimte vrij te maken of te gebruiken voor nieuwe besturingssystemen of data.</li> <li>Partities formatteren met verschillende bestandssystemen. Een bestandssysteem is een manier om bestanden te organiseren en op te slaan op een partitie. Sommige voorbeelden van bestandssystemen zijn NTFS voor Windows, ext4 voor Linux en FAT32 voor compatibiliteit met meerdere systemen.</li> <li>Een partitie een naam of een label geven. Dit helpt je om je partities te identificeren en te onderscheiden van elkaar.</li> <li>Een partitie een nieuw UUID geven. Een UUID is een unieke identificatiecode die elke partitie heeft. Het wordt gebruikt om partities te herkennen en te koppelen aan hun mountpunten of bootconfiguraties.</li> <li>Partities controleren op fouten of beschadigingen. Dit kan helpen om problemen met je schijf of je bestanden op te lossen of te voorkomen.</li> <li>Partitievlaggen beheren, zoals boot, lvm of raid. Partitievlaggen zijn kenmerken die bepalen hoe een partitie wordt behandeld door het besturingssysteem of de bootloader. Sommige vlaggen zijn nodig voor speciale functies, zoals het opstarten van een systeem, het gebruiken van logische volumes of het maken van een RAID-array.</li> </ul> <p>Om Gparted te gebruiken, heb je een live CD/USB nodig die Gparted bevat. Je kunt deze downloaden van de offici\u00eble website van Gparted en branden op een CD of USB-stick. Vervolgens kun je je computer opstarten vanaf de live CD/USB en Gparted starten. Je zult dan een venster zien met een lijst van je schijfapparaten en hun partities. Je kunt dan met de rechtermuisknop op een partitie klikken om de beschikbare acties te zien. Je kunt ook het menu bovenaan gebruiken om andere opties te selecteren.</p> <p>Als je een actie uitvoert met Gparted, wordt deze toegevoegd aan de wachtrij van bewerkingen. Dit betekent dat de actie nog niet wordt toegepast op je schijf, maar alleen wordt onthouden door Gparted. Je kunt meerdere acties toevoegen aan de wachtrij voordat je ze toepast. Je kunt ook de laatste actie ongedaan maken of alle acties wissen als je van gedachten verandert. Om de acties toe te passen op je schijf, moet je op de knop \"Toepassen\" klikken. Dit kan enige tijd duren, afhankelijk van de grootte en het aantal van de betrokken partities.</p>"},{"location":"tools/nmap/","title":"NMap","text":""},{"location":"tools/openssh/","title":"OpenSSH Cheat-Sheet","text":""},{"location":"tools/openssh/#openssh-cheat-sheet","title":"OpenSSH Cheat-Sheet","text":""},{"location":"tools/openssh/#known-hosts","title":"Known Hosts","text":"<p>Remove Entry from the Known-Hosts File. </p><pre><code>ssh-keygen -R hostname\n</code></pre>"},{"location":"tools/openssh/#using-the-ssh-config-file","title":"Using the SSH Config File","text":"<p>If you are regularly connecting to multiple remote systems over SSH, you can configure your remote servers with the <code>.ssh/config</code> file.</p> <p>Example:* </p><pre><code>Host dev\n    HostName dev.your-domain\n    User xcad\n    Port 7654\n    IdentityFile ~/.ssh/targaryen.key\n\nHost *\n    User root\n    Compression yes\n</code></pre> <p>Connect to a host (like dev , eg.) with <code>ssh dev</code>.</p>"},{"location":"tools/openssl/","title":"OpenSSL","text":""},{"location":"tools/starship/","title":"Starship Prompt","text":""},{"location":"tools/starship/#starship-prompt","title":"Starship Prompt","text":"<p>Starship is a minimal, blazing-fast, and infinitely customizable prompt for any shell. </p> <p>Project Homepage: Starship: Cross-Shell Prompt Documentation: Configuration | Starship</p>"},{"location":"tools/starship/#installation","title":"Installation","text":""},{"location":"tools/starship/#linux","title":"Linux","text":"<ol> <li>Install the latest version for your system: <pre><code>curl -sS https://starship.rs/install.sh | sh\n</code></pre></li> <li>Add the following to the end of <code>~/.bashrc</code> or <code>~/.zshrc</code>: <pre><code>eval \"$(starship init bash)\"\n# -- or --\neval \"$(starship init zsh)\"\n</code></pre></li> </ol>"},{"location":"tools/terraform/","title":"Terraform","text":""},{"location":"tools/terraform/#terraform","title":"Terraform","text":"<p>Terraform is a free and open-source infrastructure as code automation tool, to provision, change, and version resources on any environment.</p> <p>Project Homepage: Terraform by HashiCorp Documentation: Documentation | Terraform by HashiCorp TF Registry: Terraform Registry</p>"},{"location":"tools/terraform/#format-and-validate","title":"Format and Validate","text":"COMMAND DESCRIPTION <code>terraform fmt</code> Reformat your configuration in the standard style <code>terraform validate</code> Check whether the configuration is valid ## Initialize Working Directory COMMAND DESCRIPTION --- --- <code>terraform init</code> Prepare your working directory for other commands ## Plan, Deploy and Cleanup COMMAND DESCRIPTION --- --- <code>terraform apply --auto-approve</code> Create or update infrastructure without confirmation prompt <code>terraform destroy --auto-approve</code> Destroy previously-created infrastructure without confirmation prompt <code>terraform plan -out plan.out</code> Output the deployment plan to plan.out <code>terraform apply plan.out</code> Use the plan.out to deploy infrastructure <code>terraform plan -destroy</code> Outputs a destroy plan <code>terraform apply -target=aws_instance.myinstance</code> Only apply/deploy changes to targeted resource <code>terraform apply -var myregion=us-east-1</code> Pass a variable via CLI while applying a configuration <code>terraform apply -lock=true</code> Lock the state file so it can't be modified <code>terraform apply refresh=false</code> Do not reconcile state file with real-world resources <code>terraform apply --parallelism=5</code> Number of simultaneous resource operations <code>terraform refresh</code> Reconcile the state in Terraform state file with real-world resources <code>terraform providers</code> Get informatino about providers used in the current configuration ## Workspaces COMMAND DESCRIPTION --- --- <code>terraform workspace new myworkspace</code> Create a new workspace <code>terraform workspace select default</code> Change to a workspace <code>terraform workspace list</code> List all workspaces ## State Manipulation COMMAND DESCRIPTION --- --- <code>terraform state show aws_instance.myinstance</code> Show details stored in the Terraform state file <code>terraform state pull &gt; terraform.tfstate</code> Output Terraform state to a file <code>terraform state mv aws_iam_role.my_ssm_role module.mymodule</code> Move a resource tracked via state to different module <code>terraform state replace-provider hashicorp/aws registry.custom.com/aws</code> Replace an existing provider with another <code>terraform state list</code> List all resources tracked in the Terraform state file <code>terraform state rm aws_instance.myinstance</code> Unmanage a resource, delete it from the Terraform state file ## Import and Outputs COMMAND DESCRIPTION --- --- <code>terraform import resourcetype.myresource &lt;id&gt;</code> Import a Resource <code>terraform output</code> List all outputs <code>terraform output &lt;output&gt;</code> List a specific output <code>terraform output -json</code> List all outputs in JSON format ## Terraform Cloud COMMAND DESCRIPTION --- --- <code>terraform login</code> Login to Terraform Cloud with an API token <code>terraform logou</code> Logout from Terraform Cloud"},{"location":"tools/terraform/#import-existing-resources","title":"Import existing resources","text":""},{"location":"tools/vagrant/","title":"Vagrant Cheat-Sheet","text":""},{"location":"tools/vagrant/#vagrant-cheat-sheet","title":"Vagrant Cheat-Sheet","text":""},{"location":"tools/vagrant/#general-management","title":"General Management","text":"COMMAND DESCRIPTION <code>vagrant status</code> Outputs status of the vagrant machine <code>vagrant global-status</code> Outputs status of all vagrant machines <code>vagrant global-status --prune</code> Same as above, but prunes invalid entries"},{"location":"tools/vagrant/#managing-vms","title":"Managing VMs","text":"COMMAND DESCRIPTION <code>vagrant init</code> Initialize Vagrant with a Vagrantfile and ./.vagrant directory, using no specified base image. Before you can do vagrant up, you'll need to specify a base image in the Vagrantfile. <code>vagrant up</code> Starts vagrant environment (also provisions only on the FIRST vagrant up) <code>vagrant halt</code> Stops the vagrant machine <code>vagrant suspend</code> Suspends a virtual machine (remembers state) <code>vagrant resume</code> Resume a suspended machine (vagrant up works just fine for this as well) <code>vagrant ssh</code> Sonnects to machine via SSH <code>vagrant ssh &lt;BOXNAME&gt;</code> If you give your box a name in your Vagrantfile, you can ssh into it with boxname. Works from any directory. <code>vagrant destroy</code> Stops and deletes all traces of the vagrant machine <code>vagrant destroy -f</code> Same as above, without confirmation"},{"location":"tools/vagrant/#provisioning-vms","title":"Provisioning VMs","text":"COMMAND DESCRIPTION <code>vagrant provision</code> Forces reprovisioning of the vagrant machine <code>vagrant provision --debug</code> Use the debug flag to increase the verbosity of the output <code>vagrant up --provision | tee provision.log</code> Runs <code>vagrant up</code>, forces provisioning and logs all output to a file"},{"location":"tools/vagrant/#manage-boxes","title":"Manage Boxes","text":"COMMAND DESCRIPTION <code>vagrant box list</code> See a list of all installed boxes on your computer <code>vagrant box add &lt;BOXNAME&gt; &lt;BOXURL&gt;</code> Download a box image to your computer <code>vagrant box outdated</code> Check for updates vagrant box update <code>vagrant box remove &lt;BOXNAME&gt;</code> Deletes a box from the machine <code>vagrant package</code> Packages a running virtualbox env in a reusable box"},{"location":"tools/vagrant/#vagrant-with-wsl2","title":"Vagrant with WSL2","text":"<p>Vagrant is able to run inside your Windows Subsystem for Linux environment. A tutorial on how to install and use it with your Windows installed Virtualbox can be found here.</p>"},{"location":"tools/vscode/","title":"VSCode (Visual Studio Code)","text":""},{"location":"tools/vscode/#vscode-visual-studio-code","title":"VSCode (Visual Studio Code)","text":"<p>VSCode Shortcuts on MacOS ([[vscode-macos-shortcuts]])</p>"},{"location":"tools/wsl/","title":"WSL Cheat-Sheet","text":""},{"location":"tools/wsl/#wsl-cheat-sheet","title":"WSL Cheat-Sheet","text":""},{"location":"tools/wsl/#backup-and-restore-wsl","title":"Backup and Restore WSL","text":""},{"location":"tools/wsl/#listing-running-distros","title":"Listing Running Distros","text":"<pre><code>wsl --list --verbose\n</code></pre>"},{"location":"tools/wsl/#startingrestarting-a-distro","title":"Starting/Restarting a Distro","text":"<pre><code>wsl --distribution DISTRO-NAME\n</code></pre>"},{"location":"tools/wsl/#terminate-a-running-distro","title":"Terminate a Running Distro","text":"<pre><code>wsl --t DISTRO-NAME\n</code></pre>"},{"location":"tools/wsl/#terminate-all-running-distros-and-wsl-process","title":"Terminate All Running Distros and WSL process","text":"<pre><code>wsl --shutdown\n</code></pre>"},{"location":"tools/wsl/#backup-a-wsl-distro","title":"Backup a WSL Distro","text":"<pre><code>wsl --export (distribution) (filename.tar)\n</code></pre>"},{"location":"tools/wsl/#restore-a-wsl-distro-from-backup","title":"Restore a WSL Distro from Backup","text":"<pre><code>wsl --import (distribution) (install location) (file location and filename)\n</code></pre>"},{"location":"tools/wsl/#symbolic-links","title":"Symbolic Links","text":""},{"location":"tools/wsl/#link-ssh-folder","title":"Link .ssh folder","text":"<pre><code>sudo ln -s /mnt/c/Users/lempa/.ssh ~/.ssh\n</code></pre>"},{"location":"tools/wsl/#link-kube-folder","title":"Link .kube folder","text":"<pre><code>sudo ln -s /mnt/c/Users/lempa/.ssh ~/.ssh\n</code></pre>"},{"location":"tools/wsl/#file-permissions","title":"File Permissions","text":"<p>Advanced settings configuration in WSL: WSL Config Parameters</p> <p>Example wsl.conf </p><pre><code>[automount]\nenabled = true\noptions = \"metadata,uid=1000,gid=1000,umask=077,fmask=11,case=off\"\nmountFsTab = true\n\n[interop]\nenabled = false\nappendWindowsPath = false\n</code></pre>"},{"location":"tools/wsl/#networking","title":"Networking","text":""},{"location":"tools/wsl/#port-forwarding","title":"Port Forwarding","text":"<p>Find IP Address </p><pre><code>bash.exe -c \"ifconfig eth0 | grep 'inet '\"\n</code></pre> <p>Add PortForwarding </p><pre><code>$port = 8080\n$remoteaddr = 0.0.0.0\n\nnetsh interface portproxy add v4tov4 listenport=$port connectport=$port connectaddress=$remoteaddr\n\nnetsh advfirewall firewall add rule name=$port dir=in action=allow protocol=TCP localport=$port\n</code></pre> <p>Delete PortForwarding </p><pre><code>$port = 8080\n\nnetsh interface portproxy delete v4tov4 listenport=$port\nnetsh advfirewall firewall delete rule name=$port\n</code></pre> <p>Show PortForwardings </p><pre><code>netsh interface portproxy show v4tov4\n</code></pre>"},{"location":"tools/wsl/#linux-desktop-in-wsl2","title":"Linux desktop in WSL2","text":"<p>With WSL2 it's possible to install and run a Linux desktop environment (XFCE). A tutorial on how to implement that, can be found here.</p>"},{"location":"tools/dotfiles/dotfiles/","title":"Dotfiles","text":""},{"location":"tools/dotfiles/ohmyzsh/","title":"Oh My ZSH","text":""},{"location":"tools/dotfiles/ohmyzsh/#zsh","title":"Zsh?","text":"<p>Oh My Zsh is a framework for Zsh, the Z shell.</p> <ul> <li>In order for Oh My Zsh to work, Zsh must be installed.</li> <li>Please run <code>zsh --version</code> to confirm.</li> <li>Expected result: <code>zsh 5.0.8</code> or more recent</li> <li>Additionally, Zsh should be set as your default shell.</li> <li>Please run <code>echo $SHELL</code> from a new terminal to confirm.</li> <li>Expected result: <code>/usr/bin/zsh</code> or similar</li> </ul>"},{"location":"tools/dotfiles/ohmyzsh/#install-and-set-up-zsh-as-default","title":"Install and set up zsh as default","text":"<p>If necessary, follow these steps to install Zsh:</p> <ol> <li> <p>There are two main ways to install Zsh:</p> </li> <li> <p>With the package manager of your choice, e.g. <code>sudo apt install zsh</code> (see below for more examples)</p> </li> <li> <p>From source, following the instructions from the Zsh FAQ.</p> </li> <li> <p>Verify installation by running <code>zsh --version</code>. Expected result: <code>zsh 5.0.8</code> or more recent.</p> </li> <li> <p>Make it your default shell: <code>chsh -s $(which zsh)</code> or use <code>sudo lchsh $USER</code> if you are on Fedora.</p> </li> <li> <p>Note that this will not work if Zsh is not in your authorized shells list (<code>/etc/shells</code>)     or if you don't have permission to use <code>chsh</code>. If that's the case you'll need to use a different procedure.</p> <ul> <li>If you use <code>lchsh</code> you need to type <code>/bin/zsh</code> to make it your default shell.</li> </ul> </li> <li> <p>Log out and log back in again to use your new default shell.</p> </li> <li> <p>Test that it worked with <code>echo $SHELL</code>. Expected result: <code>/bin/zsh</code> or similar.</p> </li> <li> <p>Test with <code>$SHELL --version</code>. Expected result: 'zsh 5.8' or similar</p> </li> </ol>"},{"location":"tools/dotfiles/ohmyzsh/#how-to-install-zsh-on-many-platforms","title":"How to install zsh on many platforms","text":""},{"location":"tools/dotfiles/ohmyzsh/#macos","title":"macOS","text":"<p>Try <code>zsh --version</code> before installing it from Homebrew. Preferably newer than or equal to <code>5.0.8</code>.</p> <pre><code>brew install zsh\n</code></pre> <p>To set zsh as your default shell, execute the following assuming a default install of Homebrew</p> <ul> <li>Recent macOS versions:</li> </ul> <p>For m1 macs:</p> <pre><code>chsh -s /opt/homebrew/bin/zsh\n</code></pre> <p>For intel macs:</p> <pre><code>chsh -s /usr/local/bin/zsh\n</code></pre> <ul> <li>macOS High Sierra and older:</li> </ul> <pre><code>chsh -s /bin/zsh\n</code></pre> <p>Assuming you have Homebrew installed. If not, most versions of macOS ship zsh by default, but it's normally an older version.  Alternatively, you may also use MacPorts</p> <pre><code>sudo port install zsh zsh-completions\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#ubuntu-debian-derivatives-windows-10-wsl-native-linux-kernel-with-windows-10-build-1903","title":"Ubuntu, Debian &amp; derivatives (Windows 10 WSL | Native Linux kernel with Windows 10 build 1903)","text":"<pre><code>apt install zsh\n</code></pre> <p>If you don't have <code>apt</code>, the recommended package manager for end users [1] [2] [3] [4] , you can try <code>apt-get</code> or <code>aptitude</code>.</p> <p>Other distributions that apply include: Linux Mint, elementary OS, Zorin OS, Raspbian, MX Linux, Deepin.</p>"},{"location":"tools/dotfiles/ohmyzsh/#opensuse","title":"OpenSUSE","text":"<pre><code>zypper install zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#arch-linux-or-manjaro","title":"Arch Linux or Manjaro","text":"<pre><code>pacman -S zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#void-linux","title":"Void Linux","text":"<pre><code>xbps-install zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#fedora","title":"Fedora","text":"<pre><code>dnf install zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#openbsd","title":"OpenBSD","text":"<p>To install the package:</p> <pre><code>pkg_add zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#freebsd","title":"FreeBSD","text":"<p>To install the package:</p> <pre><code>pkg install zsh\n</code></pre> <p>To install the port:</p> <pre><code>cd /usr/ports/shells/zsh/ &amp;&amp; make install clean\n</code></pre> <p>To reduce memory usage, optionally enable zsh-mem options with </p> <pre><code>make config\n</code></pre> <p>before running \"make install\".</p>"},{"location":"tools/dotfiles/ohmyzsh/#centosrhel","title":"Centos/RHEL","text":"<pre><code>sudo yum update &amp;&amp; sudo yum -y install zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#cygwin","title":"Cygwin","text":"<p>Install the zsh package using the installer. Unfortunately Cygwin doesn't have a standard command line interface. You could, however, setup apt-cyg and install zsh as follows:</p> <pre><code>apt-cyg install zsh\n</code></pre> <p>The easiest way to change the default shell is to set your SHELL user environment variable. Search for \"Edit Environment variables for your account\" to bring up the environment variables window, create a new variable named \"SHELL\" and give it the value \"/usr/bin/zsh/\".</p> <p>Alternatively: Open Cygwin (in BASH) then type:</p> <pre><code>sudo nano ~/.bashrc\n</code></pre> <p>Once the .bashrc file is open, add this line to the very top:</p> <pre><code>exec zsh\n</code></pre> <p>Close and save the file. Close and reopen Cygwin. It will execute the command every time you load the terminal and run your zsh shell.</p>"},{"location":"tools/dotfiles/ohmyzsh/#solus","title":"Solus","text":"<pre><code>eopkg it zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#funtoogentoo","title":"Funtoo/Gentoo","text":"<pre><code>emerge app-shells/zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#alpine-linux","title":"Alpine Linux","text":"<pre><code>apk add zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#msys2","title":"MSYS2","text":"<pre><code>pacman -S zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#termux-android","title":"Termux (Android)","text":"<p>Termux is an terminal emulator for Android but has modern feature like Debian and Ubuntu (Termux has Bash shell and Busybox GNU-like programs). For the package manager, Termux using an Debian/Ubuntu package manager, APT. To install the package, run this command:</p> <pre><code>pkg install zsh\n</code></pre> <p>The command looks like FreeBSD package manager (<code>pkg</code>). Or you can run this command:</p> <pre><code>apt update &amp;&amp; apt upgrade\napt install zsh\n</code></pre> <p>To set zsh as your default shell, run this command:</p> <pre><code>chsh -s zsh\n</code></pre>"},{"location":"tools/dotfiles/ohmyzsh/#oh-my-zsh","title":"Oh My Zsh","text":"<p>Oh My Zsh is an open source, community-driven framework for managing your zsh configuration.</p> <ul> <li>You'll need <code>zsh</code> to install Oh My Zsh. Run <code>zsh --version</code> to check if you have it:</li> </ul> <pre><code>$ zsh --version\nzsh 5.8 (x86_64-ubuntu-linux-gnu)\n</code></pre> <ul> <li>If you see <code>command not found</code> you don't have zsh installed. See Installing Zsh for instructions.</li> <li>Once you have zsh, you can install Oh My Zsh by simply running one of these commands:</li> </ul> Method Command curl <code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"</code> wget <code>sh -c \"$(wget -O- https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"</code> fetch <code>sh -c \"$(fetch -o - https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"</code> <p>NOTE: the installer will rename an existing <code>.zshrc</code> file to <code>.zshrc.pre-oh-my-zsh</code>.</p>"},{"location":"tools/dotfiles/ohmyzsh/#cheatsheet","title":"Cheatsheet","text":"<p>Quick reference:</p> <ul> <li>Oh My Zsh's Command-Line Interface (CLI): <code>omz</code>. Run <code>omz --help</code> for available commands.</li> <li>To update Oh My Zsh: <code>omz update</code>.</li> <li>To uninstall it: <code>uninstall_oh_my_zsh</code>.</li> <li>To apply changes made to <code>.zshrc</code>: <code>omz reload</code> (this just runs <code>exec zsh</code>).   Do NOT run <code>source ~/.zshrc</code>.</li> </ul>"},{"location":"tools/dotfiles/ohmyzsh/#commands","title":"Commands","text":"Command Description <code>alias</code> List all aliases <code>mkcd</code> Create a new directory and change to it, will create intermediate directories as required. <code>take</code> Like <code>mkcd</code>, but also knows how to handle remote URLs. When given an argument that looks like a URL (something that ends in <code>.git</code> or <code>.tar.(gz\\|bz2\\|xz)</code>), download the remote resource and extract it (if necessary) into the current directory. Then change to the newly extracted/downloaded/cloned directory. <code>zsh_stats</code> Get a list of the top 20 commands and how many times they have been run."},{"location":"tools/dotfiles/ohmyzsh/#directory","title":"Directory","text":"Alias Command <code>md</code> <code>mkdir -p</code> <code>rd</code> <code>rmdir</code> <code>cd</code> / <code>~</code> <code>cd</code> to your home directory <code>..</code> <code>cd ..</code> <code>...</code> <code>cd ..</code> <code>....</code> <code>cd ..</code> <code>.....</code> <code>cd ..</code> <code>/</code> <code>cd /</code> <code>d</code> <code>dirs -v</code> (lists last visited directories) <code>cd +n</code> Switch to directory number <code>n</code> <code>-</code> <code>cd</code> to last visited directory <code>1</code> <code>cd -1</code> <code>2</code> <code>cd -2</code> <code>3</code> <code>cd -3</code> <code>4</code> <code>cd -4</code> <code>5</code> <code>cd -5</code> <code>6</code> <code>cd -6</code> <code>7</code> <code>cd -7</code> <code>8</code> <code>cd -8</code> <code>9</code> <code>cd -9</code>"},{"location":"tools/usb_installation_media/balena-etcher/","title":"Balena Etcher","text":""},{"location":"tools/usb_installation_media/balena-etcher/#balena-etcher","title":"Balena Etcher","text":""},{"location":"tools/usb_installation_media/balena-etcher/#wat-is-balena-etcher","title":"Wat is Balena Etcher?","text":"<p>Balena Etcher is een gratis en open-source hulpprogramma dat wordt gebruikt voor het schrijven van afbeeldingsbestanden zoals .iso- en .img-bestanden, evenals gecomprimeerde mappen naar opslagmedia om live SD-kaarten en USB-flashstations te maken.</p> <p></p>"},{"location":"tools/usb_installation_media/balena-etcher/#links","title":"Links","text":"<p>Website</p>"},{"location":"tools/usb_installation_media/rpi-imager/","title":"Raspberry Pi Imager","text":""},{"location":"tools/usb_installation_media/rpi-imager/#raspberry-pi-imager","title":"Raspberry Pi Imager","text":""},{"location":"tools/usb_installation_media/rpi-imager/#wat-is-raspberry-pi-imager","title":"Wat is Raspberry Pi Imager?","text":"<p>Raspberry Pi Imager is een hulpprogramma waarmee je eenvoudig en snel een besturingssysteem naar een microSD-kaart kunt schrijven, klaar voor gebruik met je Raspberry Pi. Je kunt kiezen uit verschillende besturingssystemen die door Raspberry Pi worden aangeboden, zoals Raspberry Pi OS en andere.</p> <p>Raspberry Pi Imager downloadt het geselecteerde besturingssysteem rechtstreeks van de website van Raspberry Pi en schrijft het naar de SD-kaart. Dit versnelt het proces aanzienlijk in vergelijking met de standaardmethode van downloaden, opslaan en kopi\u00ebren. Raspberry Pi Imager is beschikbaar voor Windows, macOS en Ubuntu.</p> <p></p>"},{"location":"tools/usb_installation_media/rpi-imager/#installatie","title":"Installatie","text":"<p>Om Raspberry Pi Imager te gebruiken, moet je het eerst downloaden en installeren op een computer met een SD-kaartlezer:</p>"},{"location":"tools/usb_installation_media/rpi-imager/#download","title":"Download","text":"<ul> <li>Je kunt de downloadlinks vinden op de website van Raspberry Pi.</li> <li>Als je al Raspberry Pi OS of een debian-gebaseerd os gebruikt, kun je Raspberry Pi Imager ook installeren door <code>sudo apt install rpi-imager</code> te typen in een Terminal-venster.</li> </ul> <p>Nadat je Raspberry Pi Imager hebt ge\u00efnstalleerd, stop je de SD-kaart die je wilt gebruiken met je Raspberry Pi in de lezer en start je Raspberry Pi Imager op.</p> <ol> <li>Je ziet dan een eenvoudige interface met twee opties: Choose OS en Choose SD Card.</li> <li>Klik op Choose OS om een lijst te zien van alle beschikbare besturingssystemen die je kunt installeren. Je kunt ook kiezen voor Use custom om een eigen image-bestand te selecteren.</li> <li>Klik vervolgens op Choose SD Card om de SD-kaart te selecteren waarop je het besturingssysteem wilt schrijven. Zorg ervoor dat je de juiste kaart kiest, want alle gegevens erop zullen worden gewist</li> <li>Klik ten slotte op Write om het schrijfproces te starten. Dit kan enkele minuten duren, afhankelijk van de grootte van het besturingssysteem en de snelheid van je SD-kaart.</li> <li>Als het schrijfproces klaar is, kun je de SD-kaart uitwerpen en in je Raspberry Pi steken.</li> <li>Start je Raspberry Pi op en volg de instructies op het scherm om je besturingssysteem in te stellen.</li> </ol>"},{"location":"tools/usb_installation_media/rufus/","title":"Rufus","text":""},{"location":"tools/usb_installation_media/rufus/#rufus","title":"Rufus","text":""},{"location":"tools/usb_installation_media/rufus/#wat-is-rufus","title":"Wat is Rufus?","text":"<p>Rufus is a utility that helps format and create bootable USB flash drives, such as USB keys/pendrives, memory sticks, etc.</p> <p>It can be especially useful for cases where:</p> <ul> <li>you need to create USB installation media from bootable ISOs (Windows, Linux, UEFI, etc.)</li> <li>you need to work on a system that doesn't have an OS installed</li> <li>you need to flash a BIOS or other firmware from DOS</li> <li>you want to run a low-level utility</li> </ul> <p>Despite its small size, Rufus provides everything you need!</p> <p>Oh, and Rufus is fast. For instance it's about twice as fast as UNetbootin, Universal USB Installer or Windows 7 USB download tool, on the creation of a Windows 7 USB installation drive from an ISO. It is also marginally faster on the creation of Linux bootable USB from ISOs. A non exhaustive list of Rufus supported ISOs is also provided at the bottom of this page.</p>"},{"location":"tools/usb_installation_media/ventoy/","title":"Ventoy","text":""},{"location":"tools/usb_installation_media/ventoy/#ventoy","title":"Ventoy","text":""},{"location":"tools/usb_installation_media/ventoy/#wat-is-ventoy","title":"Wat is Ventoy?","text":"<p>Ventoy is een open source tool vor het maken van een bootable USB voor ISO/WIM/IMG/VHD(x)/EFI files. Met ventoy hoeft u de schijf niet steeds opnieuw te formatteren, u hoeft alleen maar de ISO/WIM/IMG/VHD(x)/EFI-bestanden naar de USB-drive te kopi\u00ebren en ze direct op te starten. Je kunt veel bestanden tegelijk kopi\u00ebren en ventoy geeft je een opstartmenu waarin je ze kunt selecteren (screenshot). U kunt ook door ISO/WIM/IMG/VHD(x)/EFI-bestanden op lokale schijven bladeren en deze opstarten. x86 Legacy BIOS, IA32 UEFI, x86_64 UEFI, ARM64 UEFI en MIPS64EL UEFI worden op dezelfde manier ondersteund. De meeste typen besturingssystemen worden ondersteund (Windows/WinPE/Linux/ChromeOS/Unix/VMware/Xen...)</p> <p></p>"},{"location":"tools/usb_installation_media/ventoy/#installatie","title":"Installatie","text":""},{"location":"tools/usb_installation_media/ventoy/#download","title":"Download","text":"<p>download te laatste versie van https://www.ventoy.net/en/download.html</p>"},{"location":"tools/usb_installation_media/ventoy/#installeren","title":"Installeren","text":"<ul> <li>Pak het gedownloade bestand uit.</li> <li>Open de folder en zoek naar Ventoy2disk/VentoyGUI en open deze file</li> <li>Selecteer de USB en druk op install.</li> </ul> <ul> <li>Achter de installatie zie je in je verkenner een USB met de naam Ventoy. Hier drop je alle ISO files in. Deze zijn direkt booteble.</li> </ul> <ul> <li>Restart je computer of steek de USB in de desbetreffende computer en ga naar het bootmenu. Daar zie je de Ventoy USB. Druk vervolgens op de juiste ISO.</li> </ul>"},{"location":"tools/usb_installation_media/ventoy/#links","title":"links","text":"<p>Download: https://www.ventoy.net/en/download.html</p>"},{"location":"windows/chocolatey/","title":"Chocolatey","text":""},{"location":"windows/chocolatey/#chocolatey","title":"Chocolatey","text":"<p>Chocolatey is a machine-level, command-line package manager and installer for Windows software.</p> <p>Project Homepage: Chocolatey Homepage</p>"},{"location":"windows/chocolatey/#installation","title":"Installation","text":"<ol> <li>Check the Execution Policy</li> </ol> <p>Run\u00a0<code>Get-ExecutionPolicy</code>. If it returns\u00a0<code>Restricted</code>, then run\u00a0<code>Set-ExecutionPolicy AllSigned</code>\u00a0or\u00a0<code>Set-ExecutionPolicy Bypass -Scope Process</code>.</p> <ol> <li>Install Chocolatey</li> </ol> <pre><code>Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\n</code></pre> <ol> <li>Check if you install chocolatey</li> </ol> <pre><code>choco -?\n</code></pre>"},{"location":"windows/chocolatey/#install-software-package","title":"Install software package","text":"<pre><code>choco install &lt;package&gt;\n</code></pre>"},{"location":"windows/environment-variables-in-windows/","title":"Environment Variables in Windows","text":""},{"location":"windows/environment-variables-in-windows/#environment-variables-in-windows","title":"Environment Variables in Windows","text":""},{"location":"windows/environment-variables-in-windows/#how-to-use-them-in-powershell","title":"How to use them in PowerShell","text":"<p>Environment Varaibles can be used in PowerShell with the prefix <code>$env:</code>.</p> <p>Example*: Variable: <code>%APPDATA%</code> In Powershell: <code>$env:APPDATA</code></p>"},{"location":"windows/environment-variables-in-windows/#list-of-environment-variables","title":"List of environment variables","text":"Variable Description <code>%ALLUSERSPROFILE%</code> C:\\ProgramData <code>%APPDATA%</code> C:\\Users{username}\\AppData\\Roaming <code>%COMMONPROGRAMFILES%</code> C:\\Program Files\\Common Files <code>%COMMONPROGRAMFILES(x86)%</code> C:\\Program Files (x86)\\Common Files <code>%CommonProgramW6432%</code> C:\\Program Files\\Common Files <code>%COMSPEC%</code> C:\\Windows\\System32\\cmd.exe <code>%HOMEDRIVE%</code> C:\\ <code>%HOMEPATH%</code> C:\\Users{username} <code>%LOCALAPPDATA%</code> C:\\Users{username}\\AppData\\Local <code>%LOGONSERVER%</code> \\{domain_logon_server} <code>%PATH%</code> C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem <code>%PathExt%</code> .com;.exe;.bat;.cmd;.vbs;.vbe;.js;.jse;.wsf;.wsh;.msc <code>%PROGRAMDATA%</code> C:\\ProgramData <code>%PROGRAMFILES%</code> C:\\Program Files <code>%ProgramW6432%</code> C:\\Program Files <code>%PROGRAMFILES(X86)%</code> C:\\Program Files (x86) <code>%PROMPT%</code> \\(P\\)G <code>%SystemDrive%</code> C: <code>%SystemRoot%</code> C:\\Windows <code>%TEMP%</code> C:\\Users{username}\\AppData\\Local\\Temp <code>%TMP%</code> C:\\Users{username}\\AppData\\Local\\Temp <code>%USERDOMAIN%</code> Userdomain associated with current user. <code>%USERDOMAIN_ROAMINGPROFILE%</code> Userdomain associated with roaming profile. <code>%USERNAME%</code> {username} <code>%USERPROFILE%</code> C:\\Users{username} <code>%WINDIR%</code> C:\\Windows <code>%PUBLIC%</code> C:\\Users\\Public <code>%PSModulePath%</code> %SystemRoot%\\system32\\WindowsPowerShell\\v1.0\\Modules\\ <code>%OneDrive%</code> C:\\Users{username}\\OneDrive <code>%DriverData%</code> C:\\Windows\\System32\\Drivers\\DriverData <code>%CD%</code> Outputs current directory path. (Command Prompt.) <code>%CMDCMDLINE%</code> Outputs command line used to launch current Command Prompt session. (Command Prompt.) <code>%CMDEXTVERSION%</code> Outputs the number of current command processor extensions. (Command Prompt.) <code>%COMPUTERNAME%</code> Outputs the system name. <code>%DATE%</code> Outputs current date. (Command Prompt.) <code>%TIME%</code> Outputs time. (Command Prompt.) <code>%ERRORLEVEL%</code> Outputs the number of defining exit status of previous command. (Command Prompt.) <code>%PROCESSOR_IDENTIFIER%</code> Outputs processor identifier. <code>%PROCESSOR_LEVEL%</code> Outputs processor level. <code>%PROCESSOR_REVISION%</code> Outputs processor revision. <code>%NUMBER_OF_PROCESSORS%</code> Outputs the number of physical and virtual cores. <code>%RANDOM%</code> Outputs random number from 0 through 32767. <code>%OS%</code> Windows_NT"},{"location":"windows/powershell/","title":"PowerShell Cheat-Sheet","text":""},{"location":"windows/powershell/#powershell-cheat-sheet","title":"PowerShell Cheat-Sheet","text":"<p>PowerShell is a task automation and configuration management program from Microsoft, consisting of a command-line shell and the associated scripting language.</p>"},{"location":"windows/powershell/#install-powershell","title":"Install PowerShell","text":"<p>PowerShell was made open-source and cross-platform with PowerShell Core, and can be installed on multiple operating systems.</p>"},{"location":"windows/powershell/#windows","title":"Windows","text":"<ol> <li>Download MSI Package from the Official PowerShell Docs</li> <li>Set up PowerShell Profile in Windows Terminal. <pre><code>\"commandline\": \"pwsh.exe -nologo\",\n\"name\": \"Powershell\",\n\"source\": \"Windows.Terminal.PowershellCore\"\n</code></pre></li> </ol>"},{"location":"windows/powershell/#linux-ubuntu","title":"Linux (Ubuntu)","text":"<pre><code># Update the list of packages\nsudo apt-get update\n# Install pre-requisite packages.\nsudo apt-get install -y wget apt-transport-https software-properties-common\n# Download the Microsoft repository GPG keys\nwget -q https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb\n# Register the Microsoft repository GPG keys\nsudo dpkg -i packages-microsoft-prod.deb\n# Update the list of packages after we added packages.microsoft.com\nsudo apt-get update\n# Install PowerShell\nsudo apt-get install -y powershell\n# Start PowerShell\npwsh\n</code></pre>"},{"location":"windows/powershell/#profile","title":"Profile","text":"<p>Set up a PowerShell Profile by opening the profile script : </p><pre><code>code $PROFILE\n</code></pre>"},{"location":"windows/powershell/#optional-set-up-starship-prompt","title":"(Optional) Set up starship Prompt","text":"<p>You can customize the look and feel of PowerShell with the Starship Prompt ([[starship]]).</p>"},{"location":"windows/windows-terminal/","title":"Windows terminal","text":""},{"location":"windows/windows-terminal/#windows-terminal","title":"Windows Terminal.","text":""},{"location":"windows/windows-terminal/#install-windows-terminal","title":"Install Windows Terminal","text":"<p>Windows Store: Windows Terminal</p>"},{"location":"windows/windows-terminal/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"<ol> <li> <p>Applic\u00adation commands</p> <ul> <li>ALT - F4: Close window</li> <li>CTRL - S\u00adHIFT - F: Find</li> <li>CTRL - S\u00adHIF\u00adT - SPACE: Open dropdown</li> <li>CTRL - ,: Open settings file</li> <li>ALT - ENTER - F11: Toggle full screen</li> </ul> </li> <li> <p>Tab commands</p> <ul> <li>CTRL - S\u00adHIFT - D: Duplicate tab</li> <li>CTRL - S\u00adHIFT - T: New tab</li> <li>CTRL - S\u00adHIFT - P: New tab from profile p=1..9</li> <li>CTRL - TAB: Switch to next tab</li> <li>CTRL - S\u00adHIF\u00adT - TAB: Switch to prev tab</li> <li>CTRL - ALT - N: Switch to tab n=0..9</li> </ul> </li> <li> <p>Pane commands</p> <ul> <li>ALT - SH\u00adIFT - D: Split pane optimally. Active profile</li> <li>ALT - SH\u00adIFT -  -: Split pane horizontally. Default profile</li> <li>ALT - SH\u00adIFT - +: Split pane vertically. Default profile</li> <li>ALT - SHIFT - ARROWS: Resize pane</li> <li>ALT - ARROWS: Move pane focus</li> <li>CTRL - S\u00adHIFT - W: Close innermost pane, tab, or window</li> </ul> </li> <li> <p>Clipboard commands</p> <ul> <li>CTRL - C: Copy</li> <li>CTRL - V: Paste</li> </ul> </li> <li> <p>Scrollback commands</p> <ul> <li>CTRL - S\u00adHIFT - UP: Scroll up</li> <li>CTRL - S\u00adHIF\u00adT - DOWN: Scroll down</li> <li>CTRL - S\u00adHIF\u00adT - PGUP: Scroll page up</li> <li>CTRL - S\u00adHIF\u00adT - PGDN: Scroll page down</li> </ul> </li> <li>Visual adjustment commands<ul> <li>CTRL - =: Increase font size</li> <li>CTRL -  -: Decrease font size</li> <li>CTRL - 0: Reset font size</li> </ul> </li> </ol>"},{"location":"windows/wsl/","title":"WSL","text":""},{"location":"windows/wsl/#install-wsl","title":"install WSL","text":"<p>Je kan WSL installeren door powershell op te starten als administrator en het volgende commando te plakken: </p><pre><code>wsl --install\n</code></pre> Na dit te hebben uitgevoerd moet u uw computer opnieuw opstarten. Ga vervolgens naar de Microsoft Store en download uw Linux ditro naar keuze."},{"location":"windows/wsl/#automatically-update-wsl-distributions-using-the-windows-scheduler","title":"Automatically update WSL distributions using the Windows Scheduler","text":"<p>Windows Subsystem for Linux (WSL) allows running one or multiple Linux distributions on Windows. Like any Operating System, you must install security updates on it. Instead of doing it manually, let's automate it using the Windows Scheduler!</p> <p>Open PowerShell and run the following commands to create a scheduled task that updates the default WSL distribution once a week.</p> <pre><code># https://learn.microsoft.com/en-us/powershell/module/scheduledtasks/new-scheduledtasktrigger?WT.mc_id=DT-MVP-5003978\n$Time = New-ScheduledTaskTrigger -At 12:00 -Weekly -WeeksInterval 1 -DaysOfWeek Monday\n\n# https://learn.microsoft.com/en-us/powershell/module/scheduledtasks/new-scheduledtaskaction?WT.mc_id=DT-MVP-5003978\n# If you want to update a specific distro, you can add \"--distribution &lt;DistributionName&gt;\"\n$Actions = @(\n    New-ScheduledTaskAction -Execute \"wsl\" -Argument \"--user root --exec apt-get update\"\n    New-ScheduledTaskAction -Execute \"wsl\" -Argument \"--user root --exec apt-get upgrade --yes\"\n)\n\n# https://learn.microsoft.com/en-us/powershell/module/scheduledtasks/new-scheduledtasksettingsset?WT.mc_id=DT-MVP-5003978\n$Settings = New-ScheduledTaskSettingsSet -WakeToRun:$false `\n                                         -MultipleInstances IgnoreNew `\n                                         -RunOnlyIfNetworkAvailable:$true `\n                                         -StartWhenAvailable:$true\n\n# https://learn.microsoft.com/en-us/powershell/module/scheduledtasks/register-scheduledtask?WT.mc_id=DT-MVP-5003978\nRegister-ScheduledTask -TaskName \"Update wsl\" -Trigger $Time -Action $Actions -Settings $Settings -TaskPath Updates\n</code></pre> <p>Note</p> <p>If you have multiple WSL distributions, you must duplicate the previous commands for each distro and add <code>--distribution &lt;ditro_name&gt;</code></p> <p>If everything's good, you should see the new task in the Task Scheduler:</p> <p></p> <p>You can run the task manually once to validate it works well. It could take a few minutes if you have never updated the distro!</p>"}]}